{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z0s4JIpel8sA"
   },
   "source": [
    "### Read the input data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Gbh1JMYGl8sB"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "GO3KFJ9fl8sE",
    "outputId": "eff78ff0-b104-4da0-c7d8-c31eb5dd28d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n"
     ]
    }
   ],
   "source": [
    "#Read the tweets one by one and process it\n",
    "import csv\n",
    "# inpTweets = csv.reader(open('TwitterData/survey_dump.csv', 'rb'), delimiter=',')\n",
    "user_id=[]\n",
    "inpTweets = csv.reader(open('TwitterData/survey_dump_with_tweet_count', 'rt'), delimiter=',')\n",
    "i = 0\n",
    "for row in inpTweets:\n",
    "    i+=1;\n",
    "    if(i>1):\n",
    "        user_id.append(row[0])\n",
    "\n",
    "print(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FW2hL82wl8sJ"
   },
   "source": [
    "### Pre-process Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "NNwpmlvel8sK"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class PreprocessTweets:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.name = 'PreprocessTweets'\n",
    "\n",
    "    #start process_tweet\n",
    "    def processTweet(self, tweet):\n",
    "        \n",
    "        #Convert to lower case\n",
    "        tweet = tweet.lower()\n",
    "        #Convert www.* or https?://* to URL\n",
    "        tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','URL',tweet)\n",
    "        #Convert @username to AT_USER\n",
    "        tweet = re.sub('@[^\\s]+','AT_USER',tweet)\n",
    "        #Remove additional white spaces\n",
    "        tweet = re.sub('[\\s]+', ' ', tweet)\n",
    "        #Replace #word with word\n",
    "        tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet)\n",
    "        #trim\n",
    "        tweet = tweet.strip('\\'\"')\n",
    "        # Remove all Non-ASCII characters\n",
    "        tweet = re.sub(r'[^\\x00-\\x7F]+',' ', tweet)\n",
    "\n",
    "        return tweet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "CvehIc4el8sN"
   },
   "outputs": [],
   "source": [
    "class FilterStopWords:\n",
    "\n",
    "    # stopWords = []\n",
    "    def __init__(self):\n",
    "        self.name = 'FilterStopWords'\n",
    "        #initialize stopWords\n",
    "        self.stopWords = []\n",
    "\n",
    "\n",
    "    def getStopWordList(self, stopWordListFileName):\n",
    "        #read the stopwords file and build a list\n",
    "        stopWords = []\n",
    "        stopWords.append('AT_USER')\n",
    "        stopWords.append('URL')\n",
    "        stopWords.append('[')\n",
    "        stopWords.append('[')\n",
    "\n",
    "        fp = open(stopWordListFileName, 'r')\n",
    "        line = fp.readline()\n",
    "        while line:\n",
    "            word = line.strip()\n",
    "            stopWords.append(word)\n",
    "            line = fp.readline()\n",
    "        fp.close()\n",
    "        return stopWords\n",
    "    \n",
    "    def getFeatureVector(self, tweet, stopWords):\n",
    "        featureVector = []\n",
    "        #split tweet into words\n",
    "        words = tweet.split()\n",
    "        for w in words:\n",
    "            #replace two or more with two occurrences\n",
    "            #w = replaceTwoOrMore(w)\n",
    "            #strip punctuation\n",
    "            w = w.strip('\\'\"?,.')\n",
    "            #check if the word stats with an alphabet\n",
    "            val = re.search(r\"^[a-zA-Z][a-zA-Z0-9]*$\", w)\n",
    "            #ignore if it is a stop word\n",
    "            if(w in self.stopWords or val is None):\n",
    "                continue\n",
    "            else:\n",
    "                featureVector.append(w.lower())\n",
    "        return featureVector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jdqkPePBl8sP"
   },
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "QV2Tb7J_l8sS"
   },
   "outputs": [],
   "source": [
    "\n",
    "import nltk\n",
    "from textblob import TextBlob\n",
    "# nltk.download()\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "class FeatureEngineering:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.name = 'FeatureEngineering'\n",
    "        self.featureList = []\n",
    "        # self.sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "\n",
    "    #start extract_features\n",
    "    def extract_features(self,tweet):\n",
    "        tweet_words = set(tweet)\n",
    "        features = {}\n",
    "        for word in self.featureList:\n",
    "            features['contains(%s)' % word] = (word in tweet_words)\n",
    "        return features\n",
    "\n",
    "## Create New Training set based on personality labels predicted from Survey results\n",
    "\n",
    "    def createNewTrainingSet(self, fileName):\n",
    "        XTrain = []\n",
    "        YTrain = []\n",
    "        XTrainFeatures = []\n",
    "        XTrainSentiment = []\n",
    "        XTrainFreqTweets = []\n",
    "        geo_latitude = []\n",
    "        geo_longitude = []\n",
    "        \n",
    "        objFilterStopWords = FilterStopWords()\n",
    "        objPreprocessTweets = PreprocessTweets()\n",
    "\n",
    "        stopWords = objFilterStopWords.getStopWordList('TwitterData/StopWords.txt')\n",
    "        \n",
    "        #Read the tweets one by one and process it\n",
    "        inpTweets = csv.reader(open(fileName, 'r'), delimiter=',')\n",
    "        next(inpTweets)\n",
    "        tweets = []\n",
    "        i = 0\n",
    "        for row in inpTweets:\n",
    "#             print row\n",
    "            personality = row[5]\n",
    "            tweet = row[1]\n",
    "            cleanTweet = tweet.replace('\"\",\"\"',\" \")\n",
    "            cleanTweet = cleanTweet.replace('\"\"',\" \")\n",
    "            processedTweet = objPreprocessTweets.processTweet(cleanTweet)\n",
    "\n",
    "            XTrainFreqTweets.append(int(row[4]))\n",
    "            wordsList = processedTweet.split()\n",
    "            \n",
    "            # Remove stop words\n",
    "            filtered_words = [word for word in wordsList if word not in stopwords.words('english')]\n",
    "            filteredTweets = ' '.join(filtered_words)\n",
    "            \n",
    "            featureVector = objFilterStopWords.getFeatureVector(processedTweet, stopWords)\n",
    "            \n",
    "            geo_latitude.append(float(row[2]))\n",
    "            geo_longitude.append(float(row[3]))\n",
    "            \n",
    "            blob = TextBlob(processedTweet)\n",
    "            sentiment = 0\n",
    "            for sentence in blob.sentences:\n",
    "                sentiment += sentence.sentiment.polarity\n",
    "\n",
    "            totSentiment = sentiment/ len(blob.sentences)\n",
    "\n",
    "            XTrainSentiment.append(totSentiment)\n",
    "\n",
    "            XTrainFeatures.append(filteredTweets)\n",
    "            \n",
    "            YTrain.append(personality)\n",
    "                        \n",
    "#             i+=1\n",
    "#             if i==3:\n",
    "#                 break\n",
    "            \n",
    "\n",
    "        return XTrain, YTrain, XTrainFeatures, XTrainSentiment, XTrainFreqTweets, geo_latitude, geo_longitude\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "-JYbu2ial8sU"
   },
   "outputs": [],
   "source": [
    "objFeatureEngineering = FeatureEngineering()\n",
    "fileName = 'TwitterData/survey_dump_with_tweet_count'\n",
    "XTrain, YTrain, XTrainFeatures, XTrainSentiment, XTrainFreqTweets, geo_latitude, geo_longitude = objFeatureEngineering.createNewTrainingSet(fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "l9adhNOjl8sa"
   },
   "outputs": [],
   "source": [
    "fileName = 'TwitterData/survey_dump_geo_gt_8_1'\n",
    "XEval, YEval, XEvalFeatures, XEvalSentiment, XEvalFreqTweets, eval_geo_latitude, eval_geo_longitude = objFeatureEngineering.createNewTrainingSet(fileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NwIlCYDrl8si"
   },
   "source": [
    "### Get Feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "dkyE9qeml8sl"
   },
   "outputs": [],
   "source": [
    "newYTrain = []\n",
    "# print YTrain\n",
    "for item in YTrain:\n",
    "    temp = item.replace('[', '')\n",
    "    temp = temp.replace('\\\"', '')\n",
    "    newItem = temp.replace(']', '')\n",
    "    newYTrain.append(newItem)\n",
    "    \n",
    "YTrain = newYTrain\n",
    "# print YTrain\n",
    "# print XTrainFeatures[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B-AyAxLMl8sp"
   },
   "source": [
    "### Map the class labels to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "VCXCmHgil8sq"
   },
   "outputs": [],
   "source": [
    "\n",
    "def mapLabels(className):\n",
    "    if className == 'Conscientiousness':\n",
    "        return 0\n",
    "    elif className == 'Extrovert':\n",
    "        return 1\n",
    "    elif className == 'Agreeable':\n",
    "        return 2\n",
    "    elif className == 'Empathetic':\n",
    "        return 3\n",
    "    elif className == 'Novelty Seeking':\n",
    "        return 4\n",
    "    elif className == 'Perfectionist':\n",
    "        return 5\n",
    "    elif className == 'Rigid':\n",
    "        return 6\n",
    "    elif className == 'Impulsive':\n",
    "        return 7\n",
    "    elif className == 'Psychopath':\n",
    "        return 8\n",
    "    elif className == 'Obsessive':\n",
    "        return 9\n",
    "    #elif className == None:\n",
    "        #return 10\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "YTrain = [mapLabels(x) for x in YTrain]\n",
    "YEval = [mapLabels(x) for x in YEval]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "nW3dh6Xul8ss",
    "outputId": "274c288d-8337-4757-8260-3d5a931726d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, None, None, None]\n"
     ]
    }
   ],
   "source": [
    "print (YEval[1:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "K-r1So9Fl8sv",
    "outputId": "1d46b509-f994-434e-e91a-891c448a205d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "80\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "XTrain = np.array(XTrainFeatures)\n",
    "YTrain = np.array(YTrain)\n",
    "\n",
    "print (len(XTrain))\n",
    "print (len(YTrain))\n",
    "\n",
    "#print (XTrain[1])\n",
    "print (YTrain[1])\n",
    "\n",
    "#print (XTrain[15])\n",
    "#print (YTrain[15])\n",
    "\n",
    "XEval = np.array(XEvalFeatures)\n",
    "YEval = np.array(YEval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KzAk6sADl8sy"
   },
   "source": [
    "### Split Train and Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "m8BT_RnZl8s0",
    "outputId": "f682b2bb-2003-4157-e199-b0bf4dc9644a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "20\n",
      "80\n",
      "[10  7  8  6  4  9  7  9  6  1  6  7  2  4  2  2  7  9  7  9  7  8  6  9\n",
      "  4  8  9  1  3  9  9  8  7  7  9  9  1  1  1  8  9  7  8  1  6  8  5  8\n",
      "  6  3  1  4  9  3  9  7  7  9  9  3]\n"
     ]
    }
   ],
   "source": [
    "trainSamples = XTrain[0:60]\n",
    "YtrainSamples = YTrain[0:60]\n",
    "\n",
    "\n",
    "testSamples = XTrain[60:]\n",
    "YtestSamples = YTrain[60:]\n",
    "\n",
    "print (len(trainSamples))\n",
    "print (len(testSamples))\n",
    "\n",
    "# print XTrain[60:63]\n",
    "print (len(XTrain))\n",
    "\n",
    "\n",
    "trainSentimentSamples = np.array(XTrainSentiment[0:60])\n",
    "testSentimentSamples = np.array(XTrainSentiment[60:])\n",
    "trainFreqTweetSamples = np.array(XTrainFreqTweets[0:60])\n",
    "testFreqTweetSamples = np.array(XTrainFreqTweets[60:])\n",
    "print (YtrainSamples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EtniRnE5l8s2"
   },
   "source": [
    "### Bag of Words as Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "bnuzEgeDl8s2",
    "outputId": "8a8e623c-830d-4699-ed17-4311d2884496"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5228\n",
      "(60, 5228)\n",
      "(20, 5228)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "XTr = vectorizer.fit_transform(trainSamples)\n",
    "print (len(vectorizer.get_feature_names()))\n",
    "trainBagVector = XTr.toarray()\n",
    "print (trainBagVector.shape)\n",
    "XTe = vectorizer.transform(testSamples)\n",
    "testBagVector = XTe.toarray()\n",
    "print (testBagVector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "C7sSJoLNl8s7",
    "outputId": "8b5cf259-b09c-4985-c32a-90478636419b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37012\n",
      "(3995, 37012)\n"
     ]
    }
   ],
   "source": [
    "XEv = vectorizer.fit_transform(XEval)\n",
    "print (len(vectorizer.get_feature_names()))\n",
    "evalBagVector = XEv.toarray()\n",
    "print (evalBagVector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "3Qry68AZl8s9"
   },
   "outputs": [],
   "source": [
    "XEv = XTe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "EHuKIpAWl8tA",
    "outputId": "9c040bc7-b49c-41e5-ad5a-16a66caab1f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 5228)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evalBagVector = evalBagVector[:,0:4909]\n",
    "#print (evalBagVector.shape)\n",
    "evalBagVector = XEv.toarray()\n",
    "evalBagVector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Lo4q2jeNl8tD",
    "outputId": "31d01d37-7b4b-4dc4-8c92-45925791f0ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(trainBagVector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YtqOYQfGl8tL"
   },
   "source": [
    "### State Transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "zlslXFcql8tL",
    "outputId": "db570f90-f4ca-4ffc-cb5b-fc19fe1c7e03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37012 37012\n"
     ]
    }
   ],
   "source": [
    "stateDict = {}\n",
    "featureVectors = vectorizer.get_feature_names()\n",
    "for i in range(len(featureVectors)):\n",
    "    stateDict[featureVectors[i]] = i+1\n",
    "print (len(stateDict), len(featureVectors)) #, stateDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "AGtvOciMl8tN"
   },
   "outputs": [],
   "source": [
    "def createStateTransitionVector(categoricalState, stateDict, maxLength):\n",
    "    if categoricalState:\n",
    "        feature = []\n",
    "        for state in categoricalState.split(' '):\n",
    "            try:\n",
    "                feature.append(stateDict[state.lower()])\n",
    "            except KeyError:\n",
    "                pass\n",
    "#                 print state\n",
    "        if len(feature) != maxLength:\n",
    "            for i in range(maxLength-len(feature)):\n",
    "                feature.append(0)\n",
    "        assert(len(feature)==maxLength)\n",
    "        return feature\n",
    "    else:\n",
    "        return [0] * maxLength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "SlhOKofAl8tP"
   },
   "outputs": [],
   "source": [
    "def createStateVectors(XStates, stateDict, maxLength):\n",
    "    XFeatures = []\n",
    "    for state in XStates:\n",
    "        XFeatures.append(createStateTransitionVector(state, stateDict, maxLength))\n",
    "    return XFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "P0qa1oexl8tQ",
    "outputId": "f479e378-bd67-4a09-a83f-5c25e0165b40"
   },
   "outputs": [],
   "source": [
    "trainStateTransitionVector =  createStateVectors(trainSamples, stateDict,6222)\n",
    "testStateTransitionVector = createStateVectors(testSamples, stateDict,6222)\n",
    "#print (trainStateTransitionVector[:2], testStateTransitionVector[:2])\n",
    "#print(trainStateTransitionVector[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "6s9gvaB1l8tT",
    "outputId": "a3f425bd-a5d2-4a4c-ba48-4a19386cf13e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6222\n",
      "6222\n"
     ]
    }
   ],
   "source": [
    "print (max([len(i) for i in trainStateTransitionVector]))\n",
    "print (max([len(i) for i in testStateTransitionVector]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Je72AVLbl8tW"
   },
   "source": [
    "### N Grams as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "X9Fk-SBIl8tW",
    "outputId": "4a4930d2-8c94-4f1b-c957-24c60769ac12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)\n",
      "45413\n",
      "(60, 45413)\n",
      "(20, 45413)\n"
     ]
    }
   ],
   "source": [
    "import scipy as sp\n",
    "noNGram = 3\n",
    "vectorizerNGram = CountVectorizer(ngram_range=(1, noNGram))\n",
    "XTrainNGram = vectorizerNGram.fit_transform(trainSamples)\n",
    "\n",
    "print (vectorizerNGram)\n",
    "\n",
    "\n",
    "print (len(vectorizerNGram.get_feature_names()))\n",
    "trainNGramVector = XTrainNGram.toarray()\n",
    "print (trainNGramVector.shape)\n",
    "XTestNGram = vectorizerNGram.transform(testSamples)\n",
    "testNGramVector = XTestNGram.toarray()\n",
    "print (testNGramVector.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IlWAkodOl8tb"
   },
   "source": [
    "### Stack or concatenate all features together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "bm9h-y3ul8tc",
    "outputId": "e3e22f64-6be4-4121-93ad-073e97c8acf7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      " 3.94581807e-02 6.20000000e+01]\n",
      "[0.         0.         0.         ... 0.         0.         0.10764351]\n"
     ]
    }
   ],
   "source": [
    "XTrainWordFeatures = trainBagVector #trainNGramVector\n",
    "#print (XTrainWordFeatures.shape)\n",
    "#print (trainSentimentSamples.shape)\n",
    "\n",
    "temp = np.column_stack((XTrainWordFeatures, trainSentimentSamples))\n",
    "#print (trainSentimentSamples[0])\n",
    "#print(XTrainWordFeatures[0],trainSentimentSamples[0])\n",
    "\n",
    "XTrainAllFeatures =  np.column_stack((temp, trainFreqTweetSamples))\n",
    "#print(XTrainWordFeatures.shape, trainSentimentSamples.shape)\n",
    "#print(trainFreqTweetSamples[0])\n",
    "print (XTrainAllFeatures[0])\n",
    "\n",
    "XTestWordFeatures = testBagVector #testNGramVector\n",
    "temp =  np.column_stack((XTestWordFeatures, testSentimentSamples))\n",
    "print (temp[0])\n",
    "XTestAllFeatures =  np.column_stack((temp, testFreqTweetSamples))\n",
    "\n",
    "\n",
    "#print (XTrainAllFeatures.shape)\n",
    "#print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "_V6LFYH9l8td",
    "outputId": "ada9e44e-dcc0-4213-daeb-917740578cc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(XEvalFreqTweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "oVkqJ-ERl8tg",
    "outputId": "d2fb6634-dd42-4ba0-ae30-6948c5aa7307"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# XEvalWordFeatures = evalBagVector #evalNGramVector\n",
    "# temp = np.column_stack((XEvalWordFeatures, XEvalSentiment))\n",
    "XEvalAllFeatures =  np.column_stack((np.column_stack((evalBagVector, XTrainSentiment[60:])), XTrainFreqTweets[60:]))\n",
    "\n",
    "print (type(XEvalAllFeatures))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JdqHbq9zl8ti"
   },
   "source": [
    "### Write Predicted Output Labels to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hHucWncol8ti"
   },
   "outputs": [],
   "source": [
    "def writePredictedLabelFile(YPred):\n",
    "    f = open(\"Predictions.csv\",\"w\")\n",
    "    f.write(\"Id,Label\" + \"\\n\")\n",
    "    for i in range(len(YPred)):\n",
    "        f.write(str(i) + \",\" + str(np.around(YPred[i],decimals=2))+ \"\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qQR3Xmwjl8tn"
   },
   "source": [
    "### Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "pnjJcBSQl8tp"
   },
   "outputs": [],
   "source": [
    "#Multi Class SVM\n",
    "from sklearn import svm\n",
    "def classifyMultiClassSVMClassifier(XTrain, XTest, YTrain, YTest, params):\n",
    "    ker = params['kernel']\n",
    "    YPred = svm.SVC(kernel=ker).fit(XTrain, YTrain).predict(XTest)\n",
    "    diff = YPred - YTest\n",
    "    score = diff[diff == 0].size\n",
    "    return (100.0 * score)/(YPred.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "gZQTzUZfl8tr"
   },
   "outputs": [],
   "source": [
    "#K Nearest Neighbours Classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "def classifyKNNClassifier(XTrain, XTest, YTrain, YTest, params):\n",
    "#     print XTrain.shape, XTest.shape\n",
    "    neighbours = params['neighbours']\n",
    "    neigh = KNeighborsClassifier(n_neighbors=neighbours)\n",
    "    YPred = neigh.fit(XTrain, YTrain).predict(XTest)\n",
    "    diff = YPred - YTest\n",
    "    score = diff[diff == 0].size\n",
    "    return (100.0 * score)/(YPred.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "GxLTVXd1l8tt"
   },
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "from sklearn import linear_model\n",
    "def classifyLogisticRegression(XTrain, XTest, YTrain, YTest, params):\n",
    "    LogReg = linear_model.LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None)\n",
    "    LogReg.fit(XTrain, YTrain)\n",
    "    # Finds the optimal model parameters using a least squares method.\n",
    "    # To get the parameter values:\n",
    "    # LogReg.get_params()\n",
    "    # To predict a new input XTest,\n",
    "    YPred = LogReg.predict(XTest)\n",
    "    diff = YPred - YTest\n",
    "    score = diff[diff == 0].size\n",
    "    return (100.0 * score)/(YPred.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6k-88uusl8uN"
   },
   "source": [
    "### Stratified K Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hKs91Zeml8uO"
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import StratifiedKFold\n",
    "def stratifiedKFoldVal(XTrain, YTrain, classify, params):\n",
    "    n_folds = 5\n",
    "    score = 0.0\n",
    "    skf = StratifiedKFold(YTrain, n_folds)\n",
    "    try:\n",
    "        multi = params['multi']\n",
    "    except KeyError:\n",
    "        multi = False\n",
    "    for train_index, test_index in skf:\n",
    "        y_train, y_test = YTrain[train_index], YTrain[test_index]\n",
    "        if not multi:\n",
    "            X_train, X_test = XTrain[train_index], XTrain[test_index]\n",
    "            score += classify(X_train, X_test,  y_train, y_test, params)\n",
    "        else:\n",
    "            X_train, X_test = [XTrain[i] for i in train_index], [XTrain[i] for i in test_index]\n",
    "            score += classify(np.array(X_train), np.array(X_test),  y_train, y_test, params)\n",
    "        \n",
    "    return score/n_folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0zx5kHJHl8uQ"
   },
   "source": [
    "### Normalisation of Feature Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "L5xH3w_xl8uR"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "def NormalizeVector(XTestFeatures,XTrainFeatures):\n",
    "    XTestFeaturesNorm = preprocessing.normalize(XTestFeatures, norm='l2')\n",
    "    XTrainFeaturesNorm = preprocessing.normalize(XTrainFeatures, norm='l2')\n",
    "    print (XTrainFeaturesNorm.shape,XTestFeaturesNorm.shape)\n",
    "#     print XTrainFeaturesNorm[0],XTestFeaturesNorm[0]\n",
    "    return XTrainFeaturesNorm, XTestFeaturesNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0c-XMcBBl8uT"
   },
   "source": [
    "### Assign Train features for cross validation based on the feature encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "4LE18q6Al8uT",
    "outputId": "d47657c6-eeab-4c2e-fb4f-88d632cbcfc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'list'>\n",
      "(60, 5230)\n",
      "(60,)\n"
     ]
    }
   ],
   "source": [
    "train = XTrainAllFeatures\n",
    "# train = tfidfTrain\n",
    "# train = trainStateTransitionVector\n",
    "print (type(trainBagVector), type(trainStateTransitionVector))\n",
    "# train = []\n",
    "# for i in xrange(len(trainBagVector)):\n",
    "#     train.append(trainBagVector[i]+trainStateTransitionVector[i])\n",
    "# print len(train)\n",
    "# train = np.hstack([tfidfTrain, np.array(trainStateTransitionVector)])\n",
    "# train = np.hstack([trainBagVector, np.array(trainStateTransitionVector)])\n",
    "\n",
    "print (train.shape)\n",
    "YTrain = YtrainSamples\n",
    "print (YTrain.shape)\n",
    "YTest = YtestSamples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FVGRhnefl8uZ"
   },
   "source": [
    "### Selection of Nearest Neighbours for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "3NkxQNs1l8ug"
   },
   "outputs": [],
   "source": [
    "# train = np.hstack([XTrainAllFeatures, XTestAllFeatures])\n",
    "train = XTrainAllFeatures\n",
    "test = XTestAllFeatures\n",
    "params = {'neighbours':25}\n",
    "neighbours = params['neighbours']\n",
    "neigh = KNeighborsClassifier(n_neighbors=neighbours)\n",
    "YPred = neigh.fit(train, YTrain).predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "524X7jvql8uh",
    "outputId": "5e8ed81c-e923-46e7-a443-02f18b21b089"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 5230)\n"
     ]
    }
   ],
   "source": [
    "#print (YPred[2:3020])\n",
    "print (test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "vckfxNZ3l8ul"
   },
   "outputs": [],
   "source": [
    "writePredictedLabelFile(YPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "XSLTiAorl8un"
   },
   "outputs": [],
   "source": [
    "params = {'kernel':'linear'}\n",
    "ker = params['kernel']\n",
    "YPred = svm.SVC(kernel=ker, probability = True).fit(train, YTrain).decision_function(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfYPred=YPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data=dfYPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns=['Conscientiousness','Extrovert','Agreeable','Emphathetic','Nov Seekng','Perfectionist','Rigid','Impulsive','Psychopath','Obsessive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dom_pers']=df.idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['thres']= np.random.randint(10, 100, df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['user_id']=user_id[60:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conscientiousness</th>\n",
       "      <th>Extrovert</th>\n",
       "      <th>Agreeable</th>\n",
       "      <th>Emphathetic</th>\n",
       "      <th>Nov Seekng</th>\n",
       "      <th>Perfectionist</th>\n",
       "      <th>Rigid</th>\n",
       "      <th>Impulsive</th>\n",
       "      <th>Psychopath</th>\n",
       "      <th>Obsessive</th>\n",
       "      <th>dom_pers</th>\n",
       "      <th>thres</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1385371850</th>\n",
       "      <td>2.991397</td>\n",
       "      <td>1.943081</td>\n",
       "      <td>4.018347</td>\n",
       "      <td>6.074546</td>\n",
       "      <td>-0.231194</td>\n",
       "      <td>5.048139</td>\n",
       "      <td>9.150127</td>\n",
       "      <td>8.101138</td>\n",
       "      <td>7.087852</td>\n",
       "      <td>0.816567</td>\n",
       "      <td>Rigid</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1414166594</th>\n",
       "      <td>5.038901</td>\n",
       "      <td>1.807069</td>\n",
       "      <td>7.087266</td>\n",
       "      <td>4.011314</td>\n",
       "      <td>-0.230813</td>\n",
       "      <td>2.955506</td>\n",
       "      <td>6.044647</td>\n",
       "      <td>8.154049</td>\n",
       "      <td>9.320657</td>\n",
       "      <td>0.811402</td>\n",
       "      <td>Psychopath</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438909568</th>\n",
       "      <td>7.150552</td>\n",
       "      <td>1.843636</td>\n",
       "      <td>6.094489</td>\n",
       "      <td>5.022726</td>\n",
       "      <td>-0.220148</td>\n",
       "      <td>3.897060</td>\n",
       "      <td>2.932160</td>\n",
       "      <td>8.164202</td>\n",
       "      <td>9.287765</td>\n",
       "      <td>0.827558</td>\n",
       "      <td>Psychopath</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1516255956</th>\n",
       "      <td>3.990955</td>\n",
       "      <td>1.957664</td>\n",
       "      <td>4.002541</td>\n",
       "      <td>6.086920</td>\n",
       "      <td>-0.233024</td>\n",
       "      <td>4.003854</td>\n",
       "      <td>9.195879</td>\n",
       "      <td>8.108971</td>\n",
       "      <td>7.066225</td>\n",
       "      <td>0.820014</td>\n",
       "      <td>Rigid</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530948307</th>\n",
       "      <td>6.058167</td>\n",
       "      <td>0.937459</td>\n",
       "      <td>1.845558</td>\n",
       "      <td>6.122564</td>\n",
       "      <td>-0.173730</td>\n",
       "      <td>6.099958</td>\n",
       "      <td>4.995303</td>\n",
       "      <td>5.024350</td>\n",
       "      <td>5.026884</td>\n",
       "      <td>9.063487</td>\n",
       "      <td>Obsessive</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1534856329</th>\n",
       "      <td>6.064796</td>\n",
       "      <td>1.924715</td>\n",
       "      <td>2.896449</td>\n",
       "      <td>7.104210</td>\n",
       "      <td>-0.196861</td>\n",
       "      <td>8.099842</td>\n",
       "      <td>6.046714</td>\n",
       "      <td>3.998016</td>\n",
       "      <td>8.082038</td>\n",
       "      <td>0.980081</td>\n",
       "      <td>Perfectionist</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1537350764</th>\n",
       "      <td>1.961829</td>\n",
       "      <td>2.983116</td>\n",
       "      <td>5.012134</td>\n",
       "      <td>6.066373</td>\n",
       "      <td>-0.246244</td>\n",
       "      <td>4.007256</td>\n",
       "      <td>9.230343</td>\n",
       "      <td>8.145182</td>\n",
       "      <td>7.053950</td>\n",
       "      <td>0.786062</td>\n",
       "      <td>Rigid</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1537352881</th>\n",
       "      <td>3.888966</td>\n",
       "      <td>1.842349</td>\n",
       "      <td>9.273100</td>\n",
       "      <td>5.031782</td>\n",
       "      <td>-0.269227</td>\n",
       "      <td>2.805167</td>\n",
       "      <td>8.312329</td>\n",
       "      <td>6.208344</td>\n",
       "      <td>7.160727</td>\n",
       "      <td>0.746463</td>\n",
       "      <td>Agreeable</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601780840</th>\n",
       "      <td>5.044580</td>\n",
       "      <td>1.750905</td>\n",
       "      <td>8.224450</td>\n",
       "      <td>5.077734</td>\n",
       "      <td>-0.236482</td>\n",
       "      <td>2.851790</td>\n",
       "      <td>6.039276</td>\n",
       "      <td>6.115528</td>\n",
       "      <td>9.341165</td>\n",
       "      <td>0.791054</td>\n",
       "      <td>Psychopath</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1607302296</th>\n",
       "      <td>5.055989</td>\n",
       "      <td>1.884178</td>\n",
       "      <td>2.953052</td>\n",
       "      <td>6.090753</td>\n",
       "      <td>-0.224326</td>\n",
       "      <td>4.043360</td>\n",
       "      <td>9.119531</td>\n",
       "      <td>7.109496</td>\n",
       "      <td>8.159345</td>\n",
       "      <td>0.808622</td>\n",
       "      <td>Rigid</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620048930</th>\n",
       "      <td>5.101733</td>\n",
       "      <td>1.677775</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>7.235172</td>\n",
       "      <td>-0.250165</td>\n",
       "      <td>2.740922</td>\n",
       "      <td>3.843039</td>\n",
       "      <td>8.343290</td>\n",
       "      <td>6.033332</td>\n",
       "      <td>0.774902</td>\n",
       "      <td>Agreeable</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1624016628</th>\n",
       "      <td>9.075466</td>\n",
       "      <td>0.928316</td>\n",
       "      <td>1.863700</td>\n",
       "      <td>6.108735</td>\n",
       "      <td>-0.185091</td>\n",
       "      <td>6.089358</td>\n",
       "      <td>4.015666</td>\n",
       "      <td>5.007710</td>\n",
       "      <td>4.043916</td>\n",
       "      <td>8.052226</td>\n",
       "      <td>Conscientiousness</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1625810258</th>\n",
       "      <td>6.065533</td>\n",
       "      <td>1.922004</td>\n",
       "      <td>2.904171</td>\n",
       "      <td>7.114534</td>\n",
       "      <td>-0.180019</td>\n",
       "      <td>8.095764</td>\n",
       "      <td>5.019987</td>\n",
       "      <td>6.020333</td>\n",
       "      <td>7.066299</td>\n",
       "      <td>0.971393</td>\n",
       "      <td>Perfectionist</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626181508</th>\n",
       "      <td>6.054159</td>\n",
       "      <td>0.912779</td>\n",
       "      <td>1.904892</td>\n",
       "      <td>8.117846</td>\n",
       "      <td>-0.194234</td>\n",
       "      <td>8.096152</td>\n",
       "      <td>5.026055</td>\n",
       "      <td>3.003368</td>\n",
       "      <td>8.075010</td>\n",
       "      <td>4.003970</td>\n",
       "      <td>Emphathetic</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1632372234</th>\n",
       "      <td>7.070668</td>\n",
       "      <td>0.911117</td>\n",
       "      <td>1.851225</td>\n",
       "      <td>6.105517</td>\n",
       "      <td>-0.179927</td>\n",
       "      <td>6.096404</td>\n",
       "      <td>5.010254</td>\n",
       "      <td>5.016010</td>\n",
       "      <td>4.035714</td>\n",
       "      <td>9.083017</td>\n",
       "      <td>Obsessive</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1647555169</th>\n",
       "      <td>8.071488</td>\n",
       "      <td>0.924597</td>\n",
       "      <td>1.880301</td>\n",
       "      <td>7.103730</td>\n",
       "      <td>-0.187382</td>\n",
       "      <td>9.109263</td>\n",
       "      <td>3.024319</td>\n",
       "      <td>4.005524</td>\n",
       "      <td>6.057156</td>\n",
       "      <td>5.011005</td>\n",
       "      <td>Perfectionist</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1649744274</th>\n",
       "      <td>8.126696</td>\n",
       "      <td>1.877166</td>\n",
       "      <td>3.969610</td>\n",
       "      <td>6.063882</td>\n",
       "      <td>-0.190013</td>\n",
       "      <td>9.155476</td>\n",
       "      <td>4.004501</td>\n",
       "      <td>4.011952</td>\n",
       "      <td>7.096335</td>\n",
       "      <td>0.884396</td>\n",
       "      <td>Perfectionist</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1654946996</th>\n",
       "      <td>7.069886</td>\n",
       "      <td>0.928220</td>\n",
       "      <td>1.882310</td>\n",
       "      <td>7.104771</td>\n",
       "      <td>-0.193354</td>\n",
       "      <td>8.086366</td>\n",
       "      <td>4.026516</td>\n",
       "      <td>2.994836</td>\n",
       "      <td>8.084079</td>\n",
       "      <td>5.016369</td>\n",
       "      <td>Perfectionist</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234567890</th>\n",
       "      <td>6.037398</td>\n",
       "      <td>0.892898</td>\n",
       "      <td>1.852926</td>\n",
       "      <td>6.084776</td>\n",
       "      <td>-0.199542</td>\n",
       "      <td>7.069785</td>\n",
       "      <td>3.997771</td>\n",
       "      <td>2.974740</td>\n",
       "      <td>7.048419</td>\n",
       "      <td>9.240828</td>\n",
       "      <td>Obsessive</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663585442</th>\n",
       "      <td>7.064699</td>\n",
       "      <td>0.919664</td>\n",
       "      <td>1.886911</td>\n",
       "      <td>6.102453</td>\n",
       "      <td>-0.193281</td>\n",
       "      <td>8.092933</td>\n",
       "      <td>4.022826</td>\n",
       "      <td>2.995232</td>\n",
       "      <td>8.086350</td>\n",
       "      <td>6.022212</td>\n",
       "      <td>Perfectionist</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Conscientiousness  Extrovert  Agreeable  Emphathetic  Nov Seekng  \\\n",
       "user_id                                                                        \n",
       "1385371850           2.991397   1.943081   4.018347     6.074546   -0.231194   \n",
       "1414166594           5.038901   1.807069   7.087266     4.011314   -0.230813   \n",
       "1438909568           7.150552   1.843636   6.094489     5.022726   -0.220148   \n",
       "1516255956           3.990955   1.957664   4.002541     6.086920   -0.233024   \n",
       "1530948307           6.058167   0.937459   1.845558     6.122564   -0.173730   \n",
       "1534856329           6.064796   1.924715   2.896449     7.104210   -0.196861   \n",
       "1537350764           1.961829   2.983116   5.012134     6.066373   -0.246244   \n",
       "1537352881           3.888966   1.842349   9.273100     5.031782   -0.269227   \n",
       "1601780840           5.044580   1.750905   8.224450     5.077734   -0.236482   \n",
       "1607302296           5.055989   1.884178   2.953052     6.090753   -0.224326   \n",
       "1620048930           5.101733   1.677775   9.500000     7.235172   -0.250165   \n",
       "1624016628           9.075466   0.928316   1.863700     6.108735   -0.185091   \n",
       "1625810258           6.065533   1.922004   2.904171     7.114534   -0.180019   \n",
       "1626181508           6.054159   0.912779   1.904892     8.117846   -0.194234   \n",
       "1632372234           7.070668   0.911117   1.851225     6.105517   -0.179927   \n",
       "1647555169           8.071488   0.924597   1.880301     7.103730   -0.187382   \n",
       "1649744274           8.126696   1.877166   3.969610     6.063882   -0.190013   \n",
       "1654946996           7.069886   0.928220   1.882310     7.104771   -0.193354   \n",
       "1234567890           6.037398   0.892898   1.852926     6.084776   -0.199542   \n",
       "1663585442           7.064699   0.919664   1.886911     6.102453   -0.193281   \n",
       "\n",
       "            Perfectionist     Rigid  Impulsive  Psychopath  Obsessive  \\\n",
       "user_id                                                                 \n",
       "1385371850       5.048139  9.150127   8.101138    7.087852   0.816567   \n",
       "1414166594       2.955506  6.044647   8.154049    9.320657   0.811402   \n",
       "1438909568       3.897060  2.932160   8.164202    9.287765   0.827558   \n",
       "1516255956       4.003854  9.195879   8.108971    7.066225   0.820014   \n",
       "1530948307       6.099958  4.995303   5.024350    5.026884   9.063487   \n",
       "1534856329       8.099842  6.046714   3.998016    8.082038   0.980081   \n",
       "1537350764       4.007256  9.230343   8.145182    7.053950   0.786062   \n",
       "1537352881       2.805167  8.312329   6.208344    7.160727   0.746463   \n",
       "1601780840       2.851790  6.039276   6.115528    9.341165   0.791054   \n",
       "1607302296       4.043360  9.119531   7.109496    8.159345   0.808622   \n",
       "1620048930       2.740922  3.843039   8.343290    6.033332   0.774902   \n",
       "1624016628       6.089358  4.015666   5.007710    4.043916   8.052226   \n",
       "1625810258       8.095764  5.019987   6.020333    7.066299   0.971393   \n",
       "1626181508       8.096152  5.026055   3.003368    8.075010   4.003970   \n",
       "1632372234       6.096404  5.010254   5.016010    4.035714   9.083017   \n",
       "1647555169       9.109263  3.024319   4.005524    6.057156   5.011005   \n",
       "1649744274       9.155476  4.004501   4.011952    7.096335   0.884396   \n",
       "1654946996       8.086366  4.026516   2.994836    8.084079   5.016369   \n",
       "1234567890       7.069785  3.997771   2.974740    7.048419   9.240828   \n",
       "1663585442       8.092933  4.022826   2.995232    8.086350   6.022212   \n",
       "\n",
       "                     dom_pers  thres  \n",
       "user_id                               \n",
       "1385371850              Rigid     51  \n",
       "1414166594         Psychopath     34  \n",
       "1438909568         Psychopath     57  \n",
       "1516255956              Rigid     48  \n",
       "1530948307          Obsessive     25  \n",
       "1534856329      Perfectionist     63  \n",
       "1537350764              Rigid     57  \n",
       "1537352881          Agreeable     53  \n",
       "1601780840         Psychopath     37  \n",
       "1607302296              Rigid     91  \n",
       "1620048930          Agreeable     25  \n",
       "1624016628  Conscientiousness     64  \n",
       "1625810258      Perfectionist     91  \n",
       "1626181508        Emphathetic     48  \n",
       "1632372234          Obsessive     49  \n",
       "1647555169      Perfectionist     32  \n",
       "1649744274      Perfectionist     31  \n",
       "1654946996      Perfectionist     27  \n",
       "1234567890          Obsessive     84  \n",
       "1663585442      Perfectionist     44  "
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.set_index('user_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SHtTaGybl8us"
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "bPOYQ9Izl8ut"
   },
   "outputs": [],
   "source": [
    "print (YTrain[0:60])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9rxxT7Gbl8u7"
   },
   "source": [
    "### Get features in format for Models of NLTK Classify "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "itNrTZkFl8u7"
   },
   "outputs": [],
   "source": [
    "def featNLTKClassify(samples, phase):\n",
    "    featureVectors = vectorizer.get_feature_names()\n",
    "    nltkClassifySamples = []\n",
    "\n",
    "    for i in xrange(len(samples)):\n",
    "        t = samples[i]\n",
    "        lstFuncCalls = t.split()\n",
    "        wordOccDict = {}\n",
    "        for j in xrange(len(featureVectors)):\n",
    "             wordOccDict[featureVectors[j]] = lstFuncCalls.count(featureVectors[j])\n",
    "        if phase == 'train':\n",
    "            nltkClassifySamples.append((wordOccDict, YTrain[i]))\n",
    "        else:\n",
    "            nltkClassifySamples.append(wordOccDict)\n",
    "\n",
    "    return nltkClassifySamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "mrZIpseul8u8"
   },
   "outputs": [],
   "source": [
    "# nltkClassifyTrain = featNLTKClassify(trainSamples, 'train')\n",
    "# nltkClassifyTest = featNLTKClassify(testSamples, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "QCUhnIXAl8vK"
   },
   "outputs": [],
   "source": [
    "# selectRandomForestScores = []\n",
    "# selectKernelScores = []\n",
    "# selectNeighbourScores = []\n",
    "\n",
    "# train = trainBagVector\n",
    "\n",
    "# params = {'trees':1000, 'criterion':'gini','random_state':1000}\n",
    "# score = stratifiedKFoldVal(train, YTrain, classifyRandomForestClassifier, params)\n",
    "# print score\n",
    "# selectRandomForestScores.append(score)\n",
    "\n",
    "# params = {'neighbours':25}\n",
    "# score = stratifiedKFoldVal(train, YTrain, classifyKNNClassifier, params)\n",
    "# print score\n",
    "# selectNeighbourScores.append(score)\n",
    "\n",
    "# params = {'kernel':'linear'}\n",
    "# score = stratifiedKFoldVal(train, YTrain, classifyMultiClassSVMClassifier, params)\n",
    "# print score\n",
    "# selectKernelScores.append(score)\n",
    "\n",
    "\n",
    "\n",
    "# train = tfidfTrain\n",
    "\n",
    "# params = {'trees':1000, 'criterion':'gini','random_state':1000}\n",
    "# score = stratifiedKFoldVal(train, YTrain, classifyRandomForestClassifier, params)\n",
    "# print score\n",
    "# selectRandomForestScores.append(score)\n",
    "\n",
    "# params = {'neighbours':25}\n",
    "# score = stratifiedKFoldVal(train, YTrain, classifyKNNClassifier, params)\n",
    "# print score\n",
    "# selectNeighbourScores.append(score)\n",
    "\n",
    "# params = {'kernel':'rbf'}\n",
    "# score = stratifiedKFoldVal(train, YTrain, classifyMultiClassSVMClassifier, params)\n",
    "# print score\n",
    "# selectKernelScores.append(score)\n",
    "\n",
    "\n",
    "# train = np.array(trainStateTransitionVector)\n",
    "\n",
    "# params = {'trees':1000, 'criterion':'gini','random_state':1000}\n",
    "# score = stratifiedKFoldVal(train, YTrain, classifyRandomForestClassifier, params)\n",
    "# print score\n",
    "# selectRandomForestScores.append(score)\n",
    "\n",
    "# params = {'neighbours':25}\n",
    "# score = stratifiedKFoldVal(train, YTrain, classifyKNNClassifier, params)\n",
    "# print score\n",
    "# selectNeighbourScores.append(score)\n",
    "\n",
    "\n",
    "# params = {'kernel':'rbf'}\n",
    "# score = stratifiedKFoldVal(train, YTrain, classifyMultiClassSVMClassifier, params)\n",
    "# print score\n",
    "# selectKernelScores.append(score)\n",
    "\n",
    "\n",
    "# train = np.hstack([trainBagVector, np.array(trainStateTransitionVector)])\n",
    "\n",
    "# params = {'trees':1000, 'criterion':'gini','random_state':1000}\n",
    "# score = stratifiedKFoldVal(train, YTrain, classifyRandomForestClassifier, params)\n",
    "# print score\n",
    "# selectRandomForestScores.append(score)\n",
    "\n",
    "# params = {'neighbours':25}\n",
    "# score = stratifiedKFoldVal(train, YTrain, classifyKNNClassifier, params)\n",
    "# print score\n",
    "# selectNeighbourScores.append(score)\n",
    "\n",
    "# params = {'kernel':'rbf'}\n",
    "# score = stratifiedKFoldVal(train, YTrain, classifyMultiClassSVMClassifier, params)\n",
    "# print score\n",
    "# selectKernelScores.append(score)\n",
    "\n",
    "\n",
    "\n",
    "# print selectRandomForestScores\n",
    "# print selectKernelScores\n",
    "# print selectNeighbourScores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qomAnBRkl8vc"
   },
   "source": [
    "## Final evaluation results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "clEWbc15l8vj"
   },
   "source": [
    "### Bar graph depicting Categorization Accuracy Scores on the different Models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qFo7aWEQl8vp"
   },
   "source": [
    "### Hence we conclude that the best model is kNN using TF-IDF as features !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2cxQngihl8vq"
   },
   "source": [
    "## Geo Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "dOE-x8nll8vr"
   },
   "outputs": [],
   "source": [
    "def reverseMapLabels(classNo):\n",
    "    if className == 0:\n",
    "        return 'Conscientiousness'\n",
    "    elif className == 1:\n",
    "        return 'Extrovert'\n",
    "    elif className == 2:\n",
    "        return 'Agreeable'\n",
    "    elif className == 3:\n",
    "        return 'Empathetic'\n",
    "    elif className == 4:\n",
    "        return 'Novelty Seeking'\n",
    "    elif className == 5:\n",
    "        return 'Perfectionist'\n",
    "    elif className == 6:\n",
    "        return 'Rigid'\n",
    "    elif className == 7:\n",
    "        return 'Impulsive'\n",
    "    elif className == 8:\n",
    "        return 'Psychopath'\n",
    "    elif className == 9:\n",
    "        return 'Obsessive'\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "d5rQxYUSl8vt"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def GeoPlot(geo_longitude, geo_latitude, labels):\n",
    "\n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    \n",
    "    raw_data = {'latitude': geo_latitude,'longitude': geo_longitude}\n",
    "\n",
    "    df = pd.DataFrame(raw_data, columns = ['latitude', 'longitude'])\n",
    "    \n",
    "    totSampleLen = len(labels)\n",
    "#     print totSampleLen\n",
    "    colors = ['blue', 'beige', 'red', 'green', 'magenta', 'yellow', 'cyan', 'aquamarine', 'azure', 'darkkhaki']\n",
    "    \n",
    "    m = Basemap(projection='gall',lon_0=0,lat_0=0,resolution='i')\n",
    "    #x1,y1=map(geo_longitude, geo_latitude)\n",
    "    x1,y1 = map(df['longitude'].values, df['latitude'].values)\n",
    "\n",
    "\n",
    "    m.drawmapboundary(fill_color='black') # fill to edge\n",
    "    m.drawcountries()\n",
    "    m.fillcontinents(color='white',lake_color='black')\n",
    "    \n",
    "#     m.scatter(x1, y1, marker='D',color='m', s=2)\n",
    "    for i in xrange(totSampleLen):\n",
    "        for k in xrange(10):\n",
    "            if labels[i] == k:\n",
    "#                 print x1[i], y1[i]\n",
    "#                 print colors[k]\n",
    "#                 m.scatter(x1[i], y1[i], marker='D',color=colors[k], s=2)\n",
    "                m.plot(x1[i], y1[i], 'ro', color=colors[k]) #'ro', markersize=6)\n",
    "\n",
    "    \n",
    "    for k in xrange(10):\n",
    "        m.scatter(0,0, marker='D',color=colors[k], s=2, label=reverseMapLabels(k))\n",
    "    \n",
    "    plt.title(\"Geo-tagging Personality Types for Twitter Users\")\n",
    "    # Place a legend to the right of this smaller figure.\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GlTAgMuYl8vv"
   },
   "source": [
    "### Visualize Personality Types based on location of user tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "nlcR-jh2l8vv"
   },
   "outputs": [],
   "source": [
    "lon = np.random.random_integers(-180,180,60)\n",
    "lat = np.random.random_integers(-90,90,60)\n",
    "geo_latitude = lat\n",
    "geo_longitude = lon\n",
    "print (type(lat))\n",
    "print (lat.shape)\n",
    "GeoPlot(geo_longitude, geo_latitude, YTrain[0:60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "V2r7jDRTl8vw"
   },
   "outputs": [],
   "source": [
    "GeoPlot(eval_geo_longitude[0:1000], eval_geo_latitude[0:1000], YPred[0:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "atory5iSl8vy"
   },
   "source": [
    "### Geo-tagging Sentiments of Twitter Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "rTKbhnfHl8vy"
   },
   "outputs": [],
   "source": [
    "def reverseMapSentiments(classNo):\n",
    "    if classNo == 0:\n",
    "        return 'Negative'\n",
    "    elif classNo == 1:\n",
    "        return 'Neutral'\n",
    "    elif classNo == 2:\n",
    "        return 'Positive'\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Gtu6m0fjl8v2"
   },
   "outputs": [],
   "source": [
    "def GeoSentimentPlot(geo_longitude, geo_latitude, sentiments):\n",
    "\n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    \n",
    "    raw_data = {'latitude': geo_latitude,\n",
    "            'longitude': geo_longitude}\n",
    "\n",
    "    df = pd.DataFrame(raw_data, columns = ['latitude', 'longitude'])\n",
    "\n",
    "    \n",
    "    totSampleLen = len(sentiments)\n",
    "    colors = ['red', 'blue', 'green']\n",
    "    \n",
    "    negLimit = 0\n",
    "    posLimit = 0\n",
    "    \n",
    "    m = Basemap(projection='gall',lon_0=0,lat_0=0,resolution='i')\n",
    "    \n",
    "    x1,y1 = map(df['longitude'].values, df['latitude'].values)\n",
    "\n",
    "    m.drawmapboundary(fill_color='black')\n",
    "    m.drawcountries()\n",
    "    m.fillcontinents(color='white',lake_color='black')\n",
    "    \n",
    "    for i in xrange(totSampleLen):\n",
    "#         print sentiments[i]\n",
    "        if sentiments[i] < negLimit:\n",
    "            m.plot(x1[i], y1[i], 'ro', color=colors[0])\n",
    "        elif sentiments[i] >= negLimit and sentiments[i] <= posLimit:\n",
    "            m.plot(x1[i], y1[i], 'ro', color=colors[1])\n",
    "        elif sentiments[i] > posLimit:\n",
    "            m.plot(x1[i], y1[i], 'ro', color=colors[2])\n",
    "    \n",
    "    \n",
    "    for k in xrange(3):\n",
    "        m.scatter(0,0, marker='D',color=colors[k], s=2, label=reverseMapSentiments(k))\n",
    "    \n",
    "    plt.title(\"Geo-tagging Sentiments of Twitter Users\")\n",
    "    # Place a legend to the right of this smaller figure.\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HCAII7i7l8v3"
   },
   "source": [
    "### Visualize Sentiment of user tweets based on location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "zubDYtnVl8v3"
   },
   "outputs": [],
   "source": [
    "GeoSentimentPlot(geo_longitude, geo_latitude, XTrainSentiment[0:60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Z1YzM8rVl8v5"
   },
   "outputs": [],
   "source": [
    "print len(eval_geo_longitude)\n",
    "eval_geo_longitude = np.array(eval_geo_longitude)\n",
    "eval_geo_latitude = np.array(eval_geo_latitude)\n",
    "print len(eval_geo_longitude)\n",
    "print eval_geo_longitude.shape\n",
    "print type(eval_geo_longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "bOhChS8xl8v5"
   },
   "outputs": [],
   "source": [
    "GeoSentimentPlot(eval_geo_longitude[0:1000], eval_geo_latitude[0:1000], XEvalSentiment[0:1000])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "Personality Predictor and Visualizer-Copy3.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

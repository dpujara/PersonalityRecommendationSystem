
% Default to the notebook output style

    


% Inherit from the specified cell style.




    
\documentclass[11pt]{article}

    
    
    \usepackage[T1]{fontenc}
    % Nicer default font (+ math font) than Computer Modern for most use cases
    \usepackage{mathpazo}

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % We will generate all images so they have a width \maxwidth. This means
    % that they will get their normal width if they fit onto the page, but
    % are scaled down if they would overflow the margins.
    \makeatletter
    \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
    \else\Gin@nat@width\fi}
    \makeatother
    \let\Oldincludegraphics\includegraphics
    % Set max figure width to be 80% of text width, for now hardcoded.
    \renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.8\maxwidth]{#1}}
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionLabelFormat{nolabel}{}
    \captionsetup{labelformat=nolabel}

    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    

    
    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatability definitions
    \def\gt{>}
    \def\lt{<}
    % Document parameters
    \title{Notebook\_Personality\_type}
    
    
    

    % Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}



    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle
    
    

    
    \section{Predicting Myers-Briggs Personality Types from Social Media
Posts}\label{predicting-myers-briggs-personality-types-from-social-media-posts}

\subsubsection{Created by Maria Yarolin}\label{created-by-maria-yarolin}

    \begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

    \subsection{Executive Summary}\label{executive-summary}

\textbf{Problem Statement}

\emph{Personality} refers to individual differences in characteristic
patterns of thinking, feeling and behaving. \emph{Personality
typologies} classify different types of individuals to reveal and
enhance the understanding of their behaviors.

The Myers-Briggs Type Indicator (MBTI) is a psychological assessment
tool to classify people into one of 16 different personality types. The
classification system consists of a four-letter code based on four axes,
where each letter in the code refers to the predominant trait in each
axis. The four axes are: - Introversion (I) -- Extroversion (E) -
Describes the different attitudes people use to direct their energy
(i.e. the "inner world" vs. one's "outer world") - Intuition (N) --
Sensing (S) - Describes people's method of processing informaton (i.e.
paying more attention to the patterns and possibilities seen in the
information received vs. information that comes in through the five
senses) - Thinking (T) -- Feeling (F) - Describes people's method for
making decisions (i.e. putting more weight on objective principles and
impersonal facts vs. personal concerns and the people involved) -
Judging (J) -- Perceiving (P) - Describes people's orientation to the
outside world and the behaviors one exhibits (i.e. preferring a
structured and decided lifestyle vs. a more flexible and adaptive
lifestyle)

For example, a person scoring higher on Introversion, Sensing, Thinking,
and Judging would be classified with an ISTJ personality type.

This capstone project uses natural language processing techniques to
analyze text postings on a social forum, and predict the writers'
personality type using a classification model. It also compares
personality types based on other factors such as the length, polarity,
and subjectivity of these posts.

\textbf{Data source}

The dataset was obtained on Kaggle
(https://www.kaggle.com/datasnaek/mbti-type), and contains data from
8,675 subjects.

The original dataset consists of 2 columns: - \emph{type}: subjects'
known MBTI code (16 codes in total) - \emph{posts}: subjects' 50 most
recent posts on PersonalityCafe, an online forum focusing on personality
types (http://personalitycafe.com/forum/). The site is geared toward the
general public (not psychology professionals) with an interest in the
topic of personality types

The dataset is skewed toward subjects from the Introverted-Intuitive
personality types (INFJ, INFP, INTJ, and INTP). Also, personality types
are self-reported by the users of this forum, and it is assumed that
they are reported accurately.

\textbf{Key findings}

\emph{Multiclass classification}

Three different classification models were tested: K-Neighbors
Classifier, Random Forest Classifier, and One-Vs-The-Rest Classifier.
The One-Vs-The-Rest Classifier, although having only the second-highest
accuracy score of the three (0.265), cleared the 0.211 baseline and also
predicted classes across the entire 16-class range -\/- unlike the
top-scoring Random Forest Classifier.

\emph{Binary classification}

A Random Forest Classifier was used to classify each of the four axis
pairs. This model was chosen because it had the highest accuracy rate of
the three models used in the multiclass exercise (although it had
faltered in the predictions of the lower-prevalence classes). The model
topped the baseline on only the \emph{Thinking-Feeling} axis, with an
accuracy of 0.697 (vs. a baseline of 0.541), but the models for the
other three axes did not fall that far behind their respective
baselines.

\emph{Sentiment Analysis and Word Count}

On average, subjects used 26.4 words per post, with a neutral polarity
(0.133) and moderate subjectivity (0.540). Those with one of the
\emph{Intuitive-Feeling} personality types tended to have higher post
lengths than many of their counterparts, while the
\emph{Extroversion-Intuitive-Feeling} types tended to show significantly
higher (but still relatively neutral) polarity and higher (but still
relatively moderate) subjectivity than the other personality types.

    \begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

    \subsection{Document Sections}\label{document-sections}

\begin{itemize}
\tightlist
\item
  Section \ref{exploratory-data-analysis}

  \begin{itemize}
  \tightlist
  \item
    Section \ref{data-dictionary}
  \end{itemize}
\item
  Section \ref{preprocessing}
\item
  Section \ref{classification}

  \begin{itemize}
  \tightlist
  \item
    Section \ref{multiclass-classification}

    \begin{itemize}
    \tightlist
    \item
      Section \ref{random-forest-classifier}
    \item
      Section \ref{k-neighbors-classifier}
    \item
      Section \ref{one-vs-rest-classifier}
    \end{itemize}
  \item
    Section \ref{binary-classification}
  \end{itemize}
\item
  Section \ref{text-analysis}

  \begin{itemize}
  \tightlist
  \item
    Section \ref{length-of-post}
  \item
    Section \ref{polarity}
  \item
    Section \ref{subjectivity}
  \end{itemize}
\item
  Section \ref{conclusion}
\item
  Section \ref{next-steps}
\end{itemize}

    \begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

     \#\# Exploratory Data Analysis (EDA)

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}2}]:} \PY{c+c1}{\PYZsh{} Import libraries}
        \PY{k+kn}{from} \PY{n+nn}{collections} \PY{k}{import} \PY{n}{Counter}
        
        \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
        \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
        \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
        \PY{o}{\PYZpc{}}\PY{k}{matplotlib} inline
        \PY{k+kn}{import} \PY{n+nn}{seaborn} \PY{k}{as} \PY{n+nn}{sns}
        \PY{n}{sns}\PY{o}{.}\PY{n}{set\PYZus{}style}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{whitegrid}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        \PY{k+kn}{import} \PY{n+nn}{scipy}\PY{n+nn}{.}\PY{n+nn}{stats} \PY{k}{as} \PY{n+nn}{stats}
        
        \PY{k+kn}{import} \PY{n+nn}{re}
        \PY{k+kn}{import} \PY{n+nn}{string}
        
        \PY{k+kn}{from} \PY{n+nn}{imblearn}\PY{n+nn}{.}\PY{n+nn}{over\PYZus{}sampling} \PY{k}{import} \PY{n}{SMOTE}
        
        \PY{k+kn}{from} \PY{n+nn}{nltk}\PY{n+nn}{.}\PY{n+nn}{corpus} \PY{k}{import} \PY{n}{stopwords}
        \PY{k+kn}{from} \PY{n+nn}{nltk}\PY{n+nn}{.}\PY{n+nn}{stem} \PY{k}{import} \PY{n}{PorterStemmer}
        
        \PY{k+kn}{from} \PY{n+nn}{sklearn} \PY{k}{import} \PY{n}{metrics}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{feature\PYZus{}extraction}\PY{n+nn}{.}\PY{n+nn}{text} \PY{k}{import} \PY{n}{CountVectorizer}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{decomposition} \PY{k}{import} \PY{n}{TruncatedSVD}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{ensemble} \PY{k}{import} \PY{n}{RandomForestClassifier}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{multiclass} \PY{k}{import} \PY{n}{OneVsRestClassifier}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{neighbors} \PY{k}{import} \PY{n}{KNeighborsClassifier}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{metrics} \PY{k}{import} \PY{n}{confusion\PYZus{}matrix}\PY{p}{,} \PY{n}{classification\PYZus{}report}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection} \PY{k}{import} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{,} \PY{n}{GridSearchCV}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{pipeline} \PY{k}{import} \PY{n}{make\PYZus{}pipeline}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{svm} \PY{k}{import} \PY{n}{LinearSVC}
        
        \PY{k+kn}{from} \PY{n+nn}{statsmodels}\PY{n+nn}{.}\PY{n+nn}{stats}\PY{n+nn}{.}\PY{n+nn}{multicomp} \PY{k}{import} \PY{n}{pairwise\PYZus{}tukeyhsd}
        
        \PY{k+kn}{from} \PY{n+nn}{textblob} \PY{k}{import} \PY{n}{TextBlob}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}3}]:} \PY{c+c1}{\PYZsh{} Load dataset}
        \PY{n}{df} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{mbti\PYZus{}1.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


     \textbf{Data Dictionary}

Variables in original dataframe: - \emph{type}: (string) four-letter
Myers-Briggs Type Index (MBTI) code - \emph{posts}: (string) text of
fifty most recent posts to the \emph{PersonalityCafe} forum

New variables added for analysis in the \emph{df\_working} datafile: -
\emph{I-E}: (string) code on Introversion-Extroversion axis, derived
from \emph{type} - \emph{N-S}: (string) code on Intuition-Sensing axis,
derived from \emph{type} - \emph{T-F}: (string) code on Thinking-Feeling
axis, derived from \emph{type} - \emph{J-P}: (string) code on
Judging-Perceiving axis, derived from \emph{type} - \emph{posts\_r}:
(string) cleaned post text, derived from \emph{posts} -
\emph{total\_words}: (integer) number of total words across 50 posts,
derived from \emph{posts} - \emph{avg\_words\_per\_post}: (float)
average number of words per post, derived from \emph{posts} and
\emph{total words} - \emph{polarity}: (float) polarity score (range -1
to 1) - \emph{subjectivity}: (float) subjectivity score (range 0 to 1)

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}4}]:} \PY{c+c1}{\PYZsh{} View first five rows of dataset}
        \PY{n}{df}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}4}]:}    type                                              posts
        0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||{\ldots}
        1  ENTP  'I'm finding the lack of me in these posts ver{\ldots}
        2  INTP  'Good one  \_\_\_\_\_   https://www.youtube.com/wat{\ldots}
        3  INTJ  'Dear INTP,   I enjoyed our conversation the o{\ldots}
        4  ENTJ  'You're fired.|||That's another silly misconce{\ldots}
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}5}]:} \PY{c+c1}{\PYZsh{} View full text of the first post}
        \PY{n+nb}{print}\PY{p}{(}\PY{n}{df}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
'http://www.youtube.com/watch?v=qsXHcwe3krw|||http://41.media.tumblr.com/tumblr\_lfouy03PMA1qa1rooo1\_500.jpg|||enfp and intj moments  https://www.youtube.com/watch?v=iz7lE1g4XM4  sportscenter not top ten plays  https://www.youtube.com/watch?v=uCdfze1etec  pranks|||What has been the most life-changing experience in your life?|||http://www.youtube.com/watch?v=vXZeYwwRDw8   http://www.youtube.com/watch?v=u8ejam5DP3E  On repeat for most of today.|||May the PerC Experience immerse you.|||The last thing my INFJ friend posted on his facebook before committing suicide the next day. Rest in peace\textasciitilde{}   http://vimeo.com/22842206|||Hello ENFJ7. Sorry to hear of your distress. It's only natural for a relationship to not be perfection all the time in every moment of existence. Try to figure the hard times as times of growth, as{\ldots}|||84389  84390  http://wallpaperpassion.com/upload/23700/friendship-boy-and-girl-wallpaper.jpg  http://assets.dornob.com/wp-content/uploads/2010/04/round-home-design.jpg {\ldots}|||Welcome and stuff.|||http://playeressence.com/wp-content/uploads/2013/08/RED-red-the-pokemon-master-32560474-450-338.jpg  Game. Set. Match.|||Prozac, wellbrutin, at least thirty minutes of moving your legs (and I don't mean moving them while sitting in your same desk chair), weed in moderation (maybe try edibles as a healthier alternative{\ldots}|||Basically come up with three items you've determined that each type (or whichever types you want to do) would more than likely use, given each types' cognitive functions and whatnot, when left by{\ldots}|||All things in moderation.  Sims is indeed a video game, and a good one at that. Note: a good one at that is somewhat subjective in that I am not completely promoting the death of any given Sim{\ldots}|||Dear ENFP:  What were your favorite video games growing up and what are your now, current favorite video games? :cool:|||https://www.youtube.com/watch?v=QyPqT8umzmY|||It appears to be too late. :sad:|||There's someone out there for everyone.|||Wait{\ldots} I thought confidence was a good thing.|||I just cherish the time of solitude b/c i revel within my inner world more whereas most other time i'd be workin{\ldots} just enjoy the me time while you can. Don't worry, people will always be around to{\ldots}|||Yo entp ladies{\ldots} if you're into a complimentary personality,well, hey.|||{\ldots} when your main social outlet is xbox live conversations and even then you verbally fatigue quickly.|||http://www.youtube.com/watch?v=gDhy7rdfm14  I really dig the part from 1:46 to 2:50|||http://www.youtube.com/watch?v=msqXffgh7b8|||Banned because this thread requires it of me.|||Get high in backyard, roast and eat marshmellows in backyard while conversing over something intellectual, followed by massages and kisses.|||http://www.youtube.com/watch?v=Mw7eoU3BMbE|||http://www.youtube.com/watch?v=4V2uYORhQOk|||http://www.youtube.com/watch?v=SlVmgFQQ0TI|||Banned for too many b's in that sentence. How could you! Think of the B!|||Banned for watching movies in the corner with the dunces.|||Banned because Health class clearly taught you nothing about peer pressure.|||Banned for a whole host of reasons!|||http://www.youtube.com/watch?v=IRcrv41hgz4|||1) Two baby deer on left and right munching on a beetle in the middle.  2) Using their own blood, two cavemen diary today's latest happenings on their designated cave diary wall.  3) I see it as{\ldots}|||a pokemon world  an infj society  everyone becomes an optimist|||49142|||http://www.youtube.com/watch?v=ZRCEq\_JFeFM|||http://discovermagazine.com/2012/jul-aug/20-things-you-didnt-know-about-deserts/desert.jpg|||http://oyster.ignimgs.com/mediawiki/apis.ign.com/pokemon-silver-version/d/dd/Ditto.gif|||http://www.serebii.net/potw-dp/Scizor.jpg|||Not all artists are artists because they draw. It's the idea that counts in forming something of your own{\ldots} like a signature.|||Welcome to the robot ranks, person who downed my self-esteem cuz I'm not an avid signature artist like herself. :proud:|||Banned for taking all the room under my bed. Ya gotta learn to share with the roaches.|||http://www.youtube.com/watch?v=w8IgImn57aQ|||Banned for being too much of a thundering, grumbling kind of storm{\ldots} yep.|||Ahh{\ldots} old high school music I haven't heard in ages.   http://www.youtube.com/watch?v=dcCRUPCdB1w|||I failed a public speaking class a few years ago and I've sort of learned what I could do better were I to be in that position again. A big part of my failure was just overloading myself with too{\ldots}|||I like this person's mentality. He's a confirmed INTJ by the way. http://www.youtube.com/watch?v=hGKLI-GEc6M|||Move to the Denver area and start a new life for myself.'

    \end{Verbatim}

    Examining the raw text, it is noted that: - Each post is separated by 3
pipes ( \textbar{}\textbar{}\textbar{} ). - Website links appear
frequently in this post. - The 4-letter personality type codes are
referenced frequently. These posts were obtained from a forum
specifically dedicated to personality types, so the subjects were primed
regarding their classification. The data transformation should add the
codes for the 16 types to the list of stopwords, to avoid biasing the
model.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}6}]:} \PY{c+c1}{\PYZsh{} View shape of dataset}
        \PY{n}{df}\PY{o}{.}\PY{n}{shape}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}6}]:} (8675, 2)
\end{Verbatim}
            
    There are 8675 rows and 2 columns in the dataframe.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}7}]:} \PY{c+c1}{\PYZsh{} View information about the dataset}
        \PY{n}{df}\PY{o}{.}\PY{n}{info}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 8675 entries, 0 to 8674
Data columns (total 2 columns):
type     8675 non-null object
posts    8675 non-null object
dtypes: object(2)
memory usage: 135.6+ KB

    \end{Verbatim}

    The column names are 'type' and 'posts'. Both are datatype 'object'.
There are no null values.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}8}]:} \PY{c+c1}{\PYZsh{} Examine number of unique items are in the \PYZsq{}type\PYZsq{} (classification) column}
        \PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{unique}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}8}]:} array(['INFJ', 'ENTP', 'INTP', 'INTJ', 'ENTJ', 'ENFJ', 'INFP', 'ENFP',
               'ISFP', 'ISTP', 'ISFJ', 'ISTJ', 'ESTP', 'ESFP', 'ESTJ', 'ESFJ'],
              dtype=object)
\end{Verbatim}
            
    The 'type' column contains 16 unique codes, representing the 16
different personality types.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}9}]:} \PY{c+c1}{\PYZsh{} Explore the counts for each of these types}
        \PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}9}]:} INFP    1832
        INFJ    1470
        INTP    1304
        INTJ    1091
        ENTP     685
        ENFP     675
        ISTP     337
        ISFP     271
        ENTJ     231
        ISTJ     205
        ENFJ     190
        ISFJ     166
        ESTP      89
        ESFP      48
        ESFJ      42
        ESTJ      39
        Name: type, dtype: int64
\end{Verbatim}
            
    Observation: Of the 8675 records, INFP is the most frequently-appearing
Myers-Briggs type in this dataset (n=1832), while ESTJ is the least
frequent (n=39).

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}10}]:} \PY{c+c1}{\PYZsh{} Countplot of the 16 personality types in the dataset}
         \PY{n}{dims1} \PY{o}{=} \PY{p}{(}\PY{l+m+mf}{15.0}\PY{p}{,} \PY{l+m+mf}{4.0}\PY{p}{)}
         \PY{n}{fig}\PY{p}{,} \PY{n}{ax} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{n}{dims1}\PY{p}{)}
         \PY{n}{coolwarm} \PY{o}{=} \PY{n}{sns}\PY{o}{.}\PY{n}{color\PYZus{}palette}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{coolwarm}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+m+mi}{16}\PY{p}{)}
         \PY{n}{sns}\PY{o}{.}\PY{n}{set\PYZus{}palette}\PY{p}{(}\PY{n}{coolwarm}\PY{p}{)}
         \PY{n}{sns}\PY{o}{.}\PY{n}{countplot}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{type}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{data}\PY{o}{=}\PY{n}{df}\PY{p}{,} \PYZbs{}
                       \PY{n}{order}\PY{o}{=}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ENFJ}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ENFP}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ENTJ}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ENTP}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ESFJ}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ESFP}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ESTJ}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ESTP}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PYZbs{}
                              \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{INFJ}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{INFP}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{INTJ}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{INTP}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ISFJ}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ISFP}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ISTJ}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ISTP}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Distribution of Myers\PYZhy{}Briggs Types in the Dataset}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{16}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{xticks}\PY{p}{(}\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{yticks}\PY{p}{(}\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_21_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    The bar chart above shows that INFP (Introversion - Intuition - Feeling
- Perceiving) is the most frequently appearing type in the dataset,
followed by INFJ (Introversion - Intuition - Feeling - Judging).
Overall, the dataset contains many more Intuitive-Intuition (IN-)
groupings than any other type. Conversely, the dataset contains very few
Extroversion-Sensing (ES-) types.

It is possible that the sample is highly self-selected, and people who
display Introverted-Intuitive traits are more inclined to be interested
in personality theory and/or users of the PersonalityCafe site.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}11}]:} \PY{c+c1}{\PYZsh{} Explore the counts for each axis of the types}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Introversion (I) – Extroversion (E)}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{map}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{x}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Intuition (N) – Sensing (S)}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{map}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{x}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Thinking (T) – Feeling (F)}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{map}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{x}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Judging (J) – Perceiving (P)}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{map}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{x}\PY{p}{[}\PY{l+m+mi}{3}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Introversion (I) – Extroversion (E) 
 I    6676
E    1999
Name: type, dtype: int64 

Intuition (N) – Sensing (S) 
 N    7478
S    1197
Name: type, dtype: int64 

Thinking (T) – Feeling (F) 
 F    4694
T    3981
Name: type, dtype: int64 

Judging (J) – Perceiving (P) 
 P    5241
J    3434
Name: type, dtype: int64 


    \end{Verbatim}

    Viewed by individual axes, we again see the dataset contains many more
Introverts (I) than Extroverts (E), and more Intuitives (N) than Sensers
(S). The distributions of Thinkers (T) vs. Feelers (F), and Judgers (J)
vs. Perceivers (P) are more balanced.

    \begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

     \#\# Preprocessing

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}12}]:} \PY{c+c1}{\PYZsh{} Create a working copy of the dataframe}
         \PY{n}{df\PYZus{}working} \PY{o}{=} \PY{n}{df}\PY{o}{.}\PY{n}{copy}\PY{p}{(}\PY{p}{)}
         \PY{n}{df\PYZus{}working}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}12}]:}    type                                              posts
         0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||{\ldots}
         1  ENTP  'I'm finding the lack of me in these posts ver{\ldots}
         2  INTP  'Good one  \_\_\_\_\_   https://www.youtube.com/wat{\ldots}
         3  INTJ  'Dear INTP,   I enjoyed our conversation the o{\ldots}
         4  ENTJ  'You're fired.|||That's another silly misconce{\ldots}
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}13}]:} \PY{c+c1}{\PYZsh{} Create a binary column for each of the 4 axis types for later analysis}
         \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{I\PYZhy{}E}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{map}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Introversion}\PY{l+s+s1}{\PYZsq{}} \PY{k}{if} \PY{n}{x}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{I}\PY{l+s+s1}{\PYZsq{}} \PY{k}{else} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Extroversion}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{N\PYZhy{}S}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{map}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Intuition}\PY{l+s+s1}{\PYZsq{}} \PY{k}{if} \PY{n}{x}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{N}\PY{l+s+s1}{\PYZsq{}} \PY{k}{else} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Sensing}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{T\PYZhy{}F}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{map}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Thinking}\PY{l+s+s1}{\PYZsq{}} \PY{k}{if} \PY{n}{x}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{T}\PY{l+s+s1}{\PYZsq{}} \PY{k}{else} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Feeling}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{J\PYZhy{}P}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{map}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Judging}\PY{l+s+s1}{\PYZsq{}} \PY{k}{if} \PY{n}{x}\PY{p}{[}\PY{l+m+mi}{3}\PY{p}{]} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{J}\PY{l+s+s1}{\PYZsq{}} \PY{k}{else} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Perceiving}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         
         \PY{n}{df\PYZus{}working}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}13}]:}    type                                              posts           I-E  \textbackslash{}
         0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||{\ldots}  Introversion   
         1  ENTP  'I'm finding the lack of me in these posts ver{\ldots}  Extroversion   
         2  INTP  'Good one  \_\_\_\_\_   https://www.youtube.com/wat{\ldots}  Introversion   
         3  INTJ  'Dear INTP,   I enjoyed our conversation the o{\ldots}  Introversion   
         4  ENTJ  'You're fired.|||That's another silly misconce{\ldots}  Extroversion   
         
                  N-S       T-F         J-P  
         0  Intuition   Feeling     Judging  
         1  Intuition  Thinking  Perceiving  
         2  Intuition  Thinking  Perceiving  
         3  Intuition  Thinking     Judging  
         4  Intuition  Thinking     Judging  
\end{Verbatim}
            
    Codes for the new columns: - I-E: Introversion - Extroversion - N-S:
Intuition - Sensing - T-F: Thinking - Feeling - J-P: Judging -
Perceiving

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}14}]:} \PY{c+c1}{\PYZsh{} Countplot of Introversion \PYZhy{} Extroversion axis}
         \PY{n}{IEcolors} \PY{o}{=} \PY{n}{sns}\PY{o}{.}\PY{n}{xkcd\PYZus{}palette}\PY{p}{(}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{red}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{soft pink}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
         \PY{n}{sns}\PY{o}{.}\PY{n}{set\PYZus{}palette}\PY{p}{(}\PY{n}{IEcolors}\PY{p}{)}
         \PY{n}{sns}\PY{o}{.}\PY{n}{countplot}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{I\PYZhy{}E}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{data}\PY{o}{=}\PY{n}{df\PYZus{}working}\PY{p}{,} \PY{n}{order}\PY{o}{=}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Introversion}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Extroversion}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Distribution of Introversion vs. Extroversion in the Dataset}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{16}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{ylim}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{8000}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{xticks}\PY{p}{(}\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{yticks}\PY{p}{(}\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_30_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    The bar chart above show that the dataset is heavily skewed toward
Introversion over Extroversion.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}15}]:} \PY{c+c1}{\PYZsh{} Countplot of Intuition \PYZhy{} Sensing axis}
         \PY{n}{NScolors} \PY{o}{=} \PY{n}{sns}\PY{o}{.}\PY{n}{xkcd\PYZus{}palette}\PY{p}{(}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{blue}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{light blue}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
         \PY{n}{sns}\PY{o}{.}\PY{n}{set\PYZus{}palette}\PY{p}{(}\PY{n}{NScolors}\PY{p}{)}
         \PY{n}{sns}\PY{o}{.}\PY{n}{countplot}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{N\PYZhy{}S}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{data}\PY{o}{=}\PY{n}{df\PYZus{}working}\PY{p}{,} \PY{n}{order}\PY{o}{=}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Intuition}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Sensing}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Distribution of Intuition vs. Sensing in the Dataset}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{16}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{ylim}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{8000}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{xticks}\PY{p}{(}\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{yticks}\PY{p}{(}\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_32_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    The bar chart above shows that the dataset is heavily skewed toward
Intuition over Sensing.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}16}]:} \PY{c+c1}{\PYZsh{} Countplot of Thinking \PYZhy{} Feeling axis}
         \PY{n}{TFcolors} \PY{o}{=} \PY{n}{sns}\PY{o}{.}\PY{n}{xkcd\PYZus{}palette}\PY{p}{(}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{green}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{pale green}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
         \PY{n}{sns}\PY{o}{.}\PY{n}{set\PYZus{}palette}\PY{p}{(}\PY{n}{TFcolors}\PY{p}{)}
         \PY{n}{sns}\PY{o}{.}\PY{n}{countplot}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{T\PYZhy{}F}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{data}\PY{o}{=}\PY{n}{df\PYZus{}working}\PY{p}{,} \PY{n}{order}\PY{o}{=}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Thinking}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Feeling}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Distribution of Thinking vs. Feeling in the Dataset}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{16}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{ylim}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{8000}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{xticks}\PY{p}{(}\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{yticks}\PY{p}{(}\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_34_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    The bar chart above shows that the dataset is somewhat skewed toward
Feeling over Thinking.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}17}]:} \PY{c+c1}{\PYZsh{} Countplot of Judging \PYZhy{} Perceiving axis}
         \PY{n}{JPcolors} \PY{o}{=} \PY{n}{sns}\PY{o}{.}\PY{n}{xkcd\PYZus{}palette}\PY{p}{(}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{purple}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{lavender}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
         \PY{n}{sns}\PY{o}{.}\PY{n}{set\PYZus{}palette}\PY{p}{(}\PY{n}{JPcolors}\PY{p}{)}
         \PY{n}{sns}\PY{o}{.}\PY{n}{countplot}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{J\PYZhy{}P}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{data}\PY{o}{=}\PY{n}{df\PYZus{}working}\PY{p}{,} \PY{n}{order}\PY{o}{=}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Judging}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Perceiving}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Distribution of Judging vs. Perceiving in the Dataset}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{16}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{ylim}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{8000}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{xticks}\PY{p}{(}\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{yticks}\PY{p}{(}\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_36_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    The bar chart above shows that the dataset is moderately skewed toward
Perceiving over Judging.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}18}]:} \PY{c+c1}{\PYZsh{} Subset the posts column for further exploration}
         \PY{n}{posts} \PY{o}{=} \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{posts}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{copy}\PY{p}{(}\PY{p}{)}
         \PY{n}{posts} \PY{o}{=} \PY{n}{posts}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{x}\PY{o}{.}\PY{n}{replace}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{|||}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ }\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)} \PY{c+c1}{\PYZsh{} replaces post separators with empty space}
         \PY{n}{posts}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}18}]:} 0    'http://www.youtube.com/watch?v=qsXHcwe3krw ht{\ldots}
         1    'I'm finding the lack of me in these posts ver{\ldots}
         2    'Good one  \_\_\_\_\_   https://www.youtube.com/wat{\ldots}
         3    'Dear INTP,   I enjoyed our conversation the o{\ldots}
         4    'You're fired. That's another silly misconcept{\ldots}
         Name: posts, dtype: object
\end{Verbatim}
            
    \textbf{CountVectorizer}

\emph{CountVectorizer} encodes text by splitting a set of words into one
column per word, with (by default) the count of the word for that row in
that column.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}19}]:} \PY{c+c1}{\PYZsh{} Run an initial CountVectorizer with default settings on the posts column to see what\PYZsq{}s there}
         \PY{n}{cv} \PY{o}{=} \PY{n}{CountVectorizer}\PY{p}{(}\PY{p}{)}
         \PY{n}{cv}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{posts}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}19}]:} <8675x145412 sparse matrix of type '<class 'numpy.int64'>'
         	with 4516646 stored elements in Compressed Sparse Row format>
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}20}]:} \PY{c+c1}{\PYZsh{} Convert the output of the transformation to a dense matrix}
         \PY{n}{cv}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{posts}\PY{p}{)}\PY{o}{.}\PY{n}{todense}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}20}]:} matrix([[0, 0, 0, {\ldots}, 0, 0, 0],
                 [0, 1, 0, {\ldots}, 0, 0, 0],
                 [0, 0, 0, {\ldots}, 0, 0, 0],
                 {\ldots},
                 [0, 0, 0, {\ldots}, 0, 0, 0],
                 [0, 0, 0, {\ldots}, 0, 0, 0],
                 [0, 0, 0, {\ldots}, 0, 0, 0]], dtype=int64)
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}21}]:} \PY{c+c1}{\PYZsh{} Convert to a dataframe to get feature names and see the distribution of words}
         \PY{n}{df\PYZus{}posts} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{cv}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{posts}\PY{p}{)}\PY{o}{.}\PY{n}{todense}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{columns}\PY{o}{=}\PY{n}{cv}\PY{o}{.}\PY{n}{get\PYZus{}feature\PYZus{}names}\PY{p}{(}\PY{p}{)}\PY{p}{)}
         \PY{n}{df\PYZus{}posts}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}21}]:}    00  000  0000  000000  0000000000  000000000000000  \textbackslash{}
         0   0    0     0       0           0                0   
         1   0    1     0       0           0                0   
         2   0    0     0       0           0                0   
         3   0    0     0       0           0                0   
         4   0    0     0       0           0                0   
         
            00000000000000000000000000000000027  00000011  000000111  0000001111 {\ldots}  \textbackslash{}
         0                                    0         0          0           0 {\ldots}   
         1                                    0         0          0           0 {\ldots}   
         2                                    0         0          0           0 {\ldots}   
         3                                    0         0          0           0 {\ldots}   
         4                                    0         0          0           0 {\ldots}   
         
            ｓｏ  ｔｒｕｍｐu3000ｉｓu3000ａｎu3000ｅｓｔｐ  ｖａｐｏｒｗａｖｅ  \textbackslash{}
         0   0                             0          0   
         1   0                             0          0   
         2   0                             0          0   
         3   0                             0          0   
         4   0                             0          0   
         
            ｗｈｙu3000ｉｓu3000ａｎｙｏｎｅu3000ｓｔｉｌｌu3000ｄｉｓｃｕｓｓｉｎｇu3000ｔｈｉｓ  ﾉωﾉ  ﾉｼ  ﾉﾞ  ﾉﾟ  \textbackslash{}
         0                                                  0          0   0   0   0   
         1                                                  0          0   0   0   0   
         2                                                  0          0   0   0   0   
         3                                                  0          0   0   0   0   
         4                                                  0          0   0   0   0   
         
            ﾟдﾟщ  ﾟﾟ  
         0     0   0  
         1     0   0  
         2     0   0  
         3     0   0  
         4     0   0  
         
         [5 rows x 145412 columns]
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}22}]:} \PY{c+c1}{\PYZsh{} Examine shape after creation of columns}
         \PY{n}{df\PYZus{}posts}\PY{o}{.}\PY{n}{shape}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}22}]:} (8675, 145412)
\end{Verbatim}
            
    CountVectorizer created 145,412 columns from the single \emph{posts}
column.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}23}]:} \PY{c+c1}{\PYZsh{} Examine the top 10 occurring words}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{df\PYZus{}posts}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{sort\PYZus{}values}\PY{p}{(}\PY{n}{ascending}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{l+m+mi}{10}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
the     309589
to      305454
and     244200
you     187937
it      186462
of      185941
that    163696
is      140673
in      131749
my      126883
dtype: int64

    \end{Verbatim}

    Initial observations on the data in the \emph{posts} column, after the
first CountVectorizer pass:

The top 10 words are common and non-subject-specific words which appear
in the stopwords list. There are also 145,412 columns. We need to rerun
CountVectorizer and add some arguments to whittle down the list.

    \paragraph{Add Words to the Stopwords
List}\label{add-words-to-the-stopwords-list}

\emph{stopwords} eliminates common words that add no information to the
text content, or can bias a model.

Since the posts were obtained from a site specifically geared toward the
topic of personality type, it is possible that the subjects have been
primed to behave in a way that conforms to the characteristics of their
defined personality type. It is noted that some subjects reference their
(or others') personality type code within some of the posts. Thus, these
codes are excluded to avoid biasing the model (e.g. specific references
to the 4-letter code).

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}24}]:} \PY{c+c1}{\PYZsh{} Add to the stopwords list each of the 16 codes}
         \PY{n}{types} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{infj}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{entp}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{intp}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{intj}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{entj}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{enfj}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{infp}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{enfp}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{isfp}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PYZbs{}
                  \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{istp}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{isfj}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{istj}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{estp}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{esfp}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{estj}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{esfj}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
         \PY{n}{stop} \PY{o}{=} \PY{n}{stopwords}\PY{o}{.}\PY{n}{words}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{english}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         
         \PY{k}{for} \PY{n+nb}{type} \PY{o+ow}{in} \PY{n}{types}\PY{p}{:}
             \PY{n}{stop}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n+nb}{type}\PY{p}{)}
         
         \PY{n}{stop\PYZus{}rev} \PY{o}{=} \PY{n}{stop}    
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{stop\PYZus{}rev}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', "you're", "you've", "you'll", "you'd", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', "she's", 'her', 'hers', 'herself', 'it', "it's", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', "that'll", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', "don't", 'should', "should've", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', "aren't", 'couldn', "couldn't", 'didn', "didn't", 'doesn', "doesn't", 'hadn', "hadn't", 'hasn', "hasn't", 'haven', "haven't", 'isn', "isn't", 'ma', 'mightn', "mightn't", 'mustn', "mustn't", 'needn', "needn't", 'shan', "shan't", 'shouldn', "shouldn't", 'wasn', "wasn't", 'weren', "weren't", 'won', "won't", 'wouldn', "wouldn't", 'infj', 'entp', 'intp', 'intj', 'entj', 'enfj', 'infp', 'enfp', 'isfp', 'istp', 'isfj', 'istj', 'estp', 'esfp', 'estj', 'esfj']

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}25}]:} \PY{c+c1}{\PYZsh{} Rerun CountVectorizer to exclude stopwords, allow 2\PYZhy{}word pairs, and limit the number of columns to 1000}
         \PY{n}{cv} \PY{o}{=} \PY{n}{CountVectorizer}\PY{p}{(}\PY{n}{stop\PYZus{}words}\PY{o}{=}\PY{n}{stop\PYZus{}rev}\PY{p}{,} \PY{n}{ngram\PYZus{}range}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{)}\PY{p}{,} \PY{n}{max\PYZus{}features}\PY{o}{=}\PY{l+m+mi}{1000}\PY{p}{)}
         \PY{n}{cv}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{posts}\PY{p}{)}
         \PY{n}{cv}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{posts}\PY{p}{)}
         
         \PY{n}{cv}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{posts}\PY{p}{)}\PY{o}{.}\PY{n}{todense}\PY{p}{(}\PY{p}{)}
         \PY{n}{df\PYZus{}posts} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{cv}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{posts}\PY{p}{)}\PY{o}{.}\PY{n}{todense}\PY{p}{(}\PY{p}{)}\PY{p}{,} 
                      \PY{n}{columns}\PY{o}{=}\PY{n}{cv}\PY{o}{.}\PY{n}{get\PYZus{}feature\PYZus{}names}\PY{p}{(}\PY{p}{)}\PY{p}{)}
         \PY{n}{df\PYZus{}posts}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}25}]:}    10  100  12  15  20  30  50  ability  able  absolutely     {\ldots}       \textbackslash{}
         0   0    0   0   0   1   0   1        0     0           0     {\ldots}        
         1   1    0   0   0   0   0   0        0     1           0     {\ldots}        
         2   1    0   0   0   0   1   0        2     1           2     {\ldots}        
         3   0    0   0   0   0   0   1        0     2           0     {\ldots}        
         4   0    0   0   0   0   0   0        0     0           0     {\ldots}        
         
            years ago  yep  yes  yesterday  yet  young  younger  youtu  youtube  \textbackslash{}
         0          1    1    0          0    0      0        0      0       16   
         1          0    0    0          0    0      0        0      0        1   
         2          0    0    1          0    0      0        0      0        3   
         3          0    0    0          0    0      0        0      0        2   
         4          0    0    2          0    0      0        0      2        1   
         
            youtube com  
         0           16  
         1            1  
         2            3  
         3            2  
         4            1  
         
         [5 rows x 1000 columns]
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}26}]:} \PY{n}{df\PYZus{}posts}\PY{o}{.}\PY{n}{shape}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}26}]:} (8675, 1000)
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}27}]:} \PY{c+c1}{\PYZsh{} Examine the top 10 occuring words in this round of CountVectorizer}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{df\PYZus{}posts}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{sort\PYZus{}values}\PY{p}{(}\PY{n}{ascending}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{l+m+mi}{10}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
like      69706
think     49847
people    47908
one       37232
know      36950
really    35305
would     35035
get       30822
time      27628
com       25869
dtype: int64

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}28}]:} \PY{c+c1}{\PYZsh{} Define a preprocessor function to clean the text by grouping into stems, removing separators, }
         \PY{c+c1}{\PYZsh{} replacing hyperlinks, removing punctuation, removing digits, and convert letters to lower case}
         
         \PY{k}{def} \PY{n+nf}{cleaner}\PY{p}{(}\PY{n}{text}\PY{p}{)}\PY{p}{:}
             \PY{n}{stemmer} \PY{o}{=} \PY{n}{PorterStemmer}\PY{p}{(}\PY{p}{)}                                        \PY{c+c1}{\PYZsh{} groups words having the same stems}
             \PY{n}{text} \PY{o}{=} \PY{n}{text}\PY{o}{.}\PY{n}{replace}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{|||}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ }\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}                                  \PY{c+c1}{\PYZsh{} replaces post separators with empty space}
             \PY{n}{text} \PY{o}{=} \PY{n}{re}\PY{o}{.}\PY{n}{sub}\PY{p}{(}\PY{l+s+sa}{r}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZbs{}}\PY{l+s+s1}{bhttps?:}\PY{l+s+s1}{\PYZbs{}}\PY{l+s+s1}{/}\PY{l+s+s1}{\PYZbs{}}\PY{l+s+s1}{/.*?[}\PY{l+s+s1}{\PYZbs{}}\PY{l+s+s1}{r}\PY{l+s+s1}{\PYZbs{}}\PY{l+s+s1}{n]*? }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{URL }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{text}\PY{p}{,} \PY{n}{flags}\PY{o}{=}\PY{n}{re}\PY{o}{.}\PY{n}{MULTILINE}\PY{p}{)}  \PY{c+c1}{\PYZsh{} replace hyperlink with \PYZsq{}URL\PYZsq{}}
             \PY{n}{text} \PY{o}{=} \PY{n}{text}\PY{o}{.}\PY{n}{translate}\PY{p}{(}\PY{n+nb}{str}\PY{o}{.}\PY{n}{maketrans}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{string}\PY{o}{.}\PY{n}{punctuation}\PY{p}{)}\PY{p}{)} \PY{c+c1}{\PYZsh{} removes punctuation}
             \PY{n}{text} \PY{o}{=} \PY{n}{text}\PY{o}{.}\PY{n}{translate}\PY{p}{(}\PY{n+nb}{str}\PY{o}{.}\PY{n}{maketrans}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{string}\PY{o}{.}\PY{n}{digits}\PY{p}{)}\PY{p}{)}      \PY{c+c1}{\PYZsh{} removes digits}
             \PY{n}{text} \PY{o}{=} \PY{n}{text}\PY{o}{.}\PY{n}{lower}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{strip}\PY{p}{(}\PY{p}{)}                                      \PY{c+c1}{\PYZsh{} convert to lower case}
             \PY{n}{final\PYZus{}text} \PY{o}{=} \PY{p}{[}\PY{p}{]}
             \PY{k}{for} \PY{n}{w} \PY{o+ow}{in} \PY{n}{text}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{p}{)}\PY{p}{:}
                 \PY{k}{if} \PY{n}{w} \PY{o+ow}{not} \PY{o+ow}{in} \PY{n}{stop}\PY{p}{:}
                     \PY{n}{final\PYZus{}text}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{stemmer}\PY{o}{.}\PY{n}{stem}\PY{p}{(}\PY{n}{w}\PY{o}{.}\PY{n}{strip}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{)}
             \PY{k}{return} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ }\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{final\PYZus{}text}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}29}]:} \PY{c+c1}{\PYZsh{} View original text to confirm the cleaner is working properly}
         \PY{n}{df}\PY{o}{.}\PY{n}{posts}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}29}]:} "'http://www.youtube.com/watch?v=qsXHcwe3krw|||http://41.media.tumblr.com/tumblr\_lfouy03PMA1qa1rooo1\_500.jpg|||enfp and intj moments  https://www.youtube.com/watch?v=iz7lE1g4XM4  sportscenter not top ten plays  https://www.youtube.com/watch?v=uCdfze1etec  pranks|||What has been the most life-changing experience in your life?|||http://www.youtube.com/watch?v=vXZeYwwRDw8   http://www.youtube.com/watch?v=u8ejam5DP3E  On repeat for most of today.|||May the PerC Experience immerse you.|||The last thing my INFJ friend posted on his facebook before committing suicide the next day. Rest in peace\textasciitilde{}   http://vimeo.com/22842206|||Hello ENFJ7. Sorry to hear of your distress. It's only natural for a relationship to not be perfection all the time in every moment of existence. Try to figure the hard times as times of growth, as{\ldots}|||84389  84390  http://wallpaperpassion.com/upload/23700/friendship-boy-and-girl-wallpaper.jpg  http://assets.dornob.com/wp-content/uploads/2010/04/round-home-design.jpg {\ldots}|||Welcome and stuff.|||http://playeressence.com/wp-content/uploads/2013/08/RED-red-the-pokemon-master-32560474-450-338.jpg  Game. Set. Match.|||Prozac, wellbrutin, at least thirty minutes of moving your legs (and I don't mean moving them while sitting in your same desk chair), weed in moderation (maybe try edibles as a healthier alternative{\ldots}|||Basically come up with three items you've determined that each type (or whichever types you want to do) would more than likely use, given each types' cognitive functions and whatnot, when left by{\ldots}|||All things in moderation.  Sims is indeed a video game, and a good one at that. Note: a good one at that is somewhat subjective in that I am not completely promoting the death of any given Sim{\ldots}|||Dear ENFP:  What were your favorite video games growing up and what are your now, current favorite video games? :cool:|||https://www.youtube.com/watch?v=QyPqT8umzmY|||It appears to be too late. :sad:|||There's someone out there for everyone.|||Wait{\ldots} I thought confidence was a good thing.|||I just cherish the time of solitude b/c i revel within my inner world more whereas most other time i'd be workin{\ldots} just enjoy the me time while you can. Don't worry, people will always be around to{\ldots}|||Yo entp ladies{\ldots} if you're into a complimentary personality,well, hey.|||{\ldots} when your main social outlet is xbox live conversations and even then you verbally fatigue quickly.|||http://www.youtube.com/watch?v=gDhy7rdfm14  I really dig the part from 1:46 to 2:50|||http://www.youtube.com/watch?v=msqXffgh7b8|||Banned because this thread requires it of me.|||Get high in backyard, roast and eat marshmellows in backyard while conversing over something intellectual, followed by massages and kisses.|||http://www.youtube.com/watch?v=Mw7eoU3BMbE|||http://www.youtube.com/watch?v=4V2uYORhQOk|||http://www.youtube.com/watch?v=SlVmgFQQ0TI|||Banned for too many b's in that sentence. How could you! Think of the B!|||Banned for watching movies in the corner with the dunces.|||Banned because Health class clearly taught you nothing about peer pressure.|||Banned for a whole host of reasons!|||http://www.youtube.com/watch?v=IRcrv41hgz4|||1) Two baby deer on left and right munching on a beetle in the middle.  2) Using their own blood, two cavemen diary today's latest happenings on their designated cave diary wall.  3) I see it as{\ldots}|||a pokemon world  an infj society  everyone becomes an optimist|||49142|||http://www.youtube.com/watch?v=ZRCEq\_JFeFM|||http://discovermagazine.com/2012/jul-aug/20-things-you-didnt-know-about-deserts/desert.jpg|||http://oyster.ignimgs.com/mediawiki/apis.ign.com/pokemon-silver-version/d/dd/Ditto.gif|||http://www.serebii.net/potw-dp/Scizor.jpg|||Not all artists are artists because they draw. It's the idea that counts in forming something of your own{\ldots} like a signature.|||Welcome to the robot ranks, person who downed my self-esteem cuz I'm not an avid signature artist like herself. :proud:|||Banned for taking all the room under my bed. Ya gotta learn to share with the roaches.|||http://www.youtube.com/watch?v=w8IgImn57aQ|||Banned for being too much of a thundering, grumbling kind of storm{\ldots} yep.|||Ahh{\ldots} old high school music I haven't heard in ages.   http://www.youtube.com/watch?v=dcCRUPCdB1w|||I failed a public speaking class a few years ago and I've sort of learned what I could do better were I to be in that position again. A big part of my failure was just overloading myself with too{\ldots}|||I like this person's mentality. He's a confirmed INTJ by the way. http://www.youtube.com/watch?v=hGKLI-GEc6M|||Move to the Denver area and start a new life for myself.'"
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}30}]:} \PY{c+c1}{\PYZsh{} view cleaned text}
         \PY{n}{cleaner}\PY{p}{(}\PY{n}{df}\PY{o}{.}\PY{n}{posts}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}30}]:} 'url url moment url sportscent top ten play url prank lifechang experi life url url repeat today may perc experi immers last thing friend post facebook commit suicid next day rest peac url hello sorri hear distress natur relationship perfect time everi moment exist tri figur hard time time growth url url welcom stuff url game set match prozac wellbrutin least thirti minut move leg dont mean move sit desk chair weed moder mayb tri edibl healthier altern basic come three item youv determin type whichev type want would like use given type cognit function whatnot left thing moder sim inde video game good one note good one somewhat subject complet promot death given sim dear favorit video game grow current favorit video game cool url appear late sad there someon everyon wait thought confid good thing cherish time solitud bc revel within inner world wherea time id workin enjoy time dont worri peopl alway around yo ladi your complimentari personalitywel hey main social outlet xbox live convers even verbal fatigu quickli url realli dig part url ban thread requir get high backyard roast eat marshmellow backyard convers someth intellectu follow massag kiss url url url ban mani bs sentenc could think b ban watch movi corner dunc ban health class clearli taught noth peer pressur ban whole host reason url two babi deer left right munch beetl middl use blood two cavemen diari today latest happen design cave diari wall see pokemon world societi everyon becom optimist url url url url artist artist draw idea count form someth like signatur welcom robot rank person down selfesteem cuz im avid signatur artist like proud ban take room bed ya gotta learn share roach url ban much thunder grumbl kind storm yep ahh old high school music havent heard age url fail public speak class year ago ive sort learn could better posit big part failur overload like person mental he confirm way url move denver area start new life'
\end{Verbatim}
            
    Viewing the cleaned text confirms that text was grouped into stems,
\textbar{}\textbar{}\textbar{} separators removed, hyperlinks replaced,
punctuation removed, digits removed, and letters converted to lower case

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}31}]:} \PY{n}{cv}\PY{o}{.}\PY{n}{vocabulary\PYZus{}}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}31}]:} \{'http': 397,
          'www': 983,
          'youtube': 998,
          'com': 130,
          'watch': 936,
          'media': 539,
          'tumblr': 899,
          'jpg': 445,
          'https': 399,
          'top': 885,
          'life': 481,
          'experience': 255,
          'today': 880,
          'may': 532,
          'perc': 634,
          'last': 463,
          'thing': 862,
          'friend': 308,
          'posted': 663,
          'facebook': 264,
          'next': 582,
          'day': 173,
          'rest': 717,
          'hello': 374,
          'sorry': 794,
          'hear': 370,
          'natural': 570,
          'relationship': 707,
          'time': 876,
          'every': 244,
          'moment': 554,
          'try': 897,
          'figure': 288,
          'hard': 366,
          'times': 877,
          'friendship': 310,
          'girl': 331,
          'content': 149,
          'home': 388,
          'welcome': 946,
          'stuff': 827,
          'red': 704,
          'game': 320,
          'set': 752,
          'least': 474,
          'minutes': 551,
          'moving': 565,
          'mean': 535,
          'maybe': 533,
          'basically': 70,
          'come': 132,
          'three': 874,
          'type': 903,
          'types': 905,
          'want': 932,
          'would': 974,
          'likely': 485,
          'use': 916,
          'given': 335,
          'cognitive': 126,
          'functions': 317,
          'left': 476,
          'things': 863,
          'indeed': 419,
          'video': 924,
          'good': 345,
          'one': 606,
          'note': 592,
          'somewhat': 789,
          'completely': 140,
          'death': 178,
          'dear': 177,
          'favorite': 274,
          'games': 321,
          'current': 164,
          'cool': 153,
          'late': 464,
          'sad': 727,
          'someone': 784,
          'everyone': 245,
          'wait': 928,
          'thought': 870,
          'within': 956,
          'world': 969,
          'enjoy': 233,
          'worry': 970,
          'people': 630,
          'always': 31,
          'around': 50,
          'personality': 639,
          'well': 947,
          'hey': 379,
          'main': 519,
          'social': 780,
          'live': 494,
          'conversations': 152,
          'even': 240,
          'quickly': 683,
          'really': 698,
          'part': 623,
          '50': 6,
          'thread': 872,
          'get': 326,
          'high': 381,
          'eat': 218,
          'something': 786,
          'many': 527,
          'could': 155,
          'think': 865,
          'watching': 938,
          'movies': 564,
          'class': 121,
          'clearly': 123,
          'nothing': 593,
          'whole': 953,
          'reasons': 702,
          'two': 902,
          'right': 720,
          'middle': 547,
          'using': 919,
          'see': 738,
          'society': 781,
          '20': 4,
          'know': 455,
          'gif': 330,
          'net': 579,
          'idea': 408,
          'like': 483,
          'person': 637,
          'self': 745,
          'proud': 675,
          'taking': 843,
          'room': 723,
          'bed': 73,
          'ya': 986,
          'learn': 471,
          'share': 755,
          'much': 566,
          'kind': 451,
          'yep': 991,
          'old': 604,
          'school': 733,
          'music': 567,
          'heard': 371,
          'public': 677,
          'speaking': 804,
          'years': 989,
          'ago': 22,
          'sort': 795,
          'learned': 472,
          'better': 79,
          'big': 80,
          'way': 940,
          'move': 562,
          'start': 810,
          'new': 581,
          'http www': 398,
          'www youtube': 984,
          'youtube com': 999,
          'com watch': 131,
          'https www': 400,
          'jpg http': 446,
          'cognitive functions': 127,
          'something like': 787,
          'high school': 382,
          'years ago': 990,
          'finding': 291,
          'lack': 460,
          'posts': 665,
          'sex': 754,
          'boring': 88,
          'often': 600,
          'example': 251,
          'girlfriend': 332,
          'currently': 165,
          'enough': 235,
          'giving': 337,
          'meaning': 536,
          'theory': 861,
          'takes': 842,
          'words': 964,
          'hand': 358,
          'eye': 261,
          'real': 693,
          'test': 855,
          'score': 735,
          'internet': 433,
          'tests': 856,
          'funny': 318,
          'mention': 543,
          'believe': 76,
          'site': 772,
          'year': 988,
          'half': 357,
          'find': 290,
          'still': 816,
          'ideas': 409,
          'thoughts': 871,
          'us': 915,
          'sometimes': 788,
          'go': 339,
          'quote': 686,
          'perhaps': 636,
          'man': 526,
          'special': 805,
          'knowledge': 457,
          'rather': 690,
          'post': 662,
          'never': 580,
          'ne': 573,
          'ti': 875,
          'fe': 275,
          'emotions': 227,
          'rarely': 689,
          'si': 762,
          'also': 29,
          'ni': 584,
          'due': 212,
          'though': 869,
          'saying': 731,
          'happens': 364,
          'playing': 653,
          'first': 293,
          'back': 67,
          'drive': 210,
          'look': 503,
          'rock': 721,
          'best': 77,
          'makes': 522,
          'lol': 499,
          'guys': 352,
          'system': 839,
          'hell': 373,
          'sound': 797,
          'put': 679,
          'couple': 157,
          'aware': 63,
          'se': 736,
          'entps': 237,
          'admit': 18,
          'heart': 372,
          'noticed': 595,
          'known': 458,
          'away': 64,
          'anything': 44,
          'style': 829,
          'great': 348,
          'song': 791,
          'long': 500,
          'mental': 542,
          'love': 515,
          'close': 124,
          'movie': 563,
          'normally': 591,
          'played': 652,
          'books': 86,
          'said': 728,
          'looked': 505,
          'except': 252,
          'called': 100,
          'png': 656,
          'oh': 601,
          'fear': 276,
          'guy': 351,
          'personal': 638,
          'sounds': 799,
          'pretty': 668,
          'going': 342,
          'trying': 898,
          'take': 840,
          'problem': 672,
          'female': 285,
          'okay': 603,
          'help': 375,
          'friends': 309,
          'developed': 193,
          'little': 493,
          'described': 189,
          'living': 496,
          'worst': 972,
          'place': 648,
          'perfect': 635,
          'hurt': 406,
          'tell': 849,
          'traits': 890,
          'list': 489,
          'seems': 742,
          'came': 101,
          'bad': 68,
          'already': 28,
          'infjs': 422,
          'however': 396,
          'make': 521,
          'deal': 176,
          'easy': 217,
          'intps': 435,
          'identify': 410,
          'imagine': 414,
          'bit': 81,
          'car': 103,
          'trust': 895,
          'weird': 945,
          'ones': 608,
          'laughing': 468,
          'running': 726,
          'leave': 475,
          'work': 965,
          'mine': 550,
          'meet': 540,
          'damn': 169,
          'need': 575,
          'say': 730,
          'advice': 19,
          'able': 8,
          'knew': 454,
          'give': 334,
          'awesome': 65,
          'correct': 154,
          'stupid': 828,
          'play': 651,
          'laugh': 467,
          'stay': 814,
          '10': 0,
          'opinion': 612,
          'difficult': 197,
          'intjs': 434,
          'situations': 774,
          'random': 687,
          'open': 611,
          'glad': 338,
          'thanks': 859,
          'made': 518,
          'several': 753,
          'hours': 394,
          'line': 487,
          'avatar': 60,
          'later': 466,
          'fellow': 283,
          'keep': 447,
          'pretty much': 669,
          'sounds like': 800,
          'course': 158,
          'absolutely': 9,
          'positive': 659,
          'amazing': 32,
          'yes': 992,
          'case': 106,
          'feelings': 281,
          'thank': 858,
          'link': 488,
          'topic': 886,
          'stuck': 824,
          'mind': 549,
          'feels': 282,
          'truly': 894,
          'terrible': 854,
          'different': 196,
          'ever': 243,
          'incredibly': 418,
          'accurate': 11,
          'beautiful': 71,
          'description': 190,
          'highly': 383,
          'doubt': 206,
          'hi': 380,
          'sit': 771,
          '30': 5,
          'writing': 979,
          'songs': 792,
          'together': 881,
          'seen': 744,
          'entire': 236,
          'human': 404,
          'working': 967,
          'felt': 284,
          'read': 691,
          'book': 85,
          'started': 811,
          'stories': 818,
          'recently': 703,
          'interested': 430,
          'works': 968,
          'probably': 671,
          'upon': 913,
          'sense': 746,
          'humor': 405,
          'touch': 888,
          'thinks': 868,
          'true': 893,
          'fact': 265,
          'face': 263,
          'actually': 16,
          'likes': 486,
          'hugs': 403,
          'mentioned': 544,
          'head': 368,
          'pictures': 647,
          'night': 586,
          'morning': 559,
          'order': 615,
          'hope': 391,
          'sleep': 775,
          'anyway': 45,
          'wondering': 962,
          'issue': 441,
          'name': 569,
          'response': 716,
          'helpful': 377,
          'finally': 289,
          'bored': 87,
          'decide': 180,
          'food': 300,
          'understand': 907,
          'angry': 34,
          'quite': 685,
          'somewhere': 790,
          'else': 223,
          'feeling': 280,
          'liked': 484,
          'comfortable': 134,
          'women': 959,
          'ability': 7,
          'worked': 966,
          'change': 112,
          'results': 719,
          'extremely': 259,
          'online': 609,
          'language': 461,
          'study': 825,
          'interesting': 431,
          'problems': 673,
          'important': 417,
          'specific': 806,
          'must': 568,
          'show': 759,
          'best friend': 78,
          'conversation': 151,
          'nature': 572,
          'none': 589,
          'deep': 182,
          'ways': 941,
          'depends': 185,
          'individual': 420,
          'everything': 246,
          'either': 222,
          'action': 14,
          'particularly': 625,
          'introverted': 437,
          'personally': 641,
          'alone': 26,
          'wish': 955,
          'another': 37,
          'means': 537,
          'others': 617,
          'op': 610,
          'fi': 286,
          'disagree': 198,
          'mother': 561,
          'similar': 765,
          'sure': 835,
          'let': 478,
          'wow': 977,
          'nobody': 587,
          'got': 346,
          'knows': 459,
          'necessarily': 574,
          'fine': 292,
          'lately': 465,
          'break': 93,
          'comes': 133,
          'definitely': 183,
          'business': 97,
          'talk': 844,
          'yeah': 987,
          'lot': 511,
          'longer': 502,
          'te': 847,
          'whether': 951,
          'mom': 553,
          'fun': 315,
          'dark': 170,
          'logic': 497,
          'series': 749,
          'reading': 692,
          'edit': 220,
          'far': 271,
          'appreciate': 47,
          'level': 479,
          'certain': 109,
          'god': 340,
          'useful': 918,
          'wanna': 931,
          'ended': 229,
          'dislike': 200,
          'normal': 590,
          'mbti': 534,
          'common': 137,
          'sx': 838,
          'seriously': 751,
          'mostly': 560,
          'emotional': 225,
          'answer': 38,
          'argument': 49,
          'second': 737,
          'single': 769,
          'happy': 365,
          'assume': 56,
          'process': 674,
          'generally': 325,
          'view': 925,
          'seem': 740,
          'wanted': 933,
          'almost': 25,
          'bother': 90,
          'asking': 54,
          'intuitive': 439,
          'decided': 181,
          'done': 204,
          'picture': 646,
          'asked': 53,
          'point': 657,
          'actual': 15,
          'math': 530,
          'literally': 492,
          'saw': 729,
          'silly': 764,
          'rare': 688,
          'whatever': 949,
          'lives': 495,
          'agree': 23,
          'wanting': 934,
          'long time': 501,
          'would say': 976,
          'makes sense': 523,
          'even though': 241,
          'wants': 935,
          'super': 831,
          'ass': 55,
          'listen': 490,
          'months': 557,
          'crazy': 159,
          'gone': 343,
          'lost': 510,
          'shit': 757,
          'taken': 841,
          'gave': 322,
          'happened': 363,
          'woman': 958,
          'possible': 660,
          'youtu': 997,
          'went': 948,
          'married': 529,
          'forum': 303,
          'question': 681,
          'ask': 52,
          'approach': 48,
          'college': 129,
          'month': 556,
          'making': 524,
          'dead': 175,
          'xd': 985,
          'men': 541,
          'dream': 207,
          'ha': 353,
          'thinking': 867,
          'brain': 92,
          'effort': 221,
          'understanding': 908,
          'value': 922,
          'instead': 426,
          'children': 118,
          'cry': 162,
          'drink': 209,
          'sweet': 837,
          'water': 939,
          'images': 413,
          'healthy': 369,
          'interest': 429,
          'terms': 853,
          'cannot': 102,
          'without': 957,
          'involved': 440,
          'worth': 973,
          'debate': 179,
          'vs': 927,
          'religion': 709,
          'eating': 219,
          'evil': 247,
          'hands': 360,
          'term': 852,
          'questions': 682,
          'negative': 578,
          'fuck': 312,
          'reason': 701,
          'hate': 367,
          'five': 296,
          'parents': 622,
          'wrong': 981,
          'energy': 230,
          'end': 228,
          'focus': 297,
          'written': 980,
          'met': 546,
          'really like': 700,
          'one thing': 607,
          'people think': 633,
          'science': 734,
          'information': 423,
          'obvious': 598,
          'party': 627,
          'found': 305,
          'although': 30,
          'bring': 94,
          'control': 150,
          'full': 314,
          'word': 963,
          'usually': 921,
          'emotionally': 226,
          'since': 768,
          'avoid': 62,
          'truth': 896,
          'telling': 850,
          'tv': 901,
          'nice': 585,
          'relate': 705,
          'looking': 506,
          'told': 882,
          'respect': 714,
          'choice': 119,
          'stop': 817,
          'cause': 108,
          'lose': 509,
          'power': 666,
          'kill': 450,
          'number': 597,
          'seeing': 739,
          'care': 104,
          'anyone': 42,
          'took': 884,
          'become': 72,
          'light': 482,
          'feel': 278,
          'consider': 144,
          'plan': 650,
          'pick': 645,
          'learning': 473,
          'fall': 268,
          'along': 27,
          'wrote': 982,
          'four': 306,
          'happen': 362,
          'english': 232,
          'degree': 184,
          'dominant': 203,
          'possibly': 661,
          'anxiety': 40,
          'research': 713,
          'tend': 851,
          'simply': 767,
          'expect': 254,
          'state': 813,
          'explain': 257,
          'religious': 710,
          'subject': 830,
          'general': 324,
          'guess': 350,
          'text': 857,
          'apparently': 46,
          'says': 732,
          'father': 273,
          'sister': 770,
          'side': 763,
          'step': 815,
          'brother': 95,
          'needs': 577,
          'follow': 298,
          'think would': 866,
          'people like': 632,
          'real life': 694,
          'haha': 354,
          'past': 628,
          'sharing': 756,
          'future': 319,
          'tongue': 883,
          'values': 923,
          'hold': 387,
          'experiences': 256,
          'older': 605,
          'physical': 644,
          'upset': 914,
          'whenever': 950,
          'helps': 378,
          'original': 616,
          'situation': 773,
          'pay': 629,
          'stand': 809,
          'stress': 822,
          'describe': 188,
          'girls': 333,
          'coming': 135,
          'exact': 249,
          'buy': 98,
          'white': 952,
          'posting': 664,
          'strong': 823,
          'especially': 238,
          'partner': 626,
          'looks': 507,
          'wink': 954,
          'attention': 57,
          'anymore': 41,
          'young': 995,
          'dreams': 208,
          'outside': 619,
          'less': 477,
          'fit': 295,
          'purpose': 678,
          'connection': 143,
          'particular': 624,
          'romantic': 722,
          'boyfriend': 91,
          'first time': 294,
          'people know': 631,
          'lot people': 512,
          'personality type': 640,
          'call': 99,
          'bunch': 96,
          'dont': 205,
          'form': 302,
          'im': 411,
          'free': 307,
          'interests': 432,
          'meant': 538,
          'towards': 889,
          'wonder': 960,
          'act': 13,
          'unsure': 912,
          'add': 17,
          'fight': 287,
          'express': 258,
          'fan': 270,
          'create': 160,
          'check': 116,
          'company': 138,
          'remember': 711,
          'kinda': 452,
          'gets': 328,
          'desire': 192,
          'used': 917,
          'pain': 621,
          'low': 517,
          '15': 3,
          'goes': 341,
          'house': 395,
          'hmm': 386,
          'somehow': 783,
          'huge': 402,
          'soul': 796,
          'would like': 975,
          'seems like': 743,
          'loved': 516,
          'matter': 531,
          'might': 548,
          'voice': 926,
          'getting': 329,
          'naturally': 571,
          'early': 213,
          'body': 84,
          'reality': 695,
          'depression': 187,
          'serious': 750,
          'certainly': 110,
          'easily': 216,
          'worse': 971,
          'feel like': 279,
          'unfortunately': 909,
          'trouble': 892,
          'wear': 942,
          'run': 725,
          'sent': 748,
          'confused': 142,
          'tapatalk': 846,
          'quiet': 684,
          'hair': 356,
          'logical': 498,
          'miss': 552,
          'yet': 994,
          'chance': 111,
          'cat': 107,
          'honest': 389,
          'short': 758,
          'kid': 448,
          'issues': 442,
          'country': 156,
          'attracted': 58,
          'message': 545,
          'helped': 376,
          'mood': 558,
          'job': 443,
          'realize': 696,
          'kitteh': 453,
          'easier': 215,
          'coffee': 125,
          'shows': 760,
          'date': 171,
          'black': 82,
          'lead': 470,
          'considering': 146,
          'prefer': 667,
          'walking': 930,
          'turn': 900,
          'character': 114,
          'teacher': 848,
          'using tapatalk': 920,
          'looks like': 508,
          'look like': 504,
          'things like': 864,
          'dad': 168,
          'gonna': 344,
          '100': 1,
          'days': 174,
          'art': 51,
          'career': 105,
          'inferior': 421,
          'function': 316,
          'age': 21,
          'somebody': 782,
          'spent': 808,
          'enfps': 231,
          'story': 819,
          'sensitive': 747,
          'handle': 359,
          'cold': 128,
          'talking': 845,
          'otherwise': 618,
          'hug': 401,
          'dom': 202,
          'eventually': 242,
          'walk': 929,
          'ok': 602,
          'inside': 425,
          'obviously': 599,
          'family': 269,
          'fair': 266,
          'younger': 996,
          'support': 832,
          'straight': 820,
          'notice': 594,
          'non': 588,
          'nf': 583,
          'slightly': 776,
          'blue': 83,
          'behavior': 74,
          'smart': 778,
          'considered': 145,
          'please': 654,
          'fairly': 267,
          'difference': 195,
          'group': 349,
          'get along': 327,
          'characters': 115,
          'eyes': 262,
          'across': 12,
          'ex': 248,
          'annoying': 36,
          'male': 525,
          'introvert': 436,
          'fucking': 313,
          'supposed': 834,
          'comment': 136,
          'plus': 655,
          'curious': 163,
          'phone': 643,
          'joke': 444,
          'major': 520,
          'choose': 120,
          'sound like': 798,
          'large': 462,
          'relationships': 708,
          'exactly': 250,
          'places': 649,
          'week': 943,
          'clear': 122,
          'attractive': 59,
          'knowing': 456,
          'animals': 35,
          'reply': 712,
          'dating': 172,
          'shy': 761,
          'studying': 826,
          'afraid': 20,
          'result': 718,
          'spend': 807,
          'realized': 697,
          'threads': 873,
          'unless': 911,
          'putting': 680,
          'behind': 75,
          'complete': 139,
          'tired': 878,
          'die': 194,
          'unhealthy': 910,
          'intuition': 438,
          'answers': 39,
          'amount': 33,
          'respond': 715,
          'speak': 803,
          'tried': 891,
          'suppose': 833,
          'contact': 148,
          'awkward': 66,
          'watched': 937,
          'based': 69,
          'pretty sure': 670,
          'gives': 336,
          'simple': 766,
          'nt': 596,
          'forget': 301,
          'changed': 113,
          'opposite': 614,
          'related': 706,
          'imgur': 415,
          'child': 117,
          'smile': 779,
          'discussion': 199,
          'imgur com': 416,
          'etc': 239,
          'totally': 887,
          'money': 555,
          'cut': 166,
          'hour': 393,
          'dude': 211,
          'creative': 161,
          'surprised': 836,
          'wonderful': 961,
          'kids': 449,
          'depressed': 186,
          'dog': 201,
          'write': 978,
          'front': 311,
          'husband': 407,
          'loud': 514,
          'small': 777,
          'honestly': 390,
          'intelligence': 427,
          'accept': 10,
          'needed': 576,
          'rules': 724,
          'someone else': 785,
          'many people': 528,
          'average': 61,
          'yesterday': 993,
          'points': 658,
          'infps': 424,
          'intelligent': 428,
          'enneagram': 234,
          'opinions': 613,
          'ah': 24,
          'strange': 821,
          'extroverted': 260,
          'emotion': 224,
          'image': 412,
          'fast': 272,
          'lazy': 469,
          'history': 384,
          'psychology': 676,
          'descriptions': 191,
          'constantly': 147,
          'forums': 304,
          'feature': 277,
          'born': 89,
          'space': 802,
          'soon': 793,
          'lots': 513,
          'really good': 699,
          'thats': 860,
          'earth': 214,
          'listening': 491,
          '12': 2,
          'computer': 141,
          'gender': 323,
          'starting': 812,
          'anyone else': 43,
          'lie': 480,
          'seemed': 741,
          'perspective': 642,
          'cute': 167,
          'weeks': 944,
          'hit': 385,
          'typing': 906,
          'hot': 392,
          'hahaha': 355,
          'sp': 801,
          'gotten': 347,
          'page': 620,
          'hang': 361,
          'following': 299,
          'typed': 904,
          'title': 879,
          'exist': 253\}
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}32}]:} \PY{c+c1}{\PYZsh{} Run a final CountVectorizer on posts to include the cleaning preprocessor arguments}
         \PY{n}{cv} \PY{o}{=} \PY{n}{CountVectorizer}\PY{p}{(}\PY{n}{preprocessor}\PY{o}{=}\PY{n}{cleaner}\PY{p}{,} \PY{n}{stop\PYZus{}words}\PY{o}{=}\PY{n}{stop\PYZus{}rev}\PY{p}{,} \PY{n}{ngram\PYZus{}range}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{)}\PY{p}{,} \PY{n}{max\PYZus{}features}\PY{o}{=}\PY{l+m+mi}{1000}\PY{p}{)}
         \PY{n}{cv}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{posts}\PY{p}{)}
         
         \PY{n}{cv}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{posts}\PY{p}{)}\PY{o}{.}\PY{n}{todense}\PY{p}{(}\PY{p}{)}
         \PY{n}{df\PYZus{}posts} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{cv}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{posts}\PY{p}{)}\PY{o}{.}\PY{n}{todense}\PY{p}{(}\PY{p}{)}\PY{p}{,} 
                      \PY{n}{columns}\PY{o}{=}\PY{n}{cv}\PY{o}{.}\PY{n}{get\PYZus{}feature\PYZus{}names}\PY{p}{(}\PY{p}{)}\PY{p}{)}
         \PY{n}{df\PYZus{}posts}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}32}]:}    abil  abl  absolut  accept  account  accur  across  act  action  activ  \textbackslash{}
         0     0    0        0       0        0      0       0    0       0      0   
         1     0    1        0       0        0      0       0    0       0      0   
         2     2    1        2       0        0      1       0    0       0      0   
         3     0    2        1       1        0      0       0    0       2      0   
         4     0    0        0       0        0      0       0    0       0      0   
         
            {\ldots}   year old  yep  yesterday  yet  youd  youll  young  younger  youtub  \textbackslash{}
         0  {\ldots}          0    1          0    0     0      0      0        0       0   
         1  {\ldots}          0    0          0    0     0      0      0        0       0   
         2  {\ldots}          0    0          0    0     0      0      0        0       0   
         3  {\ldots}          0    0          0    0     0      1      0        0       0   
         4  {\ldots}          1    0          0    0     0      0      0        0       0   
         
            youv  
         0     1  
         1     0  
         2     0  
         3     2  
         4     0  
         
         [5 rows x 1000 columns]
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}33}]:} \PY{c+c1}{\PYZsh{} Confirm shape}
         \PY{n}{df\PYZus{}posts}\PY{o}{.}\PY{n}{shape}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}33}]:} (8675, 1000)
\end{Verbatim}
            
    The transformed dataset contains 8675 rows and 1000 columns, as
expected.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}34}]:} \PY{c+c1}{\PYZsh{} Examine the top 10 occuring words in this round of CountVectorizer}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{df\PYZus{}posts}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{sort\PYZus{}values}\PY{p}{(}\PY{n}{ascending}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{l+m+mi}{10}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
im        79995
like      75765
think     58275
dont      52778
peopl     47904
one       39656
know      39430
get       38870
feel      37014
realli    35223
dtype: int64

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}35}]:} \PY{c+c1}{\PYZsh{} View the tokens created}
         \PY{k}{with} \PY{n}{pd}\PY{o}{.}\PY{n}{option\PYZus{}context}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{display.max\PYZus{}rows}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{display.max\PYZus{}columns}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{k+kc}{None}\PY{p}{)}\PY{p}{:}
             \PY{n+nb}{print}\PY{p}{(}\PY{n}{df\PYZus{}posts}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
    abil  abl  absolut  accept  account  accur  across  act  action  activ  \textbackslash{}
0      0    0        0       0        0      0       0    0       0      0   
..   {\ldots}  {\ldots}      {\ldots}     {\ldots}      {\ldots}    {\ldots}     {\ldots}  {\ldots}     {\ldots}    {\ldots}   

    actual  add  admit  advic  affect  afraid  age  ago  agre  ah  allow  \textbackslash{}
0        0    0      0      0       0       0    1    1     0   0      0   
..     {\ldots}  {\ldots}    {\ldots}    {\ldots}     {\ldots}     {\ldots}  {\ldots}  {\ldots}   {\ldots}  ..    {\ldots}   

    almost  alon  along  alreadi  also  although  alway  amaz  amount  angri  \textbackslash{}
0        0     0      0        0     0         0      1     0       0      0   
..     {\ldots}   {\ldots}    {\ldots}      {\ldots}   {\ldots}       {\ldots}    {\ldots}   {\ldots}     {\ldots}    {\ldots}   

    anim  annoy  anoth  answer  answer question  anxieti  anymor  anyon  \textbackslash{}
0      0      0      0       0                0        0       0      0   
..   {\ldots}    {\ldots}    {\ldots}     {\ldots}              {\ldots}      {\ldots}     {\ldots}    {\ldots}   

    anyon els  anyth  anyway  apart  apolog  appar  appear  appli  appreci  \textbackslash{}
0           0      0       0      0       0      0       1      0        0   
..        {\ldots}    {\ldots}     {\ldots}    {\ldots}     {\ldots}    {\ldots}     {\ldots}    {\ldots}      {\ldots}   

    approach  area  arent  argu  argument  around  art  articl  artist  ask  \textbackslash{}
0          0     1      0     0         0       1    0       0       3    0   
..       {\ldots}   {\ldots}    {\ldots}   {\ldots}       {\ldots}     {\ldots}  {\ldots}     {\ldots}     {\ldots}  {\ldots}   

    aspect  ass  assum  attempt  attent  attract  avatar  averag  avoid  aw  \textbackslash{}
0        0    0      0        0       0        0       0       0      0   0   
..     {\ldots}  {\ldots}    {\ldots}      {\ldots}     {\ldots}      {\ldots}     {\ldots}     {\ldots}    {\ldots}  ..   

    awar  away  awesom  awkward  babi  back  bad  balanc  base  basic  beauti  \textbackslash{}
0      0     0       0        0     1     0    0       0     0      1       0   
..   {\ldots}   {\ldots}     {\ldots}      {\ldots}   {\ldots}   {\ldots}  {\ldots}     {\ldots}   {\ldots}    {\ldots}     {\ldots}   

    becom  bed  begin  behavior  behind  belief  believ  best  best friend  \textbackslash{}
0       1    1      0         0       0       0       0     0            0   
..    {\ldots}  {\ldots}    {\ldots}       {\ldots}     {\ldots}     {\ldots}     {\ldots}   {\ldots}          {\ldots}   

    better  big  bit  black  blue  bodi  book  bore  born  bother  boy  \textbackslash{}
0        1    1    0      0     0     0     0     0     0       0    0   
..     {\ldots}  {\ldots}  {\ldots}    {\ldots}   {\ldots}   {\ldots}   {\ldots}   {\ldots}   {\ldots}     {\ldots}  {\ldots}   

    boyfriend  brain  break  bring  brother  build  bunch  busi  buy  call  \textbackslash{}
0           0      0      0      0        0      0      0     0    0     0   
..        {\ldots}    {\ldots}    {\ldots}    {\ldots}      {\ldots}    {\ldots}    {\ldots}   {\ldots}  {\ldots}   {\ldots}   

    calm  came  cannot  cant  car  care  career  case  cat  caus  certain  \textbackslash{}
0      0     0       0     0    0     0       0     0    0     0        0   
..   {\ldots}   {\ldots}     {\ldots}   {\ldots}  {\ldots}   {\ldots}     {\ldots}   {\ldots}  {\ldots}   {\ldots}      {\ldots}   

    certainli  challeng  chanc  chang  charact  check  child  children  choic  \textbackslash{}
0           0         0      0      0        0      0      0         0      0   
..        {\ldots}       {\ldots}    {\ldots}    {\ldots}      {\ldots}    {\ldots}    {\ldots}       {\ldots}    {\ldots}   

    choos  christian  citi  claim  class  clean  clear  clearli  close  \textbackslash{}
0       0          0     0      0      2      0      0        1      0   
..    {\ldots}        {\ldots}   {\ldots}    {\ldots}    {\ldots}    {\ldots}    {\ldots}      {\ldots}    {\ldots}   

    close friend  cloth  coffe  cognit  cognit function  cold  colleg  color  \textbackslash{}
0              0      0      0       1                1     0       0      0   
..           {\ldots}    {\ldots}    {\ldots}     {\ldots}              {\ldots}   {\ldots}     {\ldots}    {\ldots}   

    combin  come  comfort  comment  common  commun  compani  compar  complet  \textbackslash{}
0        0     1        0        0       0       0        0       0        1   
..     {\ldots}   {\ldots}      {\ldots}      {\ldots}     {\ldots}     {\ldots}      {\ldots}     {\ldots}      {\ldots}   

    compliment  comput  concept  concern  conclus  confid  conflict  confus  \textbackslash{}
0            0       0        0        0        0       1         0       0   
..         {\ldots}     {\ldots}      {\ldots}      {\ldots}      {\ldots}     {\ldots}       {\ldots}     {\ldots}   

    connect  consid  constantli  contact  continu  control  convers  convinc  \textbackslash{}
0         0       0           0        0        0        0        2        0   
..      {\ldots}     {\ldots}         {\ldots}      {\ldots}      {\ldots}      {\ldots}      {\ldots}      {\ldots}   

    cool  correct  could  couldnt  count  countri  coupl  cours  crazi  creat  \textbackslash{}
0      1        0      2        0      1        0      0      0      0      0   
..   {\ldots}      {\ldots}    {\ldots}      {\ldots}    {\ldots}      {\ldots}    {\ldots}    {\ldots}    {\ldots}    {\ldots}   

    creativ  cri  critic  crush  cultur  curiou  current  cut  cute  dad  \textbackslash{}
0         0    0       0      0       0       0        1    0     0    0   
..      {\ldots}  {\ldots}     {\ldots}    {\ldots}     {\ldots}     {\ldots}      {\ldots}  {\ldots}   {\ldots}  {\ldots}   

    damn  danc  dark  date  day  dead  deal  dear  death  debat  decid  decis  \textbackslash{}
0      0     0     0     0    1     0     0     1      1      0      0      0   
..   {\ldots}   {\ldots}   {\ldots}   {\ldots}  {\ldots}   {\ldots}   {\ldots}   {\ldots}    {\ldots}    {\ldots}    {\ldots}    {\ldots}   

    deep  defin  definit  degre  depend  depress  describ  descript  desir  \textbackslash{}
0      0      0        0      0       0        0        0         0      0   
..   {\ldots}    {\ldots}      {\ldots}    {\ldots}     {\ldots}      {\ldots}      {\ldots}       {\ldots}    {\ldots}   

    detail  develop  didnt  die  differ  difficult  direct  disagre  discov  \textbackslash{}
0        0        0      0    0       0          0       0        0       0   
..     {\ldots}      {\ldots}    {\ldots}  {\ldots}     {\ldots}        {\ldots}     {\ldots}      {\ldots}     {\ldots}   

    discuss  dislik  doesnt  dog  domin  done  dont  dont care  dont even  \textbackslash{}
0         0       0       0    0      0     0     2          0          0   
..      {\ldots}     {\ldots}     {\ldots}  {\ldots}    {\ldots}   {\ldots}   {\ldots}        {\ldots}        {\ldots}   

    dont feel  dont get  dont know  dont like  dont realli  dont see  \textbackslash{}
0           0         0          0          0            0         0   
..        {\ldots}       {\ldots}        {\ldots}        {\ldots}          {\ldots}       {\ldots}   

    dont think  dont understand  dont want  doubt  draw  dream  drink  drive  \textbackslash{}
0            0                0          0      0     1      0      0      0   
..         {\ldots}              {\ldots}        {\ldots}    {\ldots}   {\ldots}    {\ldots}    {\ldots}    {\ldots}   

    drug  dude  due  earli  easi  easier  easili  eat  edit  effect  effort  \textbackslash{}
0      0     0    0      0     0       0       0    1     0       0       0   
..   {\ldots}   {\ldots}  {\ldots}    {\ldots}   {\ldots}     {\ldots}     {\ldots}  {\ldots}   {\ldots}     {\ldots}     {\ldots}   

    either  els  emot  end  energi  english  enjoy  enneagram  enough  entir  \textbackslash{}
0        0    0     0    0       0        0      1          0       0      0   
..     {\ldots}  {\ldots}   {\ldots}  {\ldots}     {\ldots}      {\ldots}    {\ldots}        {\ldots}     {\ldots}    {\ldots}   

    environ  equal  especi  etc  even  even though  event  eventu  ever  \textbackslash{}
0         0      0       0    0     1            0      0       0     0   
..      {\ldots}    {\ldots}     {\ldots}  {\ldots}   {\ldots}          {\ldots}    {\ldots}     {\ldots}   {\ldots}   

    everi  everyon  everyth  evil  ex  exact  exactli  exampl  except  excit  \textbackslash{}
0       1        2        0     0   0      0        0       0       0      0   
..    {\ldots}      {\ldots}      {\ldots}   {\ldots}  ..    {\ldots}      {\ldots}     {\ldots}     {\ldots}    {\ldots}   

    exist  expect  experi  experienc  explain  express  extravert  extrem  \textbackslash{}
0       1       0       2          0        0        0          0       0   
..    {\ldots}     {\ldots}     {\ldots}        {\ldots}      {\ldots}      {\ldots}        {\ldots}     {\ldots}   

    extrovert  eye  face  facebook  fact  fail  fair  fairli  fall  famili  \textbackslash{}
0           0    0     0         1     0     1     0       0     0       0   
..        {\ldots}  {\ldots}   {\ldots}       {\ldots}   {\ldots}   {\ldots}   {\ldots}     {\ldots}   {\ldots}     {\ldots}   

    fan  far  fast  father  favorit  favourit  fe  fear  feel  feel like  \textbackslash{}
0     0    0     0       0        2         0   0     0     0          0   
..  {\ldots}  {\ldots}   {\ldots}     {\ldots}      {\ldots}       {\ldots}  ..   {\ldots}   {\ldots}        {\ldots}   

    fellow  felt  femal  fi  fight  figur  film  final  find  fine  finish  \textbackslash{}
0        0     0      0   0      0      1     0      0     0     0       0   
..     {\ldots}   {\ldots}    {\ldots}  ..    {\ldots}    {\ldots}   {\ldots}    {\ldots}   {\ldots}   {\ldots}     {\ldots}   

    first  first time  fit  five  fix  focu  focus  follow  food  forc  \textbackslash{}
0       0           0    0     0    0     0      0       1     0     0   
..    {\ldots}         {\ldots}  {\ldots}   {\ldots}  {\ldots}   {\ldots}    {\ldots}     {\ldots}   {\ldots}   {\ldots}   

    forget  form  forum  found  four  freak  free  friend  friendship  front  \textbackslash{}
0        0     1      0      0     0      0     0       1           0      0   
..     {\ldots}   {\ldots}    {\ldots}    {\ldots}   {\ldots}    {\ldots}   {\ldots}     {\ldots}         {\ldots}    {\ldots}   

    frustrat  fuck  full  fun  function  funni  futur  game  gave  gender  \textbackslash{}
0          0     0     0    0         1      0      0     4     0       0   
..       {\ldots}   {\ldots}   {\ldots}  {\ldots}       {\ldots}    {\ldots}    {\ldots}   {\ldots}   {\ldots}     {\ldots}   

    gener  genuin  get  get along  gift  girl  girlfriend  give  given  glad  \textbackslash{}
0       0       0    1          0     0     0           0     0      2     0   
..    {\ldots}     {\ldots}  {\ldots}        {\ldots}   {\ldots}   {\ldots}         {\ldots}   {\ldots}    {\ldots}   {\ldots}   

    go  goal  god  goe  gone  gonna  good  got  gotten  grade  great  group  \textbackslash{}
0    0     0    0    0     0      0     3    0       0      0      0      0   
..  ..   {\ldots}  {\ldots}  {\ldots}   {\ldots}    {\ldots}   {\ldots}  {\ldots}     {\ldots}    {\ldots}    {\ldots}    {\ldots}   

    grow  guess  guy  ha  haha  hahaha  hair  half  hand  handl  hang  happen  \textbackslash{}
0      1      0    0   0     0       0     0     0     0      0     0       1   
..   {\ldots}    {\ldots}  {\ldots}  ..   {\ldots}     {\ldots}   {\ldots}   {\ldots}   {\ldots}    {\ldots}   {\ldots}     {\ldots}   

    happi  hard  hate  havent  head  healthi  hear  heard  heart  hell  hello  \textbackslash{}
0       0     1     0       1     0        0     1      1      0     0      1   
..    {\ldots}   {\ldots}   {\ldots}     {\ldots}   {\ldots}      {\ldots}   {\ldots}    {\ldots}    {\ldots}   {\ldots}    {\ldots}   

    help  hey  hi  hide  high  high school  highli  histori  hit  hmm  hold  \textbackslash{}
0      0    1   0     0     2            1       0        0    0    0     0   
..   {\ldots}  {\ldots}  ..   {\ldots}   {\ldots}          {\ldots}     {\ldots}      {\ldots}  {\ldots}  {\ldots}   {\ldots}   

    home  honest  honestli  hope  horribl  hot  hour  hous  howev  hug  huge  \textbackslash{}
0      0       0         0     0        0    0     0     0      0    0     0   
..   {\ldots}     {\ldots}       {\ldots}   {\ldots}      {\ldots}  {\ldots}   {\ldots}   {\ldots}    {\ldots}  {\ldots}   {\ldots}   

    human  humor  hurt  husband  id  id like  id say  idea  ideal  identifi  \textbackslash{}
0       0      0     0        0   1        0       0     1      0         0   
..    {\ldots}    {\ldots}   {\ldots}      {\ldots}  ..      {\ldots}     {\ldots}   {\ldots}    {\ldots}       {\ldots}   

    ignor  ill  im  im go  im pretti  im realli  im sorri  im still  im sure  \textbackslash{}
0       0    0   1      0          0          0         0         0        0   
..    {\ldots}  {\ldots}  ..    {\ldots}        {\ldots}        {\ldots}       {\ldots}       {\ldots}      {\ldots}   

    im tri  imag  imagin  import  impress  includ  incred  inde  individu  \textbackslash{}
0        0     0       0       0        0       0       0     1         0   
..     {\ldots}   {\ldots}     {\ldots}     {\ldots}      {\ldots}     {\ldots}     {\ldots}   {\ldots}       {\ldots}   

    inferior  inform  initi  insid  insight  inspir  instead  intellig  \textbackslash{}
0          0       0      0      0        0       0        0         0   
..       {\ldots}     {\ldots}    {\ldots}    {\ldots}      {\ldots}     {\ldots}      {\ldots}       {\ldots}   

    intens  intent  interact  interest  intern  internet  introvert  intuit  \textbackslash{}
0        0       0         0         0       0         0          0       0   
..     {\ldots}     {\ldots}       {\ldots}       {\ldots}     {\ldots}       {\ldots}        {\ldots}     {\ldots}   

    involv  isnt  issu  ive  ive alway  ive never  ive seen  job  join  joke  \textbackslash{}
0        0     0     0    1          0          0         0    0     0     0   
..     {\ldots}   {\ldots}   {\ldots}  {\ldots}        {\ldots}        {\ldots}       {\ldots}  {\ldots}   {\ldots}   {\ldots}   

    judg  jump  keep  kid  kill  kind  kinda  knew  know  know im  knowledg  \textbackslash{}
0      0     0     0    0     0     1      0     0     0        0         0   
..   {\ldots}   {\ldots}   {\ldots}  {\ldots}   {\ldots}   {\ldots}    {\ldots}   {\ldots}   {\ldots}      {\ldots}       {\ldots}   

    known  lack  languag  larg  last  late  later  laugh  law  lazi  lead  \textbackslash{}
0       0     0        0     0     1     1      0      0    0     0     0   
..    {\ldots}   {\ldots}      {\ldots}   {\ldots}   {\ldots}   {\ldots}    {\ldots}    {\ldots}  {\ldots}   {\ldots}   {\ldots}   

    learn  least  leav  left  less  let  letter  level  lie  life  light  \textbackslash{}
0       2      1     0     2     0    0       0      0    0     2      0   
..    {\ldots}    {\ldots}   {\ldots}   {\ldots}   {\ldots}  {\ldots}     {\ldots}    {\ldots}  {\ldots}   {\ldots}    {\ldots}   

    like  like im  limit  line  link  list  listen  liter  littl  live  logic  \textbackslash{}
0      4        0      0     0     0     0       0      0      0     1      0   
..   {\ldots}      {\ldots}    {\ldots}   {\ldots}   {\ldots}   {\ldots}     {\ldots}    {\ldots}    {\ldots}   {\ldots}    {\ldots}   

    lol  long  long time  longer  look  look like  lose  lost  lot  lot peopl  \textbackslash{}
0     0     0          0       0     0          0     0     0    0          0   
..  {\ldots}   {\ldots}        {\ldots}     {\ldots}   {\ldots}        {\ldots}   {\ldots}   {\ldots}  {\ldots}        {\ldots}   

    loud  love  low  made  main  major  make  make feel  make sens  male  man  \textbackslash{}
0      0     0    0     0     1      0     0          0          0     0    0   
..   {\ldots}   {\ldots}  {\ldots}   {\ldots}   {\ldots}    {\ldots}   {\ldots}        {\ldots}        {\ldots}   {\ldots}  {\ldots}   

    manag  mani  mani peopl  manipul  marri  match  math  matter  matur  may  \textbackslash{}
0       0     1           0        0      0      1     0       0      0    1   
..    {\ldots}   {\ldots}         {\ldots}      {\ldots}    {\ldots}    {\ldots}   {\ldots}     {\ldots}    {\ldots}  {\ldots}   

    mayb  mbti  mean  meant  meet  member  memori  men  mental  mention  mess  \textbackslash{}
0      1     0     1      0     0       0       0    0       1        0     0   
..   {\ldots}   {\ldots}   {\ldots}    {\ldots}   {\ldots}     {\ldots}     {\ldots}  {\ldots}     {\ldots}      {\ldots}   {\ldots}   

    messag  met  middl  might  mind  mine  minut  miss  mistak  mix  mom  \textbackslash{}
0        0    0      1      0     0     0      1     0       0    0    0   
..     {\ldots}  {\ldots}    {\ldots}    {\ldots}   {\ldots}   {\ldots}    {\ldots}   {\ldots}     {\ldots}  {\ldots}  {\ldots}   

    moment  money  month  mood  moral  morn  mostli  mother  motiv  move  \textbackslash{}
0        2      0      0     0      0     0       0       0      0     3   
..     {\ldots}    {\ldots}    {\ldots}   {\ldots}    {\ldots}   {\ldots}     {\ldots}     {\ldots}    {\ldots}   {\ldots}   

    movi  much  music  must  name  natur  ne  necessarili  need  neg  never  \textbackslash{}
0      1     1      1     0     0      1   0            0     0    0      0   
..   {\ldots}   {\ldots}    {\ldots}   {\ldots}   {\ldots}    {\ldots}  ..          {\ldots}   {\ldots}  {\ldots}    {\ldots}   

    new  next  nf  ni  nice  night  nobodi  none  normal  note  noth  notic  \textbackslash{}
0     1     1   0   0     0      0       0     0       0     1     1      0   
..  {\ldots}   {\ldots}  ..  ..   {\ldots}    {\ldots}     {\ldots}   {\ldots}     {\ldots}   {\ldots}   {\ldots}    {\ldots}   

    nt  number  object  observ  obsess  obviou  obvious  odd  offer  often  \textbackslash{}
0    0       0       0       0       0       0        0    0      0      0   
..  ..     {\ldots}     {\ldots}     {\ldots}     {\ldots}     {\ldots}      {\ldots}  {\ldots}    {\ldots}    {\ldots}   

    oh  ok  okay  old  older  one  one thing  onlin  op  open  opinion  \textbackslash{}
0    0   0     0    1      0    2          0      0   0     0        0   
..  ..  ..   {\ldots}  {\ldots}    {\ldots}  {\ldots}        {\ldots}    {\ldots}  ..   {\ldots}      {\ldots}   

    opposit  option  order  organ  origin  otherwis  outsid  page  pain  \textbackslash{}
0         0       0      0      0       0         0       0     0     0   
..      {\ldots}     {\ldots}    {\ldots}    {\ldots}     {\ldots}       {\ldots}     {\ldots}   {\ldots}   {\ldots}   

    parent  part  parti  particular  particularli  partner  pass  passion  \textbackslash{}
0        0     2      0           0             0        0     0        0   
..     {\ldots}   {\ldots}    {\ldots}         {\ldots}           {\ldots}      {\ldots}   {\ldots}      {\ldots}   

    past  pattern  pay  peac  peopl  peopl dont  peopl like  peopl think  \textbackslash{}
0      0        0    0     1      1           0           0            0   
..   {\ldots}      {\ldots}  {\ldots}   {\ldots}    {\ldots}         {\ldots}         {\ldots}          {\ldots}   

    perc  perceiv  perfect  perhap  period  person  person type  perspect  \textbackslash{}
0      1        0        1       0       0       2            0         0   
..   {\ldots}      {\ldots}      {\ldots}     {\ldots}     {\ldots}     {\ldots}          {\ldots}       {\ldots}   

    phone  physic  pick  pictur  piec  piss  place  plan  play  pleas  plu  \textbackslash{}
0       0       0     0       0     0     0      0     0     1      0    0   
..    {\ldots}     {\ldots}   {\ldots}     {\ldots}   {\ldots}   {\ldots}    {\ldots}   {\ldots}   {\ldots}    {\ldots}  {\ldots}   

    point  polit  posit  possibl  post  potenti  power  practic  prefer  \textbackslash{}
0       0      0      1        0     1        0      0        0       0   
..    {\ldots}    {\ldots}    {\ldots}      {\ldots}   {\ldots}      {\ldots}    {\ldots}      {\ldots}     {\ldots}   

    present  pretti  pretti much  pretti sure  probabl  problem  process  \textbackslash{}
0         0       0            0            0        0        0        0   
..      {\ldots}     {\ldots}          {\ldots}          {\ldots}      {\ldots}      {\ldots}      {\ldots}   

    profil  project  proud  provid  psycholog  public  pull  purpos  push  \textbackslash{}
0        0        0      1       0          0       1     0       0     0   
..     {\ldots}      {\ldots}    {\ldots}     {\ldots}        {\ldots}     {\ldots}   {\ldots}     {\ldots}   {\ldots}   

    put  qualiti  question  quickli  quiet  quit  quot  rais  random  rare  \textbackslash{}
0     0        0         0        1      0     0     0     0       0     0   
..  {\ldots}      {\ldots}       {\ldots}      {\ldots}    {\ldots}   {\ldots}   {\ldots}   {\ldots}     {\ldots}   {\ldots}   

    rather  ration  reach  reaction  read  real  real life  realiti  realiz  \textbackslash{}
0        0       0      0         0     0     0          0        0       0   
..     {\ldots}     {\ldots}    {\ldots}       {\ldots}   {\ldots}   {\ldots}        {\ldots}      {\ldots}     {\ldots}   

    realli  realli like  reason  recent  recommend  red  refer  regard  relat  \textbackslash{}
0        1            0       1       0          0    0      0       0      0   
..     {\ldots}          {\ldots}     {\ldots}     {\ldots}        {\ldots}  {\ldots}    {\ldots}     {\ldots}    {\ldots}   

    relationship  religion  rememb  remind  repli  requir  research  respect  \textbackslash{}
0              1         0       0       0      0       1         0        0   
..           {\ldots}       {\ldots}     {\ldots}     {\ldots}    {\ldots}     {\ldots}       {\ldots}      {\ldots}   

    respond  respons  rest  result  right  rock  romant  room  rule  run  sad  \textbackslash{}
0         0        0     1       0      1     0       0     1     0    0    1   
..      {\ldots}      {\ldots}   {\ldots}     {\ldots}    {\ldots}   {\ldots}     {\ldots}   {\ldots}   {\ldots}  {\ldots}  {\ldots}   

    said  save  saw  say  say im  scare  school  scienc  score  se  search  \textbackslash{}
0      0     0    0    0       0      0       1       0      0   0       0   
..   {\ldots}   {\ldots}  {\ldots}  {\ldots}     {\ldots}    {\ldots}     {\ldots}     {\ldots}    {\ldots}  ..     {\ldots}   

    second  see  seek  seem  seem like  seen  self  sens  sensit  sensor  \textbackslash{}
0        0    1     0     0          0     0     0     0       0       0   
..     {\ldots}  {\ldots}   {\ldots}   {\ldots}        {\ldots}   {\ldots}   {\ldots}   {\ldots}     {\ldots}     {\ldots}   

    sent  seri  seriou  serious  set  sever  sex  sexual  share  shi  shit  \textbackslash{}
0      0     0       0        0    1      0    0       0      1    0     0   
..   {\ldots}   {\ldots}     {\ldots}      {\ldots}  {\ldots}    {\ldots}  {\ldots}     {\ldots}    {\ldots}  {\ldots}   {\ldots}   

    shock  short  shouldnt  show  si  side  sign  silli  similar  simpl  \textbackslash{}
0       0      0         0     0   0     0     0      0        0      0   
..    {\ldots}    {\ldots}       {\ldots}   {\ldots}  ..   {\ldots}   {\ldots}    {\ldots}      {\ldots}    {\ldots}   

    simpli  sinc  singl  sister  sit  site  situat  skill  sleep  slightli  \textbackslash{}
0        0     0      0       0    1     0       0      0      0         0   
..     {\ldots}   {\ldots}    {\ldots}     {\ldots}  {\ldots}   {\ldots}     {\ldots}    {\ldots}    {\ldots}       {\ldots}   

    small  smart  smile  smoke  social  societi  somebodi  somehow  someon  \textbackslash{}
0       0      0      0      0       1        1         0        0       1   
..    {\ldots}    {\ldots}    {\ldots}    {\ldots}     {\ldots}      {\ldots}       {\ldots}      {\ldots}     {\ldots}   

    someon els  someth  someth like  sometim  somewhat  somewher  song  soon  \textbackslash{}
0            0       2            1        0         1         0     0     0   
..         {\ldots}     {\ldots}          {\ldots}      {\ldots}       {\ldots}       {\ldots}   {\ldots}   {\ldots}   

    sorri  sort  soul  sound  sound like  space  speak  special  specif  \textbackslash{}
0       1     1     0      0           0      0      1        0       0   
..    {\ldots}   {\ldots}   {\ldots}    {\ldots}         {\ldots}    {\ldots}    {\ldots}      {\ldots}     {\ldots}   

    spend  spent  sport  spot  stand  start  state  statement  stay  step  \textbackslash{}
0       0      0      0     0      0      1      0          0     0     0   
..    {\ldots}    {\ldots}    {\ldots}   {\ldots}    {\ldots}    {\ldots}    {\ldots}        {\ldots}   {\ldots}   {\ldots}   

    stereotyp  stick  still  stop  stori  straight  strang  stranger  stress  \textbackslash{}
0           0      0      0     0      0         0       0         0       0   
..        {\ldots}    {\ldots}    {\ldots}   {\ldots}    {\ldots}       {\ldots}     {\ldots}       {\ldots}     {\ldots}   

    strong  struggl  stuck  student  studi  stuff  stupid  style  subject  \textbackslash{}
0        0        0      0        0      0      1       0      0        1   
..     {\ldots}      {\ldots}    {\ldots}      {\ldots}    {\ldots}    {\ldots}     {\ldots}    {\ldots}      {\ldots}   

    success  suck  suggest  super  support  suppos  sure  surpris  sweet  \textbackslash{}
0         0     0        0      0        0       0     0        0      0   
..      {\ldots}   {\ldots}      {\ldots}    {\ldots}      {\ldots}     {\ldots}   {\ldots}      {\ldots}    {\ldots}   

    system  take  taken  talk  tapatalk  tast  te  teach  teacher  tell  tend  \textbackslash{}
0        0     1      0     0         0     0   0      0        0     0     0   
..     {\ldots}   {\ldots}    {\ldots}   {\ldots}       {\ldots}   {\ldots}  ..    {\ldots}      {\ldots}   {\ldots}   {\ldots}   

    tendenc  term  terribl  test  text  th  thank  theori  theyr  thing  \textbackslash{}
0         0     0        0     0     0   0      0       0      0      3   
..      {\ldots}   {\ldots}      {\ldots}   {\ldots}   {\ldots}  ..    {\ldots}     {\ldots}    {\ldots}    {\ldots}   

    thing like  think  think im  think would  though  thought  thread  three  \textbackslash{}
0            0      1         0            0       0        1       1      1   
..         {\ldots}    {\ldots}       {\ldots}          {\ldots}     {\ldots}      {\ldots}     {\ldots}    {\ldots}   

    throw  ti  time  tire  titl  today  togeth  told  tongu  took  top  topic  \textbackslash{}
0       0   0     6     0     0      2       0     0      0     0    1      0   
..    {\ldots}  ..   {\ldots}   {\ldots}   {\ldots}    {\ldots}     {\ldots}   {\ldots}    {\ldots}   {\ldots}  {\ldots}    {\ldots}   

    total  touch  toward  train  trait  travel  treat  tri  troubl  true  \textbackslash{}
0       0      0       0      0      0       0      0    2       0     0   
..    {\ldots}    {\ldots}     {\ldots}    {\ldots}    {\ldots}     {\ldots}    {\ldots}  {\ldots}     {\ldots}   {\ldots}   

    truli  trust  truth  turn  tv  two  type  typic  understand  unfortun  \textbackslash{}
0       0      0      0     0   0    2     3      0           0         0   
..    {\ldots}    {\ldots}    {\ldots}   {\ldots}  ..  {\ldots}   {\ldots}    {\ldots}         {\ldots}       {\ldots}   

    unhealthi  univers  unless  unsur  upon  upset  url  url url  us  use  \textbackslash{}
0           0        0       0      0     0      0   24        8   0    2   
..        {\ldots}      {\ldots}     {\ldots}    {\ldots}   {\ldots}    {\ldots}  {\ldots}      {\ldots}  ..  {\ldots}   

    use tapatalk  user  usual  valu  version  video  view  voic  vote  vs  \textbackslash{}
0              0     0      0     0        0      3     0     0     0   0   
..           {\ldots}   {\ldots}    {\ldots}   {\ldots}      {\ldots}    {\ldots}   {\ldots}   {\ldots}   {\ldots}  ..   

    wait  walk  wall  wanna  want  warm  wasnt  wast  watch  water  way  weak  \textbackslash{}
0      1     0     1      0     1     0      0     0      1      0    1     0   
..   {\ldots}   {\ldots}   {\ldots}    {\ldots}   {\ldots}   {\ldots}    {\ldots}   {\ldots}    {\ldots}    {\ldots}  {\ldots}   {\ldots}   

    wear  week  weird  welcom  well  went  whatev  whenev  whether  white  \textbackslash{}
0      0     0      0       2     0     0       0       0        0      0   
..   {\ldots}   {\ldots}    {\ldots}     {\ldots}   {\ldots}   {\ldots}     {\ldots}     {\ldots}      {\ldots}    {\ldots}   

    whole  win  wink  wish  within  without  woman  women  wonder  wont  word  \textbackslash{}
0       1    0     0     0       1        0      0      0       0     0     0   
..    {\ldots}  {\ldots}   {\ldots}   {\ldots}     {\ldots}      {\ldots}    {\ldots}    {\ldots}     {\ldots}   {\ldots}   {\ldots}   

    work  world  worri  wors  worst  worth  would  would like  would say  \textbackslash{}
0      0      2      1     0      0      0      1           1          0   
..   {\ldots}    {\ldots}    {\ldots}   {\ldots}    {\ldots}    {\ldots}    {\ldots}         {\ldots}        {\ldots}   

    wouldnt  wow  write  written  wrong  wrote  xd  ye  yeah  year  year ago  \textbackslash{}
0         0    0      0        0      0      0   0   0     0     1         1   
..      {\ldots}  {\ldots}    {\ldots}      {\ldots}    {\ldots}    {\ldots}  ..  ..   {\ldots}   {\ldots}       {\ldots}   

    year old  yep  yesterday  yet  youd  youll  young  younger  youtub  youv  
0          0    1          0    0     0      0      0        0       0     1  
..       {\ldots}  {\ldots}        {\ldots}  {\ldots}   {\ldots}    {\ldots}    {\ldots}      {\ldots}     {\ldots}   {\ldots}  

[8675 rows x 1000 columns]

    \end{Verbatim}

    It is confirmed that the web links have been converted to the term
'url', and the 16 personality types are excluded as tokens (to avoid
biasing the model).

    \begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

     \#\# Classification

     \#\#\# Multiclass classification (16 classes)

    \subparagraph{Baseline calculation}\label{baseline-calculation}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}36}]:} \PY{c+c1}{\PYZsh{} Determine baseline}
         \PY{n}{baseline} \PY{o}{=} \PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{max}\PY{p}{(}\PY{p}{)} \PY{o}{/} \PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}
         \PY{n}{baseline}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}36}]:} 0.21118155619596543
\end{Verbatim}
            
    The baseline is 0.211 (INFP is the largest class with 1832 of the 8675
cases).

    \subparagraph{Train-test split}\label{train-test-split}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}37}]:} \PY{c+c1}{\PYZsh{} Train\PYZhy{}test split, using type variable as target and posts variable as predictor}
         \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{posts}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{values}\PY{p}{,}
                                                            \PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{values}\PY{p}{,}
                                                            \PY{n}{test\PYZus{}size}\PY{o}{=}\PY{l+m+mf}{0.30}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{42}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{X\PYZus{}train }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{X\PYZus{}train}\PY{o}{.}\PY{n}{shape}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{X\PYZus{}test }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{o}{.}\PY{n}{shape}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{y\PYZus{}train }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{o}{.}\PY{n}{shape}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
               \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{y\PYZus{}test}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
X\_train  (6072,) 
 X\_test  (2603,) 
 y\_train  (6072,) 
 y\_test (2603,)

    \end{Verbatim}

    There are 6072 cases in the training set, and 2603 cases in the testing
set.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}38}]:} \PY{c+c1}{\PYZsh{} Run CountVectorizer on the X train/test (\PYZsq{}posts\PYZsq{} column) using the arguments identified earlier}
         \PY{n}{cv} \PY{o}{=} \PY{n}{CountVectorizer}\PY{p}{(}\PY{n}{preprocessor}\PY{o}{=}\PY{n}{cleaner}\PY{p}{,} \PY{n}{stop\PYZus{}words}\PY{o}{=}\PY{n}{stop\PYZus{}rev}\PY{p}{,} \PY{n}{ngram\PYZus{}range}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{)}\PY{p}{,} \PY{n}{max\PYZus{}features}\PY{o}{=}\PY{l+m+mi}{1000}\PY{p}{)}
         \PY{n}{cv}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{)}
         \PY{n}{X\PYZus{}train\PYZus{}cv} \PY{o}{=} \PY{n}{cv}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{)}
\end{Verbatim}


    \subparagraph{Truncated SVD}\label{truncated-svd}

\emph{TruncatedSVD} is a variant of principal component analysis (pca)
used on sparse matrices to reduce dimensionality

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}39}]:} \PY{c+c1}{\PYZsh{} Run Truncated SVD}
         \PY{c+c1}{\PYZsh{} First use max components and graph the explained variance ratio to find cutoff point }
         \PY{n}{tsvd} \PY{o}{=} \PY{n}{TruncatedSVD}\PY{p}{(}\PY{n}{n\PYZus{}components}\PY{o}{=}\PY{l+m+mi}{999}\PY{p}{)}
         \PY{n}{tsvd}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}cv}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{999}\PY{p}{)}\PY{p}{,} \PY{n}{tsvd}\PY{o}{.}\PY{n}{explained\PYZus{}variance\PYZus{}ratio\PYZus{}}\PY{o}{.}\PY{n}{cumsum}\PY{p}{(}\PY{p}{)}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Truncated SVD \PYZhy{} Optimal \PYZsh{} of components}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{16}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZsh{} of components}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Explained variance ratio}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_74_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    The graph above suggests that approximately 175 components would be most
effective, since it is where the explained variance begins to flatten
out.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}40}]:} \PY{c+c1}{\PYZsh{} Run a Truncated SVD with 175 components}
         \PY{n}{tsvd} \PY{o}{=} \PY{n}{TruncatedSVD}\PY{p}{(}\PY{n}{n\PYZus{}components}\PY{o}{=}\PY{l+m+mi}{175}\PY{p}{)}
         \PY{n}{tsvd}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}cv}\PY{p}{)}
         \PY{n}{X\PYZus{}train\PYZus{}tsvd} \PY{o}{=} \PY{n}{tsvd}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}cv}\PY{p}{)}
         
         \PY{n}{X\PYZus{}test\PYZus{}cv} \PY{o}{=} \PY{n}{cv}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{)}
         \PY{n}{X\PYZus{}test\PYZus{}tsvd} \PY{o}{=} \PY{n}{tsvd}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}cv}\PY{p}{)}
\end{Verbatim}


    \textbf{Preprocessing Pipeline}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}41}]:} \PY{c+c1}{\PYZsh{} Pipeline for the data preprocessing steps (CountVectorizer, TruncatedSVD) on the X data}
         \PY{n}{pipeline\PYZus{}preprocessing} \PY{o}{=} \PY{n}{make\PYZus{}pipeline}\PY{p}{(}
             \PY{n}{CountVectorizer}\PY{p}{(}\PY{n}{preprocessor}\PY{o}{=}\PY{n}{cleaner}\PY{p}{,} \PY{n}{stop\PYZus{}words}\PY{o}{=}\PY{n}{stop\PYZus{}rev}\PY{p}{,} \PY{n}{ngram\PYZus{}range}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{)}\PY{p}{,} \PY{n}{max\PYZus{}features}\PY{o}{=}\PY{l+m+mi}{1000}\PY{p}{)}\PY{p}{,}
             \PY{n}{TruncatedSVD}\PY{p}{(}\PY{n}{n\PYZus{}components}\PY{o}{=}\PY{l+m+mi}{175}\PY{p}{)}\PY{p}{)}
         
         \PY{n}{X\PYZus{}train\PYZus{}tsvd} \PY{o}{=} \PY{n}{pipeline\PYZus{}preprocessing}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{)}
         \PY{n}{X\PYZus{}test\PYZus{}tsvd} \PY{o}{=} \PY{n}{pipeline\PYZus{}preprocessing}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{)}
\end{Verbatim}


    \textbf{A brief guide to interpreting the Classification Report:} -
Precision = True Positives / (True Positives + False Positives) - A
precision score of 1 indicates that the classifier never mistakenly
added observations from another class. A precision score of 0 would mean
that the classifier misclassified every instance of the current class. -
Recall = True Positives / (True Positives + False Negatives) - A recall
score of 1 indicates that the classifier correctly predicted (found) all
observations of the current class (by implication, no false negatives,
or misclassifications of the current class). A recall score of 0
alternatively means that the classifier missed all observations of the
current class. - F1-Score = 2 x (Precision x Recall) / (Precision +
Recall) - The f1-score's best value is 1 and worst value is 0, like the
precision and recall scores. It is a useful metric for taking into
account both measures at once. - Support is simply the number of
observations of the labelled class.

     \#\#\# Modeling

     \#\#\#\# Model: Random Forest Classifier

\emph{RandomForestClassifier} is a meta estimator that fits a number of
decision tree classifiers on various sub-samples of the dataset and use
averaging to improve the predictive accuracy and control over-fitting.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}42}]:} \PY{c+c1}{\PYZsh{} Fit and score a Random Forest Classifier}
         \PY{c+c1}{\PYZsh{} Parameters: 30 estimators, min 50 samples per leaf node, out\PYZhy{}of\PYZhy{}bag samples to estimate generalization accuracy}
         \PY{n}{rfc} \PY{o}{=} \PY{n}{RandomForestClassifier}\PY{p}{(}\PY{n}{n\PYZus{}estimators}\PY{o}{=}\PY{l+m+mi}{30}\PY{p}{,} \PY{n}{min\PYZus{}samples\PYZus{}leaf}\PY{o}{=}\PY{l+m+mi}{50}\PY{p}{,} \PY{n}{oob\PYZus{}score}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{n\PYZus{}jobs}\PY{o}{=} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{123}\PY{p}{)}
         \PY{n}{rfc}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}tsvd}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{TRAINING SET}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Accuracy: }\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{score}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}tsvd}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Confusion Matrix:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Classification Report:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{classification\PYZus{}report}\PY{p}{(}\PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{TEST SET}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Accuracy: }\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{score}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}tsvd}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Confusion Matrix:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Classification Report:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{classification\PYZus{}report}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
TRAINING SET
Accuracy:  0.4061264822134387
Confusion Matrix:
[[   0    0    0    0    0    0    0    0   23   98    4    9    0    0
     0    0]
 [   0    0    0    0    0    0    0    0   78  358   13   30    0    0
     0    0]
 [   0    0    0    0    0    0    0    0   23   81   24   45    0    0
     0    0]
 [   0    0    0    1    0    0    0    0   47  260   29  147    0    0
     0    0]
 [   0    0    0    0    0    0    0    0   11   17    1    3    0    0
     0    0]
 [   0    0    0    0    0    0    0    0    2   28    1    8    0    0
     0    0]
 [   0    0    0    0    0    0    0    0    5   11    3    3    0    0
     0    0]
 [   0    0    0    0    0    0    0    0   11   31    7   15    0    0
     0    0]
 [   0    0    0    0    0    0    0    0  503  466   15   52    0    0
     0    0]
 [   0    0    0    0    0    0    0    0   17 1203    8   38    0    0
     0    0]
 [   0    0    0    0    0    0    0    0   77  301  261  141    0    0
     0    0]
 [   0    0    0    0    0    0    0    0   65  323   14  498    0    0
     0    0]
 [   0    0    0    0    0    0    0    0   11   83    1   10    0    0
     0    0]
 [   0    0    0    0    0    0    0    0   25  143    4   15    0    0
     0    0]
 [   0    0    0    0    0    0    0    0   21   83    9   22    0    0
     0    0]
 [   0    0    0    0    0    0    0    0   30  119   21   66    0    0
     0    0]]
Classification Report:
             precision    recall  f1-score   support

       ENFJ       0.00      0.00      0.00       134
       ENFP       0.00      0.00      0.00       479
       ENTJ       0.00      0.00      0.00       173
       ENTP       1.00      0.00      0.00       484
       ESFJ       0.00      0.00      0.00        32
       ESFP       0.00      0.00      0.00        39
       ESTJ       0.00      0.00      0.00        22
       ESTP       0.00      0.00      0.00        64
       INFJ       0.53      0.49      0.51      1036
       INFP       0.33      0.95      0.49      1266
       INTJ       0.63      0.33      0.44       780
       INTP       0.45      0.55      0.50       900
       ISFJ       0.00      0.00      0.00       105
       ISFP       0.00      0.00      0.00       187
       ISTJ       0.00      0.00      0.00       135
       ISTP       0.00      0.00      0.00       236

avg / total       0.39      0.41      0.32      6072


TEST SET

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
C:\textbackslash{}Users\textbackslash{}dhava\textbackslash{}Anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}metrics\textbackslash{}classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn\_for)

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Accuracy:  0.2631578947368421
Confusion Matrix:
[[  0   0   0   0   0   0   0   0  10  41   1   4   0   0   0   0]
 [  0   0   0   0   0   0   0   0  30 142   9  15   0   0   0   0]
 [  0   0   0   0   0   0   0   0  15  28   3  12   0   0   0   0]
 [  0   0   0   0   0   0   0   0  30 108  13  50   0   0   0   0]
 [  0   0   0   0   0   0   0   0   3   7   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   6   1   2   0   0   0   0]
 [  0   0   0   0   0   0   0   0   2  11   4   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   2  14   1   8   0   0   0   0]
 [  0   0   0   0   0   0   0   0  60 314  19  41   0   0   0   0]
 [  0   0   0   0   0   0   0   0  48 459  15  44   0   0   0   0]
 [  0   0   0   0   0   0   0   0  36 161  32  82   0   0   0   0]
 [  0   0   0   0   0   0   0   0  31 212  27 134   0   0   0   0]
 [  0   0   0   0   0   0   0   0  11  41   3   6   0   0   0   0]
 [  0   0   0   0   0   0   0   0   6  68   4   6   0   0   0   0]
 [  0   0   0   0   0   0   0   0  13  31   7  19   0   0   0   0]
 [  0   0   0   0   0   0   0   0  12  47   7  35   0   0   0   0]]
Classification Report:
             precision    recall  f1-score   support

       ENFJ       0.00      0.00      0.00        56
       ENFP       0.00      0.00      0.00       196
       ENTJ       0.00      0.00      0.00        58
       ENTP       0.00      0.00      0.00       201
       ESFJ       0.00      0.00      0.00        10
       ESFP       0.00      0.00      0.00         9
       ESTJ       0.00      0.00      0.00        17
       ESTP       0.00      0.00      0.00        25
       INFJ       0.19      0.14      0.16       434
       INFP       0.27      0.81      0.41       566
       INTJ       0.22      0.10      0.14       311
       INTP       0.29      0.33      0.31       404
       ISFJ       0.00      0.00      0.00        61
       ISFP       0.00      0.00      0.00        84
       ISTJ       0.00      0.00      0.00        70
       ISTP       0.00      0.00      0.00       101

avg / total       0.16      0.26      0.18      2603


    \end{Verbatim}

    With the default arguments in the Random Forest Classifier model, the
Accuracy on the training set was 0.993 and the testing set was 0.194,
compared to the baseline of 0.211. The high accuracy of the training
data but low accuracy of predictions on the test set suggests the model
was overfit.

Using n\_estimators=30, min\_samples\_leaf=50, oob\_score=True, n\_jobs=
-1 gives a training Accuracy of 0.413 and testing Accuracy of 0.270.
This is a more realistic score for the training set (suggesting the
model is not overfit) and an improved score on predicting the testing
set. However, each of the predictions falls within a limited subset of
only four of the sixteen classes.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}43}]:} \PY{c+c1}{\PYZsh{} Convert confusion matrix to a dataframe to prepare it for heatmapping}
         \PY{n}{cm\PYZus{}rfc} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         
         \PY{n}{cm\PYZus{}randomforest} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{cm\PYZus{}rfc}\PY{p}{,} \PY{n}{index}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ENFJ}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ENFP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ENTJ}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ENTP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ESFJ}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ESFP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                                                \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ESTJ}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ESTP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{INFJ}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{INFP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{INTJ}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{INTP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                                                \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ISFJ}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ISFP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ISTJ}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ISTP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} 
                                     \PY{n}{columns}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}ENFJ}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}ENFP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}ENTJ}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                                              \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}ENTP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}ESFJ}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}ESFP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                                              \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}ESTJ}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}ESTP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}INFJ}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                                              \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}INFP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}INTJ}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}INTP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                                              \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}ISFJ}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}ISFP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}ISTJ}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                                              \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}ISTP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
         \PY{n}{cm\PYZus{}randomforest}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}43}]:}       predict\_ENFJ  predict\_ENFP  predict\_ENTJ  predict\_ENTP  predict\_ESFJ  \textbackslash{}
         ENFJ             0             0             0             0             0   
         ENFP             0             0             0             0             0   
         ENTJ             0             0             0             0             0   
         ENTP             0             0             0             0             0   
         ESFJ             0             0             0             0             0   
         ESFP             0             0             0             0             0   
         ESTJ             0             0             0             0             0   
         ESTP             0             0             0             0             0   
         INFJ             0             0             0             0             0   
         INFP             0             0             0             0             0   
         INTJ             0             0             0             0             0   
         INTP             0             0             0             0             0   
         ISFJ             0             0             0             0             0   
         ISFP             0             0             0             0             0   
         ISTJ             0             0             0             0             0   
         ISTP             0             0             0             0             0   
         
               predict\_ESFP  predict\_ESTJ  predict\_ESTP  predict\_INFJ  predict\_INFP  \textbackslash{}
         ENFJ             0             0             0            10            41   
         ENFP             0             0             0            30           142   
         ENTJ             0             0             0            15            28   
         ENTP             0             0             0            30           108   
         ESFJ             0             0             0             3             7   
         ESFP             0             0             0             0             6   
         ESTJ             0             0             0             2            11   
         ESTP             0             0             0             2            14   
         INFJ             0             0             0            60           314   
         INFP             0             0             0            48           459   
         INTJ             0             0             0            36           161   
         INTP             0             0             0            31           212   
         ISFJ             0             0             0            11            41   
         ISFP             0             0             0             6            68   
         ISTJ             0             0             0            13            31   
         ISTP             0             0             0            12            47   
         
               predict\_INTJ  predict\_INTP  predict\_ISFJ  predict\_ISFP  predict\_ISTJ  \textbackslash{}
         ENFJ             1             4             0             0             0   
         ENFP             9            15             0             0             0   
         ENTJ             3            12             0             0             0   
         ENTP            13            50             0             0             0   
         ESFJ             0             0             0             0             0   
         ESFP             1             2             0             0             0   
         ESTJ             4             0             0             0             0   
         ESTP             1             8             0             0             0   
         INFJ            19            41             0             0             0   
         INFP            15            44             0             0             0   
         INTJ            32            82             0             0             0   
         INTP            27           134             0             0             0   
         ISFJ             3             6             0             0             0   
         ISFP             4             6             0             0             0   
         ISTJ             7            19             0             0             0   
         ISTP             7            35             0             0             0   
         
               predict\_ISTP  
         ENFJ             0  
         ENFP             0  
         ENTJ             0  
         ENTP             0  
         ESFJ             0  
         ESFP             0  
         ESTJ             0  
         ESTP             0  
         INFJ             0  
         INFP             0  
         INTJ             0  
         INTP             0  
         ISFJ             0  
         ISFP             0  
         ISTJ             0  
         ISTP             0  
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}44}]:} \PY{c+c1}{\PYZsh{} Create confusion matrix heatmap of Random Forest Classifier model }
         \PY{n}{fig}\PY{p}{,} \PY{n}{ax} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{14}\PY{p}{,}\PY{l+m+mi}{10}\PY{p}{)}\PY{p}{)} 
         \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Confusion Matrix for Random Forest Classifier}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{16}\PY{p}{,}
                   \PY{n}{fontweight}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bold}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{l+m+mf}{1.02}\PY{p}{)}
         \PY{n}{sns}\PY{o}{.}\PY{n}{heatmap}\PY{p}{(}\PY{n}{cm\PYZus{}randomforest}\PY{p}{,} \PY{n}{robust}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{annot}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{linewidth}\PY{o}{=}\PY{l+m+mf}{0.5}\PY{p}{,} 
                     \PY{n}{fmt}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{cmap}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{RdBu\PYZus{}r}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{vmax}\PY{o}{=}\PY{l+m+mi}{303}\PY{p}{,} \PY{n}{ax}\PY{o}{=}\PY{n}{ax}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{xticks}\PY{p}{(}\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{yticks}\PY{p}{(}\PY{n}{rotation}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_85_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    In the heatmapped confusion matrix above, it is clear that the Random
Forest Classifier model is making predictions only within four of the
sixteen classes: INFJ, INFP, INTJ, and INTP, which are the most abundant
classes in the dataset. The other twelve categories receive no
predictions from this model at all. Despite having an accuracy score
higher than the baseline, this model is not suited to predicting classes
outside of the ones with the highest frequency.

     \#\#\#\# Model: KNeighborsClassifier

\emph{KNeighborsClassifier} is a nonparametric classification model that
finds the observations in its training data that are "nearest" to the
observation to predict; it then averages or takes a vote of those
training observations' target values to estimate the value for the new
data point.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}45}]:} \PY{c+c1}{\PYZsh{} Search for the optimal number of neighbors to use}
         \PY{n}{error\PYZus{}rate} \PY{o}{=} \PY{p}{[}\PY{p}{]}
         
         \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{4}\PY{p}{,}\PY{l+m+mi}{14}\PY{p}{)}\PY{p}{:}
             \PY{n}{knn\PYZus{}lc} \PY{o}{=} \PY{n}{KNeighborsClassifier}\PY{p}{(}\PY{n}{n\PYZus{}neighbors}\PY{o}{=}\PY{n}{i}\PY{p}{)}
             \PY{n}{knn\PYZus{}lc}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}tsvd}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}
             
             \PY{n}{pred\PYZus{}i} \PY{o}{=} \PY{n}{knn\PYZus{}lc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}tsvd}\PY{p}{)}
             \PY{n}{error\PYZus{}rate}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{pred\PYZus{}i} \PY{o}{!=} \PY{n}{y\PYZus{}test}\PY{p}{)}\PY{p}{)}
             
         \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{10}\PY{p}{,} \PY{l+m+mi}{4}\PY{p}{)}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{4}\PY{p}{,}\PY{l+m+mi}{14}\PY{p}{)}\PY{p}{,} \PY{n}{error\PYZus{}rate}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{red}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{linestyle}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dashed}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                  \PY{n}{marker}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{o}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{markerfacecolor}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{black}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{markersize}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Error Rate vs. K Value}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{16}\PY{p}{,}
                   \PY{n}{fontweight}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bold}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{l+m+mf}{1.02}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{K}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{l+m+mf}{1.02}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Error Rate}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{,} \PY{n}{x}\PY{o}{=}\PY{l+m+mf}{1.02}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_88_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    According to the graph, 13 is the optimal number of neighbors to use in
the KNeighborsClassifier model. It gives a relatively low error rate for
the lowest k neighbors (more neighbors give diminishing returns). But
this should be confirmed with a grid search to find the best
hyperparameters.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}46}]:} \PY{c+c1}{\PYZsh{} Grid Search to find the best parameters on KNeighbors Classifier}
         \PY{n}{k\PYZus{}dict} \PY{o}{=} \PY{p}{\PYZob{}}
             \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{n\PYZus{}neighbors}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+m+mi}{7}\PY{p}{,}\PY{l+m+mi}{9}\PY{p}{,}\PY{l+m+mi}{11}\PY{p}{,}\PY{l+m+mi}{13}\PY{p}{,}\PY{l+m+mi}{15}\PY{p}{]}\PY{p}{,}
             \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{weights}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{uniform}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{distance}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}
             \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{p}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{]}\PY{p}{,}\PY{p}{\PYZcb{}}
                 \PY{c+c1}{\PYZsh{} p = power parameter for the Minkowski metric. }
                 \PY{c+c1}{\PYZsh{} 1 is Manhattan; 2 is Euclidean}
         
         \PY{n}{knn} \PY{o}{=} \PY{n}{KNeighborsClassifier}\PY{p}{(}\PY{p}{)}
         \PY{n}{gs} \PY{o}{=} \PY{n}{GridSearchCV}\PY{p}{(}\PY{n}{knn}\PY{p}{,} \PY{n}{k\PYZus{}dict}\PY{p}{,} \PY{n}{verbose}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{,} \PY{n}{n\PYZus{}jobs}\PY{o}{=}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} if n\PYZus{}jobs = \PYZhy{}1, then the number of jobs is set to the number of CPU cores.}
         \PY{n}{gs}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}tsvd}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Fitting 3 folds for each of 20 candidates, totalling 60 fits

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
[Parallel(n\_jobs=-1)]: Done  33 tasks      | elapsed:  2.6min
[Parallel(n\_jobs=-1)]: Done  60 out of  60 | elapsed:  4.5min finished

    \end{Verbatim}

\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}46}]:} GridSearchCV(cv=None, error\_score='raise',
                estimator=KNeighborsClassifier(algorithm='auto', leaf\_size=30, metric='minkowski',
                    metric\_params=None, n\_jobs=1, n\_neighbors=5, p=2,
                    weights='uniform'),
                fit\_params=None, iid=True, n\_jobs=-1,
                param\_grid=\{'n\_neighbors': [7, 9, 11, 13, 15], 'weights': ['uniform', 'distance'], 'p': [1, 2]\},
                pre\_dispatch='2*n\_jobs', refit=True, return\_train\_score='warn',
                scoring=None, verbose=2)
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}47}]:} \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Best score: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{gs}\PY{o}{.}\PY{n}{best\PYZus{}score\PYZus{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Best parameters: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{gs}\PY{o}{.}\PY{n}{best\PYZus{}params\PYZus{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Best score:  0.2271080368906456
Best parameters:  \{'n\_neighbors': 15, 'p': 2, 'weights': 'distance'\}

    \end{Verbatim}

    The grid search suggests that the optimal number of neighbors is 13. The
optimal weight function is 'distance,' where points are weighted by the
inverse of their distance (closer neighbors of a query point will have a
greater influence than neighbors which are further away). These
hyperparameters will be used in the KNeighborsClassifier model. The
optimal power parameter (p) for the Minkowski metric is 2, indicating
Euclidean distance. This is the default parameter for this model so no
adjustments are needed on that hyperparameter.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}48}]:} \PY{c+c1}{\PYZsh{} Fit and score a KNeighborsClassifier using 13 neighbors and distance weighting function}
         \PY{n}{knn} \PY{o}{=} \PY{n}{KNeighborsClassifier}\PY{p}{(}\PY{n}{n\PYZus{}neighbors}\PY{o}{=}\PY{l+m+mi}{13}\PY{p}{,} \PY{n}{weights}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{distance}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{knn}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}tsvd}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{TRAINING SET}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Accuracy: }\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{knn}\PY{o}{.}\PY{n}{score}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}tsvd}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Confusion Matrix:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{knn}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Classification Report:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{classification\PYZus{}report}\PY{p}{(}\PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{knn}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{TEST SET}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Accuracy: }\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{knn}\PY{o}{.}\PY{n}{score}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}tsvd}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Confusion Matrix:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{knn}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Classification Report:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{classification\PYZus{}report}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{knn}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
TRAINING SET
Accuracy:  1.0
Confusion Matrix:
[[ 134    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0]
 [   0  479    0    0    0    0    0    0    0    0    0    0    0    0
     0    0]
 [   0    0  173    0    0    0    0    0    0    0    0    0    0    0
     0    0]
 [   0    0    0  484    0    0    0    0    0    0    0    0    0    0
     0    0]
 [   0    0    0    0   32    0    0    0    0    0    0    0    0    0
     0    0]
 [   0    0    0    0    0   39    0    0    0    0    0    0    0    0
     0    0]
 [   0    0    0    0    0    0   22    0    0    0    0    0    0    0
     0    0]
 [   0    0    0    0    0    0    0   64    0    0    0    0    0    0
     0    0]
 [   0    0    0    0    0    0    0    0 1036    0    0    0    0    0
     0    0]
 [   0    0    0    0    0    0    0    0    0 1266    0    0    0    0
     0    0]
 [   0    0    0    0    0    0    0    0    0    0  780    0    0    0
     0    0]
 [   0    0    0    0    0    0    0    0    0    0    0  900    0    0
     0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0  105    0
     0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0  187
     0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0
   135    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0  236]]
Classification Report:
             precision    recall  f1-score   support

       ENFJ       1.00      1.00      1.00       134
       ENFP       1.00      1.00      1.00       479
       ENTJ       1.00      1.00      1.00       173
       ENTP       1.00      1.00      1.00       484
       ESFJ       1.00      1.00      1.00        32
       ESFP       1.00      1.00      1.00        39
       ESTJ       1.00      1.00      1.00        22
       ESTP       1.00      1.00      1.00        64
       INFJ       1.00      1.00      1.00      1036
       INFP       1.00      1.00      1.00      1266
       INTJ       1.00      1.00      1.00       780
       INTP       1.00      1.00      1.00       900
       ISFJ       1.00      1.00      1.00       105
       ISFP       1.00      1.00      1.00       187
       ISTJ       1.00      1.00      1.00       135
       ISTP       1.00      1.00      1.00       236

avg / total       1.00      1.00      1.00      6072


TEST SET
Accuracy:  0.22973492124471764
Confusion Matrix:
[[  0   2   0   1   0   0   0   0  15  25   4   9   0   0   0   0]
 [  1   9   0  16   0   0   0   1  35  84  19  30   1   0   0   0]
 [  0   0   1   6   0   0   0   0  11  10  11  18   0   0   0   1]
 [  0   4   3  29   0   0   0   0  35  47  39  43   0   0   1   0]
 [  0   0   0   0   0   0   0   0   1   4   1   4   0   0   0   0]
 [  0   0   0   0   0   0   0   0   3   4   0   2   0   0   0   0]
 [  0   0   1   0   0   0   0   0   5   3   5   3   0   0   0   0]
 [  0   2   0   3   0   0   0   0   5   7   5   3   0   0   0   0]
 [  2  17   1  21   0   1   0   0  95 166  50  75   0   1   0   5]
 [  0  17   1  24   0   0   0   0 106 258  56  97   2   3   0   2]
 [  0   7   4  18   0   0   0   0  35  84  75  87   0   0   0   1]
 [  0  10   2  33   0   0   0   0  46  99  76 127   3   3   1   4]
 [  0   2   1   4   0   0   0   0  13  26   9   6   0   0   0   0]
 [  0   6   0   6   0   0   0   0  15  29  12  12   1   1   0   2]
 [  0   2   2   3   0   0   0   0  11  15  12  21   1   1   0   2]
 [  0   2   1   9   0   0   0   1   6  26  18  34   0   1   0   3]]
Classification Report:
             precision    recall  f1-score   support

       ENFJ       0.00      0.00      0.00        56
       ENFP       0.11      0.05      0.07       196
       ENTJ       0.06      0.02      0.03        58
       ENTP       0.17      0.14      0.16       201
       ESFJ       0.00      0.00      0.00        10
       ESFP       0.00      0.00      0.00         9
       ESTJ       0.00      0.00      0.00        17
       ESTP       0.00      0.00      0.00        25
       INFJ       0.22      0.22      0.22       434
       INFP       0.29      0.46      0.36       566
       INTJ       0.19      0.24      0.21       311
       INTP       0.22      0.31      0.26       404
       ISFJ       0.00      0.00      0.00        61
       ISFP       0.10      0.01      0.02        84
       ISTJ       0.00      0.00      0.00        70
       ISTP       0.15      0.03      0.05       101

avg / total       0.19      0.23      0.20      2603


    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
C:\textbackslash{}Users\textbackslash{}dhava\textbackslash{}Anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}metrics\textbackslash{}classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn\_for)

    \end{Verbatim}

    Using the hyperparameters suggested by the grid search (13 neighbors,
distance weighting function, and Euclidean distance), the prediction
accuracy of the model on the training set is 1.0 which suggests an
overfit model. The accuracy on the test set is 0.217, just over the
baseline of 0.211. The accuracy is lower than that of the
RandomForestClassifier model, but the predictions are not limited to
just the Introversion-Intuition subset of classes.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}49}]:} \PY{c+c1}{\PYZsh{} Convert confusion matrix for KNeightbors Classifier model to a dataframe to prepare it for heatmapping}
         \PY{n}{cm\PYZus{}knn} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{knn}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         
         \PY{n}{cm\PYZus{}kneighbors} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{cm\PYZus{}knn}\PY{p}{,} \PY{n}{index}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ENFJ}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ENFP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ENTJ}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ENTP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ESFJ}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ESFP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                                                \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ESTJ}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ESTP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{INFJ}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{INFP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{INTJ}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{INTP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                                                \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ISFJ}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ISFP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ISTJ}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ISTP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} 
                                     \PY{n}{columns}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}ENFJ}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}ENFP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}ENTJ}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                                              \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}ENTP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}ESFJ}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}ESFP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                                              \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}ESTJ}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}ESTP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}INFJ}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                                              \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}INFP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}INTJ}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}INTP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                                              \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}ISFJ}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}ISFP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}ISTJ}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                                              \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}ISTP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
         \PY{n}{cm\PYZus{}kneighbors}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}49}]:}       predict\_ENFJ  predict\_ENFP  predict\_ENTJ  predict\_ENTP  predict\_ESFJ  \textbackslash{}
         ENFJ             0             2             0             1             0   
         ENFP             1             9             0            16             0   
         ENTJ             0             0             1             6             0   
         ENTP             0             4             3            29             0   
         ESFJ             0             0             0             0             0   
         ESFP             0             0             0             0             0   
         ESTJ             0             0             1             0             0   
         ESTP             0             2             0             3             0   
         INFJ             2            17             1            21             0   
         INFP             0            17             1            24             0   
         INTJ             0             7             4            18             0   
         INTP             0            10             2            33             0   
         ISFJ             0             2             1             4             0   
         ISFP             0             6             0             6             0   
         ISTJ             0             2             2             3             0   
         ISTP             0             2             1             9             0   
         
               predict\_ESFP  predict\_ESTJ  predict\_ESTP  predict\_INFJ  predict\_INFP  \textbackslash{}
         ENFJ             0             0             0            15            25   
         ENFP             0             0             1            35            84   
         ENTJ             0             0             0            11            10   
         ENTP             0             0             0            35            47   
         ESFJ             0             0             0             1             4   
         ESFP             0             0             0             3             4   
         ESTJ             0             0             0             5             3   
         ESTP             0             0             0             5             7   
         INFJ             1             0             0            95           166   
         INFP             0             0             0           106           258   
         INTJ             0             0             0            35            84   
         INTP             0             0             0            46            99   
         ISFJ             0             0             0            13            26   
         ISFP             0             0             0            15            29   
         ISTJ             0             0             0            11            15   
         ISTP             0             0             1             6            26   
         
               predict\_INTJ  predict\_INTP  predict\_ISFJ  predict\_ISFP  predict\_ISTJ  \textbackslash{}
         ENFJ             4             9             0             0             0   
         ENFP            19            30             1             0             0   
         ENTJ            11            18             0             0             0   
         ENTP            39            43             0             0             1   
         ESFJ             1             4             0             0             0   
         ESFP             0             2             0             0             0   
         ESTJ             5             3             0             0             0   
         ESTP             5             3             0             0             0   
         INFJ            50            75             0             1             0   
         INFP            56            97             2             3             0   
         INTJ            75            87             0             0             0   
         INTP            76           127             3             3             1   
         ISFJ             9             6             0             0             0   
         ISFP            12            12             1             1             0   
         ISTJ            12            21             1             1             0   
         ISTP            18            34             0             1             0   
         
               predict\_ISTP  
         ENFJ             0  
         ENFP             0  
         ENTJ             1  
         ENTP             0  
         ESFJ             0  
         ESFP             0  
         ESTJ             0  
         ESTP             0  
         INFJ             5  
         INFP             2  
         INTJ             1  
         INTP             4  
         ISFJ             0  
         ISFP             2  
         ISTJ             2  
         ISTP             3  
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}50}]:} \PY{c+c1}{\PYZsh{} Create confusion matrix heatmap of KNeighbors Classifier model }
         \PY{n}{fig}\PY{p}{,} \PY{n}{ax} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{14}\PY{p}{,}\PY{l+m+mi}{10}\PY{p}{)}\PY{p}{)} 
         \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Confusion Matrix for K\PYZhy{}Neighbors Classifier}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                   \PY{n}{fontweight}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bold}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{l+m+mf}{1.02}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{16}\PY{p}{)}
         \PY{n}{sns}\PY{o}{.}\PY{n}{heatmap}\PY{p}{(}\PY{n}{cm\PYZus{}kneighbors}\PY{p}{,} \PY{n}{robust}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{annot}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{linewidth}\PY{o}{=}\PY{l+m+mf}{0.5}\PY{p}{,} 
                     \PY{n}{fmt}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{cmap}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{RdBu\PYZus{}r}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{vmax}\PY{o}{=}\PY{l+m+mi}{303}\PY{p}{,} \PY{n}{ax}\PY{o}{=}\PY{n}{ax}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{xticks}\PY{p}{(}\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{yticks}\PY{p}{(}\PY{n}{rotation}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_96_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    As shown in the heatmapped confusion matrix above, the KNeighbors
Classifier is best at predicting cases in the Introversion/Intuition
(IN-) classes, which are the most abundant of this dataset. However,
unlike the RandomForest Classifier, this model makes predictions outside
of those four groups as well. There is still much misclassification, yet
it is notable that many of these incorrect labelings are correct on
three of the four axes - e.g. ENFP subjects labeled as INFP (where their
Intuitive, Feeling, and Perceiving status is guessed accurately, but
they are Extroverts misattributed as Introverts).

     \#\#\#\# Model: OneVsRestClassifier

\emph{OneVsRestClassifier} is a multiclass classifier in which a class
is fitted against all the other classes; since each class is represented
by one and only one classifier, it is possible to gain knowledge about
the class by inspecting its corresponding classifier.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}51}]:} \PY{c+c1}{\PYZsh{} Fit and score a One\PYZhy{}Vs\PYZhy{}The\PYZhy{}Rest Classifier}
         \PY{n}{ovrc} \PY{o}{=} \PY{n}{OneVsRestClassifier}\PY{p}{(}\PY{n}{LinearSVC}\PY{p}{(}\PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{123}\PY{p}{)}\PY{p}{)}
         \PY{n}{ovrc}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}tsvd}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{TRAINING SET}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Accuracy: }\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{ovrc}\PY{o}{.}\PY{n}{score}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}tsvd}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Confusion Matrix:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{ovrc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Classification Report:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{classification\PYZus{}report}\PY{p}{(}\PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{ovrc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{TEST SET}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Accuracy: }\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{ovrc}\PY{o}{.}\PY{n}{score}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}tsvd}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Confusion Matrix:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{ovrc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Classification Report:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{classification\PYZus{}report}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{ovrc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
TRAINING SET
Accuracy:  0.3096179183135705
Confusion Matrix:
[[  0  21   0   0   0   0   0   0  61  12  27   7   0   0   0   6]
 [  0 171   0   6   1   0   0   1 115  74  82  12   2   1   0  14]
 [  0  11   3   3   1   0   0   0  38   7  89  10   2   0   0   9]
 [  0  63   2  28   1   1   0   0  66  30 201  56   0   0   0  36]
 [  0   3   0   0  18   0   0   0   6   2   3   0   0   0   0   0]
 [  0   6   0   1   0   3   0   0   5   5  14   4   0   0   0   1]
 [  0   0   0   0   0   0  22   0   0   0   0   0   0   0   0   0]
 [  0   9   0   2   1   0   0   4  11   2  24   2   0   0   0   9]
 [  0 113   1   2   4   1   0   0 503 129 211  40   2   5   0  25]
 [  0 144   4   8   3   1   1   0 371 388 217  84   4   1   0  40]
 [  0  56   1   2   4   1   0   0 106  51 434  80   2   2   0  41]
 [  0  57   0   6   1   3   0   0 131  68 385 204   6   1   0  38]
 [  0  16   0   0   1   0   0   0  28   8  30  10   7   0   0   5]
 [  0  21   1   1   1   0   0   0  52  40  34  18   2   7   0  10]
 [  0  25   1   0   0   0   0   0  23  11  54   7   0   2   1  11]
 [  0  13   2   1   0   0   0   0  19   7  76  28   1   1   1  87]]
Classification Report:
             precision    recall  f1-score   support

       ENFJ       0.00      0.00      0.00       134
       ENFP       0.23      0.36      0.28       479
       ENTJ       0.20      0.02      0.03       173
       ENTP       0.47      0.06      0.10       484
       ESFJ       0.50      0.56      0.53        32
       ESFP       0.30      0.08      0.12        39
       ESTJ       0.96      1.00      0.98        22
       ESTP       0.80      0.06      0.12        64
       INFJ       0.33      0.49      0.39      1036
       INFP       0.47      0.31      0.37      1266
       INTJ       0.23      0.56      0.33       780
       INTP       0.36      0.23      0.28       900
       ISFJ       0.25      0.07      0.11       105
       ISFP       0.35      0.04      0.07       187
       ISTJ       0.50      0.01      0.01       135
       ISTP       0.26      0.37      0.31       236

avg / total       0.35      0.31      0.28      6072


TEST SET
Accuracy:  0.2485593545908567
Confusion Matrix:
[[  0  10   0   0   0   0   1   0  23  10   7   3   0   0   0   2]
 [  0  51   0   0   5   1   2   2  58  32  29   6   0   1   0   9]
 [  0   5   1   2   2   0   1   0  12   4  24   4   0   0   0   3]
 [  0  31   1   4   2   1   4   1  34   9  81  19   1   0   0  13]
 [  0   3   0   0   0   0   0   0   3   0   2   0   1   1   0   0]
 [  0   1   0   0   0   0   0   0   2   1   3   1   0   0   0   1]
 [  0   4   0   0   1   0   0   0   3   2   4   1   0   0   0   2]
 [  0   2   0   0   1   0   0   0   3   0  13   2   0   0   0   4]
 [  0  55   0   1   6   1   2   0 182  67  81  17   3   1   0  18]
 [  0  82   2   3   9   0   4   0 157 149 109  32   1   4   0  14]
 [  0  19   0   2   2   1   8   0  54  24 154  33   0   1   0  13]
 [  0  27   0   3   0   0   1   0  58  38 176  78   0   1   0  22]
 [  0   5   0   0   2   0   0   0  27   3  20   2   1   0   0   1]
 [  0   4   0   0   1   0   2   0  19  22  24   3   0   4   0   5]
 [  0   7   0   0   1   0   1   0  14   4  30   2   0   1   0  10]
 [  0   9   0   2   1   0   2   0  12   6  31  14   1   0   0  23]]
Classification Report:
             precision    recall  f1-score   support

       ENFJ       0.00      0.00      0.00        56
       ENFP       0.16      0.26      0.20       196
       ENTJ       0.25      0.02      0.03        58
       ENTP       0.24      0.02      0.04       201
       ESFJ       0.00      0.00      0.00        10
       ESFP       0.00      0.00      0.00         9
       ESTJ       0.00      0.00      0.00        17
       ESTP       0.00      0.00      0.00        25
       INFJ       0.28      0.42      0.33       434
       INFP       0.40      0.26      0.32       566
       INTJ       0.20      0.50      0.28       311
       INTP       0.36      0.19      0.25       404
       ISFJ       0.12      0.02      0.03        61
       ISFP       0.29      0.05      0.08        84
       ISTJ       0.00      0.00      0.00        70
       ISTP       0.16      0.23      0.19       101

avg / total       0.27      0.25      0.23      2603


    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
C:\textbackslash{}Users\textbackslash{}dhava\textbackslash{}Anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}metrics\textbackslash{}classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn\_for)

    \end{Verbatim}

    Using a OneVsRestClassifier model with LinearSVC as the estimator
object, the accuracy predicting the training set is 0.309, and
predicting on the training set the accuracy is 0.265 which is higher
than the 0.211 baseline. And while many of the predictions occur in the
Introversion-Intuitive classes as in the other models, it is not limited
to these classes as in the Random Forest model. There are predictions in
the Extroversion classes and the other Introversion classes as well.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}52}]:} \PY{c+c1}{\PYZsh{} Convert confusion matrix to a dataframe to prepare it for heatmapping}
         \PY{n}{cm\PYZus{}ovrc} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{ovrc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         
         \PY{n}{cm\PYZus{}onevsrest} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{cm\PYZus{}ovrc}\PY{p}{,} \PY{n}{index}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ENFJ}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ENFP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ENTJ}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ENTP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ESFJ}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ESFP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                                                \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ESTJ}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ESTP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{INFJ}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{INFP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{INTJ}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{INTP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                                                \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ISFJ}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ISFP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ISTJ}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ISTP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} 
                                     \PY{n}{columns}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}ENFJ}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}ENFP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}ENTJ}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                                              \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}ENTP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}ESFJ}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}ESFP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                                              \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}ESTJ}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}ESTP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}INFJ}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                                              \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}INFP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}INTJ}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}INTP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                                              \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}ISFJ}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}ISFP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}ISTJ}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                                              \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}ISTP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
         \PY{n}{cm\PYZus{}onevsrest}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}52}]:}       predict\_ENFJ  predict\_ENFP  predict\_ENTJ  predict\_ENTP  predict\_ESFJ  \textbackslash{}
         ENFJ             0            10             0             0             0   
         ENFP             0            51             0             0             5   
         ENTJ             0             5             1             2             2   
         ENTP             0            31             1             4             2   
         ESFJ             0             3             0             0             0   
         ESFP             0             1             0             0             0   
         ESTJ             0             4             0             0             1   
         ESTP             0             2             0             0             1   
         INFJ             0            55             0             1             6   
         INFP             0            82             2             3             9   
         INTJ             0            19             0             2             2   
         INTP             0            27             0             3             0   
         ISFJ             0             5             0             0             2   
         ISFP             0             4             0             0             1   
         ISTJ             0             7             0             0             1   
         ISTP             0             9             0             2             1   
         
               predict\_ESFP  predict\_ESTJ  predict\_ESTP  predict\_INFJ  predict\_INFP  \textbackslash{}
         ENFJ             0             1             0            23            10   
         ENFP             1             2             2            58            32   
         ENTJ             0             1             0            12             4   
         ENTP             1             4             1            34             9   
         ESFJ             0             0             0             3             0   
         ESFP             0             0             0             2             1   
         ESTJ             0             0             0             3             2   
         ESTP             0             0             0             3             0   
         INFJ             1             2             0           182            67   
         INFP             0             4             0           157           149   
         INTJ             1             8             0            54            24   
         INTP             0             1             0            58            38   
         ISFJ             0             0             0            27             3   
         ISFP             0             2             0            19            22   
         ISTJ             0             1             0            14             4   
         ISTP             0             2             0            12             6   
         
               predict\_INTJ  predict\_INTP  predict\_ISFJ  predict\_ISFP  predict\_ISTJ  \textbackslash{}
         ENFJ             7             3             0             0             0   
         ENFP            29             6             0             1             0   
         ENTJ            24             4             0             0             0   
         ENTP            81            19             1             0             0   
         ESFJ             2             0             1             1             0   
         ESFP             3             1             0             0             0   
         ESTJ             4             1             0             0             0   
         ESTP            13             2             0             0             0   
         INFJ            81            17             3             1             0   
         INFP           109            32             1             4             0   
         INTJ           154            33             0             1             0   
         INTP           176            78             0             1             0   
         ISFJ            20             2             1             0             0   
         ISFP            24             3             0             4             0   
         ISTJ            30             2             0             1             0   
         ISTP            31            14             1             0             0   
         
               predict\_ISTP  
         ENFJ             2  
         ENFP             9  
         ENTJ             3  
         ENTP            13  
         ESFJ             0  
         ESFP             1  
         ESTJ             2  
         ESTP             4  
         INFJ            18  
         INFP            14  
         INTJ            13  
         INTP            22  
         ISFJ             1  
         ISFP             5  
         ISTJ            10  
         ISTP            23  
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}53}]:} \PY{c+c1}{\PYZsh{} Create confusion matrix heatmap of One vs. Rest model }
         \PY{n}{fig}\PY{p}{,} \PY{n}{ax} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{14}\PY{p}{,}\PY{l+m+mi}{10}\PY{p}{)}\PY{p}{)} 
         \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Confusion Matrix for One Vs Rest}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                   \PY{n}{fontweight}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bold}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{l+m+mf}{1.02}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{16}\PY{p}{)}
         \PY{n}{sns}\PY{o}{.}\PY{n}{heatmap}\PY{p}{(}\PY{n}{cm\PYZus{}onevsrest}\PY{p}{,} \PY{n}{robust}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{annot}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{linewidth}\PY{o}{=}\PY{l+m+mf}{0.5}\PY{p}{,} 
                     \PY{n}{fmt}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{cmap}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{RdBu\PYZus{}r}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{vmax}\PY{o}{=}\PY{l+m+mi}{303}\PY{p}{,} \PY{n}{ax}\PY{o}{=}\PY{n}{ax}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{yticks}\PY{p}{(}\PY{n}{rotation}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{xticks}\PY{p}{(}\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_102_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    The heatmapped confusion matrix above shows that, like the other two
models, the OneVsRest Classifier labels a majority of the cases as INFP
or INFJ, the two most abundant classes in the dataset. However, there
are predictions to the other classes as well, in particular the ENTP
class. Notably, there are a number of false positives for the ENTP
class, in which many members of the Introversion/Intuitive classes were
misattributed as ENTP.

     \#\#\# Binary classification (each of the 4 axes)

    \subparagraph{Baseline calculation}\label{baseline-calculation}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}54}]:} \PY{c+c1}{\PYZsh{} Determine baseline for each of the four axes}
         \PY{n}{baseline\PYZus{}IE} \PY{o}{=} \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{I\PYZhy{}E}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{max}\PY{p}{(}\PY{p}{)} \PY{o}{/} \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{I\PYZhy{}E}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}
         \PY{n}{baseline\PYZus{}NS} \PY{o}{=} \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{N\PYZhy{}S}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{max}\PY{p}{(}\PY{p}{)} \PY{o}{/} \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{N\PYZhy{}S}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}
         \PY{n}{baseline\PYZus{}TF} \PY{o}{=} \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{T\PYZhy{}F}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{max}\PY{p}{(}\PY{p}{)} \PY{o}{/} \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{T\PYZhy{}F}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}
         \PY{n}{baseline\PYZus{}JP} \PY{o}{=} \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{J\PYZhy{}P}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{max}\PY{p}{(}\PY{p}{)} \PY{o}{/} \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{J\PYZhy{}P}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}
         
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Introversion \PYZhy{} Extroversion: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{baseline\PYZus{}IE}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Intuition \PYZhy{} Sensing: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{baseline\PYZus{}NS}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Thinking \PYZhy{} Feeling: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{baseline\PYZus{}TF}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Judging \PYZhy{} Perceiving: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{baseline\PYZus{}JP}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Introversion - Extroversion:  0.7695677233429394
Intuition - Sensing:  0.8620172910662824
Thinking - Feeling:  0.5410951008645534
Judging - Perceiving:  0.604149855907781

    \end{Verbatim}

    The calculated baselines are: - Introversion - Extroversion = 0.769 -
Intuition - Sensing = 0.862 - Thinking - Feeling = 0.541 - Judging -
Perceiving = 0.604

The Introversion-Extroversion axis, and particularly the
Intuition-Sensing axis, are quite imbalanced. The Thinkin-Feeling axis,
and to a lesser extent the Judging-Perceiving axis, are relatively more
balanced.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}55}]:} \PY{c+c1}{\PYZsh{} Train\PYZhy{}test splits, using type variables as target and posts variable as predictor}
         \PY{c+c1}{\PYZsh{} Introversion \PYZhy{} Extroversion}
         \PY{n}{X\PYZus{}train\PYZus{}IE}\PY{p}{,} \PY{n}{X\PYZus{}test\PYZus{}IE}\PY{p}{,} \PY{n}{y\PYZus{}train\PYZus{}IE}\PY{p}{,} \PY{n}{y\PYZus{}test\PYZus{}IE} \PY{o}{=} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{posts}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{values}\PY{p}{,}
                                                            \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{I\PYZhy{}E}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{values}\PY{p}{,}
                                                            \PY{n}{test\PYZus{}size}\PY{o}{=}\PY{l+m+mf}{0.30}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{42}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} Intuition \PYZhy{} Sensing}
         \PY{n}{X\PYZus{}train\PYZus{}NS}\PY{p}{,} \PY{n}{X\PYZus{}test\PYZus{}NS}\PY{p}{,} \PY{n}{y\PYZus{}train\PYZus{}NS}\PY{p}{,} \PY{n}{y\PYZus{}test\PYZus{}NS} \PY{o}{=} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{posts}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{values}\PY{p}{,}
                                                            \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{N\PYZhy{}S}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{values}\PY{p}{,}
                                                            \PY{n}{test\PYZus{}size}\PY{o}{=}\PY{l+m+mf}{0.30}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{42}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} Thinking \PYZhy{} Feeling}
         \PY{n}{X\PYZus{}train\PYZus{}TF}\PY{p}{,} \PY{n}{X\PYZus{}test\PYZus{}TF}\PY{p}{,} \PY{n}{y\PYZus{}train\PYZus{}TF}\PY{p}{,} \PY{n}{y\PYZus{}test\PYZus{}TF} \PY{o}{=} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{posts}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{values}\PY{p}{,}
                                                            \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{T\PYZhy{}F}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{values}\PY{p}{,}
                                                            \PY{n}{test\PYZus{}size}\PY{o}{=}\PY{l+m+mf}{0.30}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{42}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} Judging \PYZhy{} Perceiving}
         \PY{n}{X\PYZus{}train\PYZus{}JP}\PY{p}{,} \PY{n}{X\PYZus{}test\PYZus{}JP}\PY{p}{,} \PY{n}{y\PYZus{}train\PYZus{}JP}\PY{p}{,} \PY{n}{y\PYZus{}test\PYZus{}JP} \PY{o}{=} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{posts}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{values}\PY{p}{,}
                                                            \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{J\PYZhy{}P}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{values}\PY{p}{,}
                                                            \PY{n}{test\PYZus{}size}\PY{o}{=}\PY{l+m+mf}{0.30}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{42}\PY{p}{)}
\end{Verbatim}


    \paragraph{Use Truncated SVD to determine optimal number of components
for the binary
classifications}\label{use-truncated-svd-to-determine-optimal-number-of-components-for-the-binary-classifications}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}56}]:} \PY{c+c1}{\PYZsh{} First run CountVectorizer on the X train/test (\PYZsq{}posts\PYZsq{} column) \PYZhy{} using I\PYZhy{}E axis as reference}
         \PY{n}{cv} \PY{o}{=} \PY{n}{CountVectorizer}\PY{p}{(}\PY{n}{preprocessor}\PY{o}{=}\PY{n}{cleaner}\PY{p}{,} \PY{n}{stop\PYZus{}words}\PY{o}{=}\PY{n}{stop\PYZus{}rev}\PY{p}{,} \PY{n}{ngram\PYZus{}range}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{)}\PY{p}{,} \PY{n}{max\PYZus{}features}\PY{o}{=}\PY{l+m+mi}{1000}\PY{p}{)}
         \PY{n}{cv}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}IE}\PY{p}{)}
         \PY{n}{X\PYZus{}train\PYZus{}IE\PYZus{}cv} \PY{o}{=} \PY{n}{cv}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}IE}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Use max components and graph the explained variance ratio to find cutoff point }
         \PY{n}{tsvd} \PY{o}{=} \PY{n}{TruncatedSVD}\PY{p}{(}\PY{n}{n\PYZus{}components}\PY{o}{=}\PY{l+m+mi}{999}\PY{p}{)}
         \PY{n}{tsvd}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}IE\PYZus{}cv}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{999}\PY{p}{)}\PY{p}{,} \PY{n}{tsvd}\PY{o}{.}\PY{n}{explained\PYZus{}variance\PYZus{}ratio\PYZus{}}\PY{o}{.}\PY{n}{cumsum}\PY{p}{(}\PY{p}{)}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Truncated SVD \PYZhy{} Optimal \PYZsh{} of components (for binary classification models)}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{16}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZsh{} of components}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Explained variance ratio}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_110_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    The graph above suggests that approximately 100 components would be most
effective for the binary classification models, since that is where the
explained variance begins to flatten out.

    \paragraph{Preprocessing Pipeline for the binary
classifications}\label{preprocessing-pipeline-for-the-binary-classifications}

\emph{Similar to the pipeline for the 16-class classifications, except
100 components are used in the Truncated SVD instead of 175.}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}57}]:} \PY{c+c1}{\PYZsh{} Create pipeline for the data preprocessing steps (CountVectorizer, TruncatedSVD) on the X data}
         \PY{n}{pipeline\PYZus{}preprocessing2} \PY{o}{=} \PY{n}{make\PYZus{}pipeline}\PY{p}{(}
             \PY{n}{CountVectorizer}\PY{p}{(}\PY{n}{preprocessor}\PY{o}{=}\PY{n}{cleaner}\PY{p}{,} \PY{n}{stop\PYZus{}words}\PY{o}{=}\PY{n}{stop\PYZus{}rev}\PY{p}{,} \PY{n}{ngram\PYZus{}range}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{)}\PY{p}{,} \PY{n}{max\PYZus{}features}\PY{o}{=}\PY{l+m+mi}{1000}\PY{p}{)}\PY{p}{,}
             \PY{n}{TruncatedSVD}\PY{p}{(}\PY{n}{n\PYZus{}components}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}58}]:} \PY{c+c1}{\PYZsh{} Preprocess each of the train\PYZhy{}test splits}
         \PY{c+c1}{\PYZsh{} Introversion \PYZhy{} Extroversion}
         \PY{n}{X\PYZus{}train\PYZus{}IE\PYZus{}tsvd} \PY{o}{=} \PY{n}{pipeline\PYZus{}preprocessing2}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}IE}\PY{p}{)}
         \PY{n}{X\PYZus{}test\PYZus{}IE\PYZus{}tsvd} \PY{o}{=} \PY{n}{pipeline\PYZus{}preprocessing2}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}IE}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Intuition \PYZhy{} Sensing}
         \PY{n}{X\PYZus{}train\PYZus{}NS\PYZus{}tsvd} \PY{o}{=} \PY{n}{pipeline\PYZus{}preprocessing2}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}NS}\PY{p}{)}
         \PY{n}{X\PYZus{}test\PYZus{}NS\PYZus{}tsvd} \PY{o}{=} \PY{n}{pipeline\PYZus{}preprocessing2}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}NS}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Thinking \PYZhy{} Feeling}
         \PY{n}{X\PYZus{}train\PYZus{}TF\PYZus{}tsvd} \PY{o}{=} \PY{n}{pipeline\PYZus{}preprocessing2}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}TF}\PY{p}{)}
         \PY{n}{X\PYZus{}test\PYZus{}TF\PYZus{}tsvd} \PY{o}{=} \PY{n}{pipeline\PYZus{}preprocessing2}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}TF}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Judging \PYZhy{} Perceiving}
         \PY{n}{X\PYZus{}train\PYZus{}JP\PYZus{}tsvd} \PY{o}{=} \PY{n}{pipeline\PYZus{}preprocessing2}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}JP}\PY{p}{)}
         \PY{n}{X\PYZus{}test\PYZus{}JP\PYZus{}tsvd} \PY{o}{=} \PY{n}{pipeline\PYZus{}preprocessing2}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}JP}\PY{p}{)}
\end{Verbatim}


    \subsubsection{Introversion - Extroversion axis
modeling}\label{introversion---extroversion-axis-modeling}

    For the \emph{Introversion-Extroversion} axis, the baseline is 0.769
with \emph{Introversion} being the majority class. Using a random forest
classifier with the default parameters, the accuracy was 0.735. 91\% of
the \emph{Introversion} cases were predicted accurately, while only 13\%
of the \emph{Extroversion} cases were.

A grid search was run to find the optimal parameters to use. The initial
grid search suggested that the optimal hyperparameters are a minimum of
8 samples required to be at a leaf node, a minimum of 3 samples required
to split an internal node, 14 estimators (trees in the forest), entropy
criterion for information gain (to measure the quality of a split), and
no bootstrap samples used when building trees.

Using the suggested hyperparameters increased the accuracy to 0.777,
with 99\% of the Introversion cases being predicted accurately. However,
the accuracy rate for predicting \emph{Extroversion} cases dropped to
just 1\%. The model was inaccurately predicting most of the
\emph{Extroversion} cases as members of the majority case,
\emph{Introversion}.

Due to the unbalanced nature of the initial training sample, SMOTE was
then used for over-sampling the minority class to try to improve the
model. A subsequent grid search on the that sample suggested the optimal
parameters are minimum 1 samples at a leaf, minimum 6 samples to split a
node, 76 estimators, gini criterion, and no bootstrap samples.

Using these hyperparameters on the sample that had undergone SMOTE
results in an accuracy of 0.727, with 88\% of the \emph{Introversion}
class predicted correctly. However, only 17\% of the \emph{Extroversion}
cases were accurately predicted. The final F1 score for the
\emph{Introversion} class is 0.83, and for \emph{Extroversion} it is
0.21.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}59}]:} \PY{c+c1}{\PYZsh{} Use SMOTE (Synthetic Minority Over\PYZhy{}sampling Technique) to even out the unbalanced test sample}
         \PY{n}{sm} \PY{o}{=} \PY{n}{SMOTE}\PY{p}{(}\PY{p}{)}
         \PY{n}{Xsm\PYZus{}train\PYZus{}IE\PYZus{}tsvd}\PY{p}{,} \PY{n}{ysm\PYZus{}train\PYZus{}IE} \PY{o}{=} \PY{n}{sm}\PY{o}{.}\PY{n}{fit\PYZus{}sample}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}IE\PYZus{}tsvd}\PY{p}{,} \PY{n}{y\PYZus{}train\PYZus{}IE}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}60}]:} \PY{c+c1}{\PYZsh{} Grid Search to find the best parameters on Random Forest Classifier for the SMOTEd sample}
         \PY{n}{rfc\PYZus{}dict} \PY{o}{=} \PY{p}{\PYZob{}}
             \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bootstrap}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{True}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{False}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}
             \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{criterion}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{gini}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{entropy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}
             \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{min\PYZus{}samples\PYZus{}leaf}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{]}\PY{p}{,}
             \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{min\PYZus{}samples\PYZus{}split}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{6}\PY{p}{,}\PY{l+m+mi}{7}\PY{p}{]}\PY{p}{,}
             \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{n\PYZus{}estimators}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+m+mi}{73}\PY{p}{,}\PY{l+m+mi}{74}\PY{p}{,}\PY{l+m+mi}{75}\PY{p}{,}\PY{l+m+mi}{76}\PY{p}{,}\PY{l+m+mi}{77}\PY{p}{]}\PY{p}{\PYZcb{}}
                
         \PY{n}{rfc} \PY{o}{=} \PY{n}{RandomForestClassifier}\PY{p}{(}\PY{p}{)}
         \PY{n}{gs\PYZus{}rfc} \PY{o}{=} \PY{n}{GridSearchCV}\PY{p}{(}\PY{n}{rfc}\PY{p}{,} \PY{n}{rfc\PYZus{}dict}\PY{p}{,} \PY{n}{n\PYZus{}jobs}\PY{o}{=}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{)} \PY{c+c1}{\PYZsh{} n\PYZus{}jobs = \PYZhy{}1 sets the number of jobs = CPU cores}
         \PY{n}{gs\PYZus{}rfc}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{Xsm\PYZus{}train\PYZus{}IE\PYZus{}tsvd}\PY{p}{,} \PY{n}{ysm\PYZus{}train\PYZus{}IE}\PY{p}{)}
         
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Best score: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{gs\PYZus{}rfc}\PY{o}{.}\PY{n}{best\PYZus{}score\PYZus{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Best parameters: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{gs\PYZus{}rfc}\PY{o}{.}\PY{n}{best\PYZus{}params\PYZus{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Best score:  0.8616792249730894
Best parameters:  \{'bootstrap': 'True', 'criterion': 'gini', 'min\_samples\_leaf': 1, 'min\_samples\_split': 5, 'n\_estimators': 74\}

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}61}]:} \PY{c+c1}{\PYZsh{} Fit and score a Random Forest Classifier on SMOTEd data using the parameters identified by the grid search}
         \PY{n}{rfc} \PY{o}{=} \PY{n}{RandomForestClassifier}\PY{p}{(}\PY{n}{min\PYZus{}samples\PYZus{}leaf}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{min\PYZus{}samples\PYZus{}split}\PY{o}{=}\PY{l+m+mi}{6}\PY{p}{,} \PY{n}{n\PYZus{}estimators}\PY{o}{=}\PY{l+m+mi}{76}\PY{p}{,} 
                                      \PY{n}{criterion}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{gini}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{bootstrap}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{False}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{n\PYZus{}jobs}\PY{o}{=} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{123}\PY{p}{)}
         \PY{n}{rfc}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{Xsm\PYZus{}train\PYZus{}IE\PYZus{}tsvd}\PY{p}{,} \PY{n}{ysm\PYZus{}train\PYZus{}IE}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{TRAINING SET}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Accuracy: }\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{score}\PY{p}{(}\PY{n}{Xsm\PYZus{}train\PYZus{}IE\PYZus{}tsvd}\PY{p}{,} \PY{n}{ysm\PYZus{}train\PYZus{}IE}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Confusion Matrix (counts):}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{ysm\PYZus{}train\PYZus{}IE}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{Xsm\PYZus{}train\PYZus{}IE\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Confusion Matrix (percentages):}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{ysm\PYZus{}train\PYZus{}IE}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{Xsm\PYZus{}train\PYZus{}IE\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{x}\PY{o}{/}\PY{n}{x}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}\PY{p}{,}\PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Classification Report:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{classification\PYZus{}report}\PY{p}{(}\PY{n}{ysm\PYZus{}train\PYZus{}IE}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{Xsm\PYZus{}train\PYZus{}IE\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{TEST SET}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Accuracy: }\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{score}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}IE\PYZus{}tsvd}\PY{p}{,} \PY{n}{y\PYZus{}test\PYZus{}IE}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Confusion Matrix (counts):}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}test\PYZus{}IE}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}IE\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Confusion Matrix (percentages):}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}test\PYZus{}IE}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}IE\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{x}\PY{o}{/}\PY{n}{x}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}\PY{p}{,}\PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Classification Report:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{classification\PYZus{}report}\PY{p}{(}\PY{n}{y\PYZus{}test\PYZus{}IE}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}IE\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
TRAINING SET
Accuracy:  1.0
Confusion Matrix (counts):
[[4645    0]
 [   0 4645]]
Confusion Matrix (percentages):
     0    1
0  1.0  0.0
1  0.0  1.0
Classification Report:
              precision    recall  f1-score   support

Extroversion       1.00      1.00      1.00      4645
Introversion       1.00      1.00      1.00      4645

 avg / total       1.00      1.00      1.00      9290


TEST SET
Accuracy:  0.7322320399538993
Confusion Matrix (counts):
[[ 103  469]
 [ 228 1803]]
Confusion Matrix (percentages):
         0        1
0  0.18007  0.81993
1  0.11226  0.88774
Classification Report:
              precision    recall  f1-score   support

Extroversion       0.31      0.18      0.23       572
Introversion       0.79      0.89      0.84      2031

 avg / total       0.69      0.73      0.70      2603


    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}62}]:} \PY{c+c1}{\PYZsh{} Convert confusion matrix to a dataframe to prepare it for heatmapping}
         \PY{n}{cm\PYZus{}rfc\PYZus{}IE} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}test\PYZus{}IE}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}IE\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         
         \PY{n}{cm\PYZus{}randomforest\PYZus{}IE} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{cm\PYZus{}rfc\PYZus{}IE}\PY{p}{,} \PY{n}{index}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Extroversion}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Introversion}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}
                                          \PY{n}{columns}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}Extroversion}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}Introversion}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PYZbs{}
         \PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{x}\PY{o}{/}\PY{n}{x}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}\PY{p}{,}\PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Create confusion matrix heatmap of Random Forest Classifier model }
         \PY{n}{fig}\PY{p}{,} \PY{n}{ax} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{6}\PY{p}{,}\PY{l+m+mi}{4}\PY{p}{)}\PY{p}{)} 
         \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Confusion Matrix for Random Forest Classifier: Introversion \PYZhy{} Extroversion Axis}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{16}\PY{p}{,}
                   \PY{n}{fontweight}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bold}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{l+m+mf}{1.02}\PY{p}{)}
         \PY{n}{sns}\PY{o}{.}\PY{n}{heatmap}\PY{p}{(}\PY{n}{cm\PYZus{}randomforest\PYZus{}IE}\PY{p}{,} \PY{n}{robust}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{annot}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{linewidth}\PY{o}{=}\PY{l+m+mf}{0.5}\PY{p}{,} 
                     \PY{n}{fmt}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{cmap}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{RdBu\PYZus{}r}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{vmax}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{ax}\PY{o}{=}\PY{n}{ax}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{xticks}\PY{p}{(}\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{yticks}\PY{p}{(}\PY{n}{rotation}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_120_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \subsubsection{Intuition - Sensing axis
modeling}\label{intuition---sensing-axis-modeling}

    The baseline for the \emph{Intuition - Sensing} axis is 0.862, with
\emph{Intuition} being the majority class. A random forest classifier
with the default parameters gives an accuracy of 0.855, with over 99\%
of the \emph{Intuition} cases predicteded accurately. However, just
under 2\% of the \emph{Sensing} cases were correctly predicted.
Furthermore, while the initial F1 score for \emph{Intuition} is 0.92,
for \emph{Sensing} it is just 0.04.

A grid search was run to determine the optimal hyperparameters. The
initial grid search returned parameters of a minimum of 2 samples at
leaf nodes, minimum 2 samples for node splits, 25 estimators, gini
criterion, and bootstrap samples included.

Using the suggested hyperparameters increased the accuracy only
slightly, with a negligible change after rounding. Again, over 99\% of
the \emph{Intuition} cases were accurately predicted, but now less than
1\% of the \emph{Sensing} cases were - they were being misclassified as
the majority case, \emph{Intuition}.

\emph{Intuition - Sensing} was the most unbalanced of the four axes, so
SMOTE was applied to oversample the minority class in an attempt to
improve the model. A grid search on this sample returned the optimal
hyperparameters of a minimum 1 samples at a leaf, minimum 3 samples to
split a node, 82 estimators, gini criterion, and no bootstrap samples.
With these hyperparameters, the random forest classification then
reached an accuracy of 0.819; this is lower than the baseline, with 94\%
of the \emph{Intuition} and 12\% of the \emph{Sensing} cases accurately
predicted - still low, but an improvement over the untuned model. The
final F1 score for \emph{Intuition} is 0.90, while for \emph{Sensing} it
shows a slight increase to 0.16.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}63}]:} \PY{c+c1}{\PYZsh{} Fit and score a Random Forest Classifier using the default parameters}
         \PY{n}{rfc} \PY{o}{=} \PY{n}{RandomForestClassifier}\PY{p}{(}\PY{n}{n\PYZus{}jobs}\PY{o}{=} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{123}\PY{p}{)}
         \PY{n}{rfc}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}NS\PYZus{}tsvd}\PY{p}{,} \PY{n}{y\PYZus{}train\PYZus{}NS}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{TRAINING SET}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Accuracy: }\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{score}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}NS\PYZus{}tsvd}\PY{p}{,} \PY{n}{y\PYZus{}train\PYZus{}NS}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Confusion Matrix (counts):}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}train\PYZus{}NS}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}NS\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Confusion Matrix (percentages):}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}train\PYZus{}NS}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}NS\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{x}\PY{o}{/}\PY{n}{x}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}\PY{p}{,}\PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Classification Report:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{classification\PYZus{}report}\PY{p}{(}\PY{n}{y\PYZus{}train\PYZus{}NS}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}NS\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{TEST SET}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Accuracy: }\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{score}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}NS\PYZus{}tsvd}\PY{p}{,} \PY{n}{y\PYZus{}test\PYZus{}NS}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Confusion Matrix (counts):}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}test\PYZus{}NS}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}NS\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Confusion Matrix (percentages):}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}test\PYZus{}NS}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}NS\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{x}\PY{o}{/}\PY{n}{x}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}\PY{p}{,}\PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Classification Report:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{classification\PYZus{}report}\PY{p}{(}\PY{n}{y\PYZus{}test\PYZus{}NS}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}NS\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
TRAINING SET
Accuracy:  0.9794137022397892
Confusion Matrix (counts):
[[5251    1]
 [ 124  696]]
Confusion Matrix (percentages):
         0        1
0  0.99981  0.00019
1  0.15122  0.84878
Classification Report:
             precision    recall  f1-score   support

  Intuition       0.98      1.00      0.99      5252
    Sensing       1.00      0.85      0.92       820

avg / total       0.98      0.98      0.98      6072


TEST SET
Accuracy:  0.8520937379946216
Confusion Matrix (counts):
[[2214   12]
 [ 373    4]]
Confusion Matrix (percentages):
          0         1
0  0.994609  0.005391
1  0.989390  0.010610
Classification Report:
             precision    recall  f1-score   support

  Intuition       0.86      0.99      0.92      2226
    Sensing       0.25      0.01      0.02       377

avg / total       0.77      0.85      0.79      2603


    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}65}]:} \PY{c+c1}{\PYZsh{} Grid Search to find the best parameters on Random Forest Classifier}
         \PY{n}{rfc\PYZus{}dict} \PY{o}{=} \PY{p}{\PYZob{}}
             \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bootstrap}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{True}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{False}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}
             \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{criterion}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{gini}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{entropy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}
             \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{min\PYZus{}samples\PYZus{}leaf}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{]}\PY{p}{,}
             \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{min\PYZus{}samples\PYZus{}split}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{,}\PY{l+m+mi}{4}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{6}\PY{p}{]}\PY{p}{,}
             \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{n\PYZus{}estimators}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+m+mi}{25}\PY{p}{,}\PY{l+m+mi}{26}\PY{p}{,}\PY{l+m+mi}{27}\PY{p}{]}\PY{p}{\PYZcb{}}
                
         \PY{n}{rfc} \PY{o}{=} \PY{n}{RandomForestClassifier}\PY{p}{(}\PY{p}{)}
         \PY{n}{gs\PYZus{}rfc} \PY{o}{=} \PY{n}{GridSearchCV}\PY{p}{(}\PY{n}{rfc}\PY{p}{,} \PY{n}{rfc\PYZus{}dict}\PY{p}{,} \PY{n}{verbose}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{n\PYZus{}jobs}\PY{o}{=}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{)} \PY{c+c1}{\PYZsh{} n\PYZus{}jobs = \PYZhy{}1, sets the number of jobs = CPU cores}
         \PY{n}{gs\PYZus{}rfc}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}NS\PYZus{}tsvd}\PY{p}{,} \PY{n}{y\PYZus{}train\PYZus{}NS}\PY{p}{)}
         
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Best score: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{gs\PYZus{}rfc}\PY{o}{.}\PY{n}{best\PYZus{}score\PYZus{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Best parameters: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{gs\PYZus{}rfc}\PY{o}{.}\PY{n}{best\PYZus{}params\PYZus{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Best score:  0.8651185770750988
Best parameters:  \{'bootstrap': 'True', 'criterion': 'gini', 'min\_samples\_leaf': 2, 'min\_samples\_split': 5, 'n\_estimators': 26\}

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}66}]:} \PY{c+c1}{\PYZsh{} Fit and score a Random Forest Classifier using the parameters identified by the grid search}
         \PY{n}{rfc} \PY{o}{=} \PY{n}{RandomForestClassifier}\PY{p}{(}\PY{n}{min\PYZus{}samples\PYZus{}leaf}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{,} \PY{n}{min\PYZus{}samples\PYZus{}split}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{,} \PY{n}{n\PYZus{}estimators}\PY{o}{=}\PY{l+m+mi}{25}\PY{p}{,} 
                                      \PY{n}{criterion}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{gini}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{bootstrap}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{True}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{n\PYZus{}jobs}\PY{o}{=} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{123}\PY{p}{)}
         \PY{n}{rfc}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}NS\PYZus{}tsvd}\PY{p}{,} \PY{n}{y\PYZus{}train\PYZus{}NS}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{TRAINING SET}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Accuracy: }\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{score}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}NS\PYZus{}tsvd}\PY{p}{,} \PY{n}{y\PYZus{}train\PYZus{}NS}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Confusion Matrix (counts):}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}train\PYZus{}NS}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}NS\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Confusion Matrix (percentages):}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}train\PYZus{}NS}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}NS\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{x}\PY{o}{/}\PY{n}{x}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}\PY{p}{,}\PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Classification Report:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{classification\PYZus{}report}\PY{p}{(}\PY{n}{y\PYZus{}train\PYZus{}NS}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}NS\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{TEST SET}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Accuracy: }\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{score}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}NS\PYZus{}tsvd}\PY{p}{,} \PY{n}{y\PYZus{}test\PYZus{}NS}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Confusion Matrix (counts):}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}test\PYZus{}NS}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}NS\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Confusion Matrix (percentages):}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}test\PYZus{}NS}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}NS\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{x}\PY{o}{/}\PY{n}{x}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}\PY{p}{,}\PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Classification Report:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{classification\PYZus{}report}\PY{p}{(}\PY{n}{y\PYZus{}test\PYZus{}NS}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}NS\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
TRAINING SET
Accuracy:  0.9808959156785244
Confusion Matrix (counts):
[[5252    0]
 [ 116  704]]
Confusion Matrix (percentages):
          0         1
0  1.000000  0.000000
1  0.141463  0.858537
Classification Report:
             precision    recall  f1-score   support

  Intuition       0.98      1.00      0.99      5252
    Sensing       1.00      0.86      0.92       820

avg / total       0.98      0.98      0.98      6072


TEST SET
Accuracy:  0.8555512869765655
Confusion Matrix (counts):
[[2224    2]
 [ 374    3]]
Confusion Matrix (percentages):
          0         1
0  0.999102  0.000898
1  0.992042  0.007958
Classification Report:
             precision    recall  f1-score   support

  Intuition       0.86      1.00      0.92      2226
    Sensing       0.60      0.01      0.02       377

avg / total       0.82      0.86      0.79      2603


    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}67}]:} \PY{c+c1}{\PYZsh{} Use SMOTE (Synthetic Minority Over\PYZhy{}sampling Technique) to even out the unbalanced test sample}
         \PY{n}{sm} \PY{o}{=} \PY{n}{SMOTE}\PY{p}{(}\PY{p}{)}
         \PY{n}{Xsm\PYZus{}train\PYZus{}NS\PYZus{}tsvd}\PY{p}{,} \PY{n}{ysm\PYZus{}train\PYZus{}NS} \PY{o}{=} \PY{n}{sm}\PY{o}{.}\PY{n}{fit\PYZus{}sample}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}NS\PYZus{}tsvd}\PY{p}{,} \PY{n}{y\PYZus{}train\PYZus{}NS}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}68}]:} \PY{c+c1}{\PYZsh{} Grid Search to find the best parameters on Random Forest Classifier for the SMOTEd sample}
         \PY{n}{rfc\PYZus{}dict} \PY{o}{=} \PY{p}{\PYZob{}}
             \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bootstrap}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{True}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{False}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}
             \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{criterion}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{gini}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{entropy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}
             \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{min\PYZus{}samples\PYZus{}leaf}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{]}\PY{p}{,}
             \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{min\PYZus{}samples\PYZus{}split}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{,}\PY{l+m+mi}{4}\PY{p}{]}\PY{p}{,}
             \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{n\PYZus{}estimators}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+m+mi}{75}\PY{p}{,}\PY{l+m+mi}{76}\PY{p}{,}\PY{l+m+mi}{77}\PY{p}{,}\PY{l+m+mi}{78}\PY{p}{,}\PY{l+m+mi}{79}\PY{p}{,}\PY{l+m+mi}{80}\PY{p}{,}\PY{l+m+mi}{81}\PY{p}{,}\PY{l+m+mi}{82}\PY{p}{,}\PY{l+m+mi}{83}\PY{p}{,}\PY{l+m+mi}{84}\PY{p}{]}\PY{p}{\PYZcb{}}
                
         \PY{n}{rfc} \PY{o}{=} \PY{n}{RandomForestClassifier}\PY{p}{(}\PY{p}{)}
         \PY{n}{gs\PYZus{}rfc} \PY{o}{=} \PY{n}{GridSearchCV}\PY{p}{(}\PY{n}{rfc}\PY{p}{,} \PY{n}{rfc\PYZus{}dict}\PY{p}{,} \PY{n}{n\PYZus{}jobs}\PY{o}{=}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{)} \PY{c+c1}{\PYZsh{} n\PYZus{}jobs = \PYZhy{}1 sets the number of jobs = CPU cores}
         \PY{n}{gs\PYZus{}rfc}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{Xsm\PYZus{}train\PYZus{}NS\PYZus{}tsvd}\PY{p}{,} \PY{n}{ysm\PYZus{}train\PYZus{}NS}\PY{p}{)}
         
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Best score: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{gs\PYZus{}rfc}\PY{o}{.}\PY{n}{best\PYZus{}score\PYZus{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Best parameters: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{gs\PYZus{}rfc}\PY{o}{.}\PY{n}{best\PYZus{}params\PYZus{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Best score:  0.925932977913176
Best parameters:  \{'bootstrap': 'True', 'criterion': 'gini', 'min\_samples\_leaf': 1, 'min\_samples\_split': 2, 'n\_estimators': 83\}

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}69}]:} \PY{c+c1}{\PYZsh{} Fit and score a Random Forest Classifier on SMOTEd data using the parameters identified by the grid search}
         \PY{n}{rfc} \PY{o}{=} \PY{n}{RandomForestClassifier}\PY{p}{(}\PY{n}{min\PYZus{}samples\PYZus{}leaf}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{min\PYZus{}samples\PYZus{}split}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{,} \PY{n}{n\PYZus{}estimators}\PY{o}{=}\PY{l+m+mi}{82}\PY{p}{,} 
                                      \PY{n}{criterion}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{gini}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{bootstrap}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{False}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{n\PYZus{}jobs}\PY{o}{=} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{123}\PY{p}{)}
         \PY{n}{rfc}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{Xsm\PYZus{}train\PYZus{}NS\PYZus{}tsvd}\PY{p}{,} \PY{n}{ysm\PYZus{}train\PYZus{}NS}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{TRAINING SET}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Accuracy: }\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{score}\PY{p}{(}\PY{n}{Xsm\PYZus{}train\PYZus{}NS\PYZus{}tsvd}\PY{p}{,} \PY{n}{ysm\PYZus{}train\PYZus{}NS}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Confusion Matrix (counts):}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{ysm\PYZus{}train\PYZus{}NS}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{Xsm\PYZus{}train\PYZus{}NS\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Confusion Matrix (percentages):}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{ysm\PYZus{}train\PYZus{}NS}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{Xsm\PYZus{}train\PYZus{}NS\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{x}\PY{o}{/}\PY{n}{x}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}\PY{p}{,}\PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Classification Report:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{classification\PYZus{}report}\PY{p}{(}\PY{n}{ysm\PYZus{}train\PYZus{}NS}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{Xsm\PYZus{}train\PYZus{}NS\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{TEST SET}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Accuracy: }\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{score}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}NS\PYZus{}tsvd}\PY{p}{,} \PY{n}{y\PYZus{}test\PYZus{}NS}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Confusion Matrix (counts):}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}test\PYZus{}NS}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}NS\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Confusion Matrix (percentages):}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}test\PYZus{}NS}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}NS\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{x}\PY{o}{/}\PY{n}{x}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}\PY{p}{,}\PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Classification Report:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{classification\PYZus{}report}\PY{p}{(}\PY{n}{y\PYZus{}test\PYZus{}NS}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}NS\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
TRAINING SET
Accuracy:  1.0
Confusion Matrix (counts):
[[5252    0]
 [   0 5252]]
Confusion Matrix (percentages):
     0    1
0  1.0  0.0
1  0.0  1.0
Classification Report:
             precision    recall  f1-score   support

  Intuition       1.00      1.00      1.00      5252
    Sensing       1.00      1.00      1.00      5252

avg / total       1.00      1.00      1.00     10504


TEST SET
Accuracy:  0.8186707645024971
Confusion Matrix (counts):
[[2091  135]
 [ 337   40]]
Confusion Matrix (percentages):
          0         1
0  0.939353  0.060647
1  0.893899  0.106101
Classification Report:
             precision    recall  f1-score   support

  Intuition       0.86      0.94      0.90      2226
    Sensing       0.23      0.11      0.14       377

avg / total       0.77      0.82      0.79      2603


    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}70}]:} \PY{c+c1}{\PYZsh{} Convert confusion matrix to a dataframe to prepare it for heatmapping}
         \PY{n}{cm\PYZus{}rfc\PYZus{}NS} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}test\PYZus{}NS}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}NS\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         
         \PY{n}{cm\PYZus{}randomforest\PYZus{}NS} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{cm\PYZus{}rfc\PYZus{}NS}\PY{p}{,} \PY{n}{index}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Intuition}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Sensing}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}
                                          \PY{n}{columns}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}Intuition}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}Sensing}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PYZbs{}
         \PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{x}\PY{o}{/}\PY{n}{x}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}\PY{p}{,}\PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Create confusion matrix heatmap of Random Forest Classifier model }
         \PY{n}{fig}\PY{p}{,} \PY{n}{ax} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{6}\PY{p}{,}\PY{l+m+mi}{4}\PY{p}{)}\PY{p}{)} 
         \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Confusion Matrix for Random Forest Classifier: Intuition \PYZhy{} Sensing Axis}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{16}\PY{p}{,}
                   \PY{n}{fontweight}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bold}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{l+m+mf}{1.02}\PY{p}{)}
         \PY{n}{sns}\PY{o}{.}\PY{n}{heatmap}\PY{p}{(}\PY{n}{cm\PYZus{}randomforest\PYZus{}NS}\PY{p}{,} \PY{n}{robust}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{annot}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{linewidth}\PY{o}{=}\PY{l+m+mf}{0.5}\PY{p}{,} 
                     \PY{n}{fmt}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{cmap}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{RdBu\PYZus{}r}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{vmax}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{ax}\PY{o}{=}\PY{n}{ax}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{xticks}\PY{p}{(}\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{yticks}\PY{p}{(}\PY{n}{rotation}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_129_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \subsubsection{Thinking - Feeling axis
modeling}\label{thinking---feeling-axis-modeling}

    The \emph{Thinking - Feeling} axis has a baseline of 0.541, making it
the most balanced of the four axes. The majority class is
\emph{Feeling}. Running a random forest classifer with the default
parameters results in an accuracy of 0.624, with 76\% of the
\emph{Thinking} class and 45\% of the \emph{Feeling} class being
predicted accurately. The initial F1 score for the \emph{Feeling} class
is 0.69, and for \emph{Thinking} it is 0.52.

A grid search was performed and determined the optimal paramters are a
minimum of 3 samples required to be at a leaf node, minimum of 2 samples
required to split an internal node, 86 estimators, entropy criterion,
and no bootstrap samples.

The random forest classifier using the suggested hyperparameters
resulted in an accuracy of 0.697, with 76\% of the \emph{Feeling} and
62\% of the \emph{Thinking} classes being accurately predicted. The
final F1 score for the \emph{Feeling} class is 0.73, and for the
\emph{Thinking} class it is 0.65.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}71}]:} \PY{c+c1}{\PYZsh{} Fit and score a Random Forest Classifier using the default parameters}
         \PY{n}{rfc} \PY{o}{=} \PY{n}{RandomForestClassifier}\PY{p}{(}\PY{n}{n\PYZus{}jobs}\PY{o}{=} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{123}\PY{p}{)}
         \PY{n}{rfc}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}TF\PYZus{}tsvd}\PY{p}{,} \PY{n}{y\PYZus{}train\PYZus{}TF}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{TRAINING SET}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Accuracy: }\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{score}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}TF\PYZus{}tsvd}\PY{p}{,} \PY{n}{y\PYZus{}train\PYZus{}TF}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Confusion Matrix (counts):}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}train\PYZus{}TF}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}TF\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Confusion Matrix (percentages):}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}train\PYZus{}TF}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}TF\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{x}\PY{o}{/}\PY{n}{x}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}\PY{p}{,}\PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Classification Report:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{classification\PYZus{}report}\PY{p}{(}\PY{n}{y\PYZus{}train\PYZus{}TF}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}TF\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{TEST SET}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Accuracy: }\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{score}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}TF\PYZus{}tsvd}\PY{p}{,} \PY{n}{y\PYZus{}test\PYZus{}TF}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Confusion Matrix (counts):}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}test\PYZus{}TF}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}TF\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Confusion Matrix (percentages):}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}test\PYZus{}TF}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}TF\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{x}\PY{o}{/}\PY{n}{x}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}\PY{p}{,}\PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Classification Report:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{classification\PYZus{}report}\PY{p}{(}\PY{n}{y\PYZus{}test\PYZus{}TF}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}TF\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
TRAINING SET
Accuracy:  0.9869894598155468
Confusion Matrix (counts):
[[3268   10]
 [  69 2725]]
Confusion Matrix (percentages):
          0         1
0  0.996949  0.003051
1  0.024696  0.975304
Classification Report:
             precision    recall  f1-score   support

    Feeling       0.98      1.00      0.99      3278
   Thinking       1.00      0.98      0.99      2794

avg / total       0.99      0.99      0.99      6072


TEST SET
Accuracy:  0.6346523242412601
Confusion Matrix (counts):
[[1100  316]
 [ 635  552]]
Confusion Matrix (percentages):
          0         1
0  0.776836  0.223164
1  0.534962  0.465038
Classification Report:
             precision    recall  f1-score   support

    Feeling       0.63      0.78      0.70      1416
   Thinking       0.64      0.47      0.54      1187

avg / total       0.63      0.63      0.62      2603


    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}72}]:} \PY{c+c1}{\PYZsh{} Grid Search to find the best parameters on Random Forest Classifier}
         \PY{n}{rfc\PYZus{}dict} \PY{o}{=} \PY{p}{\PYZob{}}
             \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bootstrap}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{True}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{False}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}
             \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{criterion}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{gini}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{entropy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}
             \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{min\PYZus{}samples\PYZus{}leaf}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{,}\PY{l+m+mi}{4}\PY{p}{]}\PY{p}{,}
             \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{min\PYZus{}samples\PYZus{}split}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{,}\PY{l+m+mi}{4}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{6}\PY{p}{]}\PY{p}{,}
             \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{n\PYZus{}estimators}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+m+mi}{83}\PY{p}{,}\PY{l+m+mi}{84}\PY{p}{,}\PY{l+m+mi}{85}\PY{p}{,}\PY{l+m+mi}{86}\PY{p}{]}\PY{p}{\PYZcb{}}
                
         \PY{n}{rfc} \PY{o}{=} \PY{n}{RandomForestClassifier}\PY{p}{(}\PY{p}{)}
         \PY{n}{gs\PYZus{}rfc} \PY{o}{=} \PY{n}{GridSearchCV}\PY{p}{(}\PY{n}{rfc}\PY{p}{,} \PY{n}{rfc\PYZus{}dict}\PY{p}{,} \PY{n}{verbose}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{n\PYZus{}jobs}\PY{o}{=}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{)} \PY{c+c1}{\PYZsh{} n\PYZus{}jobs = \PYZhy{}1, sets the number of jobs = CPU cores}
         \PY{n}{gs\PYZus{}rfc}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}TF\PYZus{}tsvd}\PY{p}{,} \PY{n}{y\PYZus{}train\PYZus{}TF}\PY{p}{)}
         
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Best score: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{gs\PYZus{}rfc}\PY{o}{.}\PY{n}{best\PYZus{}score\PYZus{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Best parameters: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{gs\PYZus{}rfc}\PY{o}{.}\PY{n}{best\PYZus{}params\PYZus{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Best score:  0.7127799736495388
Best parameters:  \{'bootstrap': 'True', 'criterion': 'entropy', 'min\_samples\_leaf': 4, 'min\_samples\_split': 3, 'n\_estimators': 86\}

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}73}]:} \PY{c+c1}{\PYZsh{} Fit and score a Random Forest Classifier using the parameters identified by the grid search}
         \PY{n}{rfc} \PY{o}{=} \PY{n}{RandomForestClassifier}\PY{p}{(}\PY{n}{min\PYZus{}samples\PYZus{}leaf}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{,} \PY{n}{min\PYZus{}samples\PYZus{}split}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{,} \PY{n}{n\PYZus{}estimators}\PY{o}{=}\PY{l+m+mi}{86}\PY{p}{,} 
                                      \PY{n}{criterion}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{entropy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{bootstrap}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{False}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{n\PYZus{}jobs}\PY{o}{=} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{123}\PY{p}{)}
         \PY{n}{rfc}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}TF\PYZus{}tsvd}\PY{p}{,} \PY{n}{y\PYZus{}train\PYZus{}TF}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{TRAINING SET}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Accuracy: }\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{score}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}TF\PYZus{}tsvd}\PY{p}{,} \PY{n}{y\PYZus{}train\PYZus{}TF}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Confusion Matrix (counts):}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}train\PYZus{}TF}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}TF\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Confusion Matrix (percentages):}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}train\PYZus{}TF}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}TF\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{x}\PY{o}{/}\PY{n}{x}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}\PY{p}{,}\PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Classification Report:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{classification\PYZus{}report}\PY{p}{(}\PY{n}{y\PYZus{}train\PYZus{}TF}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}TF\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{TEST SET}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Accuracy: }\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{score}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}TF\PYZus{}tsvd}\PY{p}{,} \PY{n}{y\PYZus{}test\PYZus{}TF}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Confusion Matrix (counts):}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}test\PYZus{}TF}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}TF\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Confusion Matrix (percentages):}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}test\PYZus{}TF}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}TF\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{x}\PY{o}{/}\PY{n}{x}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}\PY{p}{,}\PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Classification Report:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{classification\PYZus{}report}\PY{p}{(}\PY{n}{y\PYZus{}test\PYZus{}TF}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}TF\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
TRAINING SET
Accuracy:  1.0
Confusion Matrix (counts):
[[3278    0]
 [   0 2794]]
Confusion Matrix (percentages):
     0    1
0  1.0  0.0
1  0.0  1.0
Classification Report:
             precision    recall  f1-score   support

    Feeling       1.00      1.00      1.00      3278
   Thinking       1.00      1.00      1.00      2794

avg / total       1.00      1.00      1.00      6072


TEST SET
Accuracy:  0.6995774106799846
Confusion Matrix (counts):
[[1085  331]
 [ 451  736]]
Confusion Matrix (percentages):
          0         1
0  0.766243  0.233757
1  0.379949  0.620051
Classification Report:
             precision    recall  f1-score   support

    Feeling       0.71      0.77      0.74      1416
   Thinking       0.69      0.62      0.65      1187

avg / total       0.70      0.70      0.70      2603


    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}74}]:} \PY{c+c1}{\PYZsh{} Convert confusion matrix to a dataframe to prepare it for heatmapping}
         \PY{n}{cm\PYZus{}rfc\PYZus{}TF} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}test\PYZus{}TF}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}TF\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         
         \PY{n}{cm\PYZus{}randomforest\PYZus{}TF} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{cm\PYZus{}rfc\PYZus{}TF}\PY{p}{,} \PY{n}{index}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Feeling}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Thinking}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}
                                          \PY{n}{columns}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}Feeling}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}Thinking}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PYZbs{}
         \PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{x}\PY{o}{/}\PY{n}{x}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}\PY{p}{,}\PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Create confusion matrix heatmap of Random Forest Classifier model }
         \PY{n}{fig}\PY{p}{,} \PY{n}{ax} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{6}\PY{p}{,}\PY{l+m+mi}{4}\PY{p}{)}\PY{p}{)} 
         \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Confusion Matrix for Random Forest Classifier: Thinking \PYZhy{} Feeling Axis}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{16}\PY{p}{,}
                   \PY{n}{fontweight}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bold}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{l+m+mf}{1.02}\PY{p}{)}
         \PY{n}{sns}\PY{o}{.}\PY{n}{heatmap}\PY{p}{(}\PY{n}{cm\PYZus{}randomforest\PYZus{}TF}\PY{p}{,} \PY{n}{robust}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{annot}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{linewidth}\PY{o}{=}\PY{l+m+mf}{0.5}\PY{p}{,} 
                     \PY{n}{fmt}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{cmap}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{RdBu\PYZus{}r}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{vmax}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{ax}\PY{o}{=}\PY{n}{ax}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{xticks}\PY{p}{(}\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{yticks}\PY{p}{(}\PY{n}{rotation}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_135_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \subsubsection{Judging - Perceiving axis
modeling}\label{judging---perceiving-axis-modeling}

    The baseline of the \emph{Judging - Perceiving} axis is 0.604, with
\emph{Perceiving} being the majority class. A random forest classifier
using the default parameters returned an accuracy of 0.546, with 65\% of
the \emph{Perceiving} class and 38\% of the \emph{Judging} class being
predicted accurately. The classes garnered an F1 score of 0.64 and 0.40,
respectively.

A grid search suggested that the optimal parameters are a minimum of 3
samples required at a leaf node, a minimum of 6 samples to split an
internal node, 67 estimators, gini criterion, and no bootstrapping.

The random forest classifier using these parameters resulted in 91\% of
the \emph{Perceiving} class, but now only 13\% of the \emph{Judging}
class being predicted accurately. The model was misattributing many of
the \emph{Judging} class to the majority class of \emph{Perceiving}.

Because of the slight unbalance of the initial training sample, SMOTE
was then used to oversample the minority class for model improvement. A
follow-up grid search on that sample suggested the optimal parameters
are a minimum of 2 samples per leaf and 2 samples per split, with 85
estimators, entropy criterion, and no bootstrapping.

Using these parameters on the sample transformed by SMOTE returns a new
accuracy of 0.585, with 71\% of the \emph{Perceiving} class and 40\% of
the \emph{Judging} class being predicted accurately. The final F1 score
for the \emph{Perceiving} class increased to 0.67, and for
\emph{Judging} it is 0.43.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}75}]:} \PY{c+c1}{\PYZsh{} Fit and score a Random Forest Classifier using the default parameters}
         \PY{n}{rfc} \PY{o}{=} \PY{n}{RandomForestClassifier}\PY{p}{(}\PY{n}{n\PYZus{}jobs}\PY{o}{=} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{123}\PY{p}{)}
         \PY{n}{rfc}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}JP\PYZus{}tsvd}\PY{p}{,} \PY{n}{y\PYZus{}train\PYZus{}JP}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{TRAINING SET}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Accuracy: }\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{score}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}JP\PYZus{}tsvd}\PY{p}{,} \PY{n}{y\PYZus{}train\PYZus{}JP}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Confusion Matrix (counts):}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}train\PYZus{}JP}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}JP\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Confusion Matrix (percentages):}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}train\PYZus{}JP}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}JP\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{x}\PY{o}{/}\PY{n}{x}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}\PY{p}{,}\PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Classification Report:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{classification\PYZus{}report}\PY{p}{(}\PY{n}{y\PYZus{}train\PYZus{}JP}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}JP\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{TEST SET}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Accuracy: }\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{score}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}JP\PYZus{}tsvd}\PY{p}{,} \PY{n}{y\PYZus{}test\PYZus{}JP}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Confusion Matrix (counts):}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}test\PYZus{}JP}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}JP\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Confusion Matrix (percentages):}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}test\PYZus{}JP}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}JP\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{x}\PY{o}{/}\PY{n}{x}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}\PY{p}{,}\PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Classification Report:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{classification\PYZus{}report}\PY{p}{(}\PY{n}{y\PYZus{}test\PYZus{}JP}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}JP\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
TRAINING SET
Accuracy:  0.9912714097496707
Confusion Matrix (counts):
[[2398   19]
 [  34 3621]]
Confusion Matrix (percentages):
          0         1
0  0.992139  0.007861
1  0.009302  0.990698
Classification Report:
             precision    recall  f1-score   support

    Judging       0.99      0.99      0.99      2417
 Perceiving       0.99      0.99      0.99      3655

avg / total       0.99      0.99      0.99      6072


TEST SET
Accuracy:  0.5685747214752209
Confusion Matrix (counts):
[[ 445  572]
 [ 551 1035]]
Confusion Matrix (percentages):
          0         1
0  0.437561  0.562439
1  0.347415  0.652585
Classification Report:
             precision    recall  f1-score   support

    Judging       0.45      0.44      0.44      1017
 Perceiving       0.64      0.65      0.65      1586

avg / total       0.57      0.57      0.57      2603


    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}76}]:} \PY{c+c1}{\PYZsh{} Grid Search to find the best parameters on Random Forest Classifier}
         \PY{n}{rfc\PYZus{}dict} \PY{o}{=} \PY{p}{\PYZob{}}
             \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bootstrap}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{True}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{False}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}
             \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{criterion}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{gini}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{entropy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}
             \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{min\PYZus{}samples\PYZus{}leaf}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{]}\PY{p}{,}
             \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{min\PYZus{}samples\PYZus{}split}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{,}\PY{l+m+mi}{4}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{6}\PY{p}{,}\PY{l+m+mi}{7}\PY{p}{,}\PY{l+m+mi}{8}\PY{p}{]}\PY{p}{,}
             \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{n\PYZus{}estimators}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+m+mi}{65}\PY{p}{,}\PY{l+m+mi}{66}\PY{p}{,}\PY{l+m+mi}{67}\PY{p}{,}\PY{l+m+mi}{68}\PY{p}{,}\PY{l+m+mi}{69}\PY{p}{,}\PY{l+m+mi}{70}\PY{p}{,}\PY{l+m+mi}{71}\PY{p}{,}\PY{l+m+mi}{72}\PY{p}{,}\PY{l+m+mi}{73}\PY{p}{,}\PY{l+m+mi}{74}\PY{p}{,}\PY{l+m+mi}{75}\PY{p}{]}\PY{p}{\PYZcb{}}
                
         \PY{n}{rfc} \PY{o}{=} \PY{n}{RandomForestClassifier}\PY{p}{(}\PY{p}{)}
         \PY{n}{gs\PYZus{}rfc} \PY{o}{=} \PY{n}{GridSearchCV}\PY{p}{(}\PY{n}{rfc}\PY{p}{,} \PY{n}{rfc\PYZus{}dict}\PY{p}{,} \PY{n}{verbose}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{n\PYZus{}jobs}\PY{o}{=}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{)} \PY{c+c1}{\PYZsh{} n\PYZus{}jobs = \PYZhy{}1, sets the number of jobs = CPU cores}
         \PY{n}{gs\PYZus{}rfc}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}JP\PYZus{}tsvd}\PY{p}{,} \PY{n}{y\PYZus{}train\PYZus{}JP}\PY{p}{)}
         
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Best score: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{gs\PYZus{}rfc}\PY{o}{.}\PY{n}{best\PYZus{}score\PYZus{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Best parameters: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{gs\PYZus{}rfc}\PY{o}{.}\PY{n}{best\PYZus{}params\PYZus{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Best score:  0.6162714097496707
Best parameters:  \{'bootstrap': 'False', 'criterion': 'entropy', 'min\_samples\_leaf': 3, 'min\_samples\_split': 3, 'n\_estimators': 70\}

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}77}]:} \PY{c+c1}{\PYZsh{} Fit and score a Random Forest Classifier using the parameters identified by the grid search}
         \PY{n}{rfc} \PY{o}{=} \PY{n}{RandomForestClassifier}\PY{p}{(}\PY{n}{min\PYZus{}samples\PYZus{}leaf}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{,} \PY{n}{min\PYZus{}samples\PYZus{}split}\PY{o}{=}\PY{l+m+mi}{6}\PY{p}{,} \PY{n}{n\PYZus{}estimators}\PY{o}{=}\PY{l+m+mi}{67}\PY{p}{,} 
                                      \PY{n}{criterion}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{gini}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{bootstrap}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{False}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{n\PYZus{}jobs}\PY{o}{=} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{123}\PY{p}{)}
         \PY{n}{rfc}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}JP\PYZus{}tsvd}\PY{p}{,} \PY{n}{y\PYZus{}train\PYZus{}JP}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{TRAINING SET}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Accuracy: }\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{score}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}JP\PYZus{}tsvd}\PY{p}{,} \PY{n}{y\PYZus{}train\PYZus{}JP}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Confusion Matrix (counts):}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}train\PYZus{}JP}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}JP\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Confusion Matrix (percentages):}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}train\PYZus{}JP}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}JP\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{x}\PY{o}{/}\PY{n}{x}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}\PY{p}{,}\PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Classification Report:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{classification\PYZus{}report}\PY{p}{(}\PY{n}{y\PYZus{}train\PYZus{}JP}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}JP\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{TEST SET}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Accuracy: }\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{score}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}JP\PYZus{}tsvd}\PY{p}{,} \PY{n}{y\PYZus{}test\PYZus{}JP}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Confusion Matrix (counts):}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}test\PYZus{}JP}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}JP\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Confusion Matrix (percentages):}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}test\PYZus{}JP}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}JP\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{x}\PY{o}{/}\PY{n}{x}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}\PY{p}{,}\PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Classification Report:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{classification\PYZus{}report}\PY{p}{(}\PY{n}{y\PYZus{}test\PYZus{}JP}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}JP\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
TRAINING SET
Accuracy:  0.9995059288537549
Confusion Matrix (counts):
[[2414    3]
 [   0 3655]]
Confusion Matrix (percentages):
          0         1
0  0.998759  0.001241
1  0.000000  1.000000
Classification Report:
             precision    recall  f1-score   support

    Judging       1.00      1.00      1.00      2417
 Perceiving       1.00      1.00      1.00      3655

avg / total       1.00      1.00      1.00      6072


TEST SET
Accuracy:  0.6081444487130234
Confusion Matrix (counts):
[[ 125  892]
 [ 128 1458]]
Confusion Matrix (percentages):
          0         1
0  0.122911  0.877089
1  0.080706  0.919294
Classification Report:
             precision    recall  f1-score   support

    Judging       0.49      0.12      0.20      1017
 Perceiving       0.62      0.92      0.74      1586

avg / total       0.57      0.61      0.53      2603


    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}78}]:} \PY{c+c1}{\PYZsh{} Use SMOTE (Synthetic Minority Over\PYZhy{}sampling Technique) to even out the unbalanced test sample}
         \PY{n}{sm} \PY{o}{=} \PY{n}{SMOTE}\PY{p}{(}\PY{p}{)}
         \PY{n}{Xsm\PYZus{}train\PYZus{}JP\PYZus{}tsvd}\PY{p}{,} \PY{n}{ysm\PYZus{}train\PYZus{}JP} \PY{o}{=} \PY{n}{sm}\PY{o}{.}\PY{n}{fit\PYZus{}sample}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}JP\PYZus{}tsvd}\PY{p}{,} \PY{n}{y\PYZus{}train\PYZus{}JP}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}79}]:} \PY{c+c1}{\PYZsh{} Grid Search to find the best parameters on Random Forest Classifier for the SMOTEd sample}
         \PY{n}{rfc\PYZus{}dict} \PY{o}{=} \PY{p}{\PYZob{}}
             \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bootstrap}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{True}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{False}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}
             \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{criterion}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{gini}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{entropy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}
             \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{min\PYZus{}samples\PYZus{}leaf}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{,}\PY{l+m+mi}{4}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{]}\PY{p}{,}
             \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{min\PYZus{}samples\PYZus{}split}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{,}\PY{l+m+mi}{4}\PY{p}{]}\PY{p}{,}
             \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{n\PYZus{}estimators}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+m+mi}{75}\PY{p}{,}\PY{l+m+mi}{76}\PY{p}{,}\PY{l+m+mi}{77}\PY{p}{,}\PY{l+m+mi}{78}\PY{p}{,}\PY{l+m+mi}{79}\PY{p}{,}\PY{l+m+mi}{80}\PY{p}{,}\PY{l+m+mi}{81}\PY{p}{,}\PY{l+m+mi}{82}\PY{p}{,}\PY{l+m+mi}{83}\PY{p}{,}\PY{l+m+mi}{84}\PY{p}{,}\PY{l+m+mi}{85}\PY{p}{]}\PY{p}{\PYZcb{}}
                
         \PY{n}{rfc} \PY{o}{=} \PY{n}{RandomForestClassifier}\PY{p}{(}\PY{p}{)}
         \PY{n}{gs\PYZus{}rfc} \PY{o}{=} \PY{n}{GridSearchCV}\PY{p}{(}\PY{n}{rfc}\PY{p}{,} \PY{n}{rfc\PYZus{}dict}\PY{p}{,} \PY{n}{n\PYZus{}jobs}\PY{o}{=}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{)} \PY{c+c1}{\PYZsh{} n\PYZus{}jobs = \PYZhy{}1 sets the number of jobs = CPU cores}
         \PY{n}{gs\PYZus{}rfc}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{Xsm\PYZus{}train\PYZus{}JP\PYZus{}tsvd}\PY{p}{,} \PY{n}{ysm\PYZus{}train\PYZus{}JP}\PY{p}{)}
         
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Best score: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{gs\PYZus{}rfc}\PY{o}{.}\PY{n}{best\PYZus{}score\PYZus{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Best parameters: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{gs\PYZus{}rfc}\PY{o}{.}\PY{n}{best\PYZus{}params\PYZus{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Best score:  0.6633378932968537
Best parameters:  \{'bootstrap': 'False', 'criterion': 'gini', 'min\_samples\_leaf': 3, 'min\_samples\_split': 2, 'n\_estimators': 80\}

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}80}]:} \PY{c+c1}{\PYZsh{} Fit and score a Random Forest Classifier on SMOTEd data using the parameters identified by the grid search}
         \PY{n}{rfc} \PY{o}{=} \PY{n}{RandomForestClassifier}\PY{p}{(}\PY{n}{min\PYZus{}samples\PYZus{}leaf}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{,} \PY{n}{min\PYZus{}samples\PYZus{}split}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{,} \PY{n}{n\PYZus{}estimators}\PY{o}{=}\PY{l+m+mi}{85}\PY{p}{,} 
                                      \PY{n}{criterion}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{entropy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{bootstrap}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{False}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{n\PYZus{}jobs}\PY{o}{=} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{123}\PY{p}{)}
         \PY{n}{rfc}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{Xsm\PYZus{}train\PYZus{}JP\PYZus{}tsvd}\PY{p}{,} \PY{n}{ysm\PYZus{}train\PYZus{}JP}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{TRAINING SET}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Accuracy: }\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{score}\PY{p}{(}\PY{n}{Xsm\PYZus{}train\PYZus{}JP\PYZus{}tsvd}\PY{p}{,} \PY{n}{ysm\PYZus{}train\PYZus{}JP}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Confusion Matrix (counts):}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{ysm\PYZus{}train\PYZus{}JP}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{Xsm\PYZus{}train\PYZus{}JP\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Confusion Matrix (percentages):}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{ysm\PYZus{}train\PYZus{}JP}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{Xsm\PYZus{}train\PYZus{}JP\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{x}\PY{o}{/}\PY{n}{x}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}\PY{p}{,}\PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Classification Report:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{classification\PYZus{}report}\PY{p}{(}\PY{n}{ysm\PYZus{}train\PYZus{}JP}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{Xsm\PYZus{}train\PYZus{}JP\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{TEST SET}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Accuracy: }\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{score}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}JP\PYZus{}tsvd}\PY{p}{,} \PY{n}{y\PYZus{}test\PYZus{}JP}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Confusion Matrix (counts):}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}test\PYZus{}JP}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}JP\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Confusion Matrix (percentages):}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}test\PYZus{}JP}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}JP\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{x}\PY{o}{/}\PY{n}{x}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}\PY{p}{,}\PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Classification Report:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{classification\PYZus{}report}\PY{p}{(}\PY{n}{y\PYZus{}test\PYZus{}JP}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}JP\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
TRAINING SET
Accuracy:  1.0
Confusion Matrix (counts):
[[3655    0]
 [   0 3655]]
Confusion Matrix (percentages):
     0    1
0  1.0  0.0
1  0.0  1.0
Classification Report:
             precision    recall  f1-score   support

    Judging       1.00      1.00      1.00      3655
 Perceiving       1.00      1.00      1.00      3655

avg / total       1.00      1.00      1.00      7310


TEST SET
Accuracy:  0.5620437956204379
Confusion Matrix (counts):
[[ 394  623]
 [ 517 1069]]
Confusion Matrix (percentages):
          0         1
0  0.387414  0.612586
1  0.325977  0.674023
Classification Report:
             precision    recall  f1-score   support

    Judging       0.43      0.39      0.41      1017
 Perceiving       0.63      0.67      0.65      1586

avg / total       0.55      0.56      0.56      2603


    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}81}]:} \PY{c+c1}{\PYZsh{} Convert confusion matrix to a dataframe to prepare it for heatmapping}
         \PY{n}{cm\PYZus{}rfc\PYZus{}JP} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}test\PYZus{}JP}\PY{p}{,} \PY{n}{rfc}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}JP\PYZus{}tsvd}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         
         \PY{n}{cm\PYZus{}randomforest\PYZus{}JP} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{cm\PYZus{}rfc\PYZus{}JP}\PY{p}{,} \PY{n}{index}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Judging}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Perceiving}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}
                                          \PY{n}{columns}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}Judging}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict\PYZus{}Perceiving}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PYZbs{}
         \PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{x}\PY{o}{/}\PY{n}{x}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}\PY{p}{,}\PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Create confusion matrix heatmap of Random Forest Classifier model }
         \PY{n}{fig}\PY{p}{,} \PY{n}{ax} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{6}\PY{p}{,}\PY{l+m+mi}{4}\PY{p}{)}\PY{p}{)} 
         \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Confusion Matrix for Random Forest Classifier: Judging \PYZhy{} Perceiving Axis}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{16}\PY{p}{,}
                   \PY{n}{fontweight}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bold}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{l+m+mf}{1.02}\PY{p}{)}
         \PY{n}{sns}\PY{o}{.}\PY{n}{heatmap}\PY{p}{(}\PY{n}{cm\PYZus{}randomforest\PYZus{}JP}\PY{p}{,} \PY{n}{robust}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{annot}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{linewidth}\PY{o}{=}\PY{l+m+mf}{0.5}\PY{p}{,} 
                     \PY{n}{fmt}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{cmap}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{RdBu\PYZus{}r}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{vmax}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{ax}\PY{o}{=}\PY{n}{ax}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{xticks}\PY{p}{(}\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{yticks}\PY{p}{(}\PY{n}{rotation}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_144_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

     \#\#\# Sentiment Analysis and Word Count

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}82}]:} \PY{c+c1}{\PYZsh{} View working dataframe head}
         \PY{n}{df\PYZus{}working}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}82}]:}    type                                              posts           I-E  \textbackslash{}
         0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||{\ldots}  Introversion   
         1  ENTP  'I'm finding the lack of me in these posts ver{\ldots}  Extroversion   
         2  INTP  'Good one  \_\_\_\_\_   https://www.youtube.com/wat{\ldots}  Introversion   
         3  INTJ  'Dear INTP,   I enjoyed our conversation the o{\ldots}  Introversion   
         4  ENTJ  'You're fired.|||That's another silly misconce{\ldots}  Extroversion   
         
                  N-S       T-F         J-P  
         0  Intuition   Feeling     Judging  
         1  Intuition  Thinking  Perceiving  
         2  Intuition  Thinking  Perceiving  
         3  Intuition  Thinking     Judging  
         4  Intuition  Thinking     Judging  
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}83}]:} \PY{c+c1}{\PYZsh{} create new column with revised posts text}
         \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{posts\PYZus{}r}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{posts}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{copy}\PY{p}{(}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} replaces post separators with empty space}
         \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{posts\PYZus{}r}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{posts\PYZus{}r}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{x}\PY{o}{.}\PY{n}{replace}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{|||}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ }\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
         
         
         \PY{c+c1}{\PYZsh{} replace hyperlinks with \PYZsq{}URL\PYZsq{}}
         \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{posts\PYZus{}r}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{posts\PYZus{}r}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{re}\PY{o}{.}\PY{n}{sub}\PYZbs{}
                                                           \PY{p}{(}\PY{l+s+sa}{r}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZbs{}}\PY{l+s+s1}{bhttps?:}\PY{l+s+s1}{\PYZbs{}}\PY{l+s+s1}{/}\PY{l+s+s1}{\PYZbs{}}\PY{l+s+s1}{/.*?[}\PY{l+s+s1}{\PYZbs{}}\PY{l+s+s1}{r}\PY{l+s+s1}{\PYZbs{}}\PY{l+s+s1}{n]*? }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{URL }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{x}\PY{p}{,} \PY{n}{flags}\PY{o}{=}\PY{n}{re}\PY{o}{.}\PY{n}{MULTILINE}\PY{p}{)}\PY{p}{)}
         
         \PY{n}{df\PYZus{}working}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}83}]:}    type                                              posts           I-E  \textbackslash{}
         0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||{\ldots}  Introversion   
         1  ENTP  'I'm finding the lack of me in these posts ver{\ldots}  Extroversion   
         2  INTP  'Good one  \_\_\_\_\_   https://www.youtube.com/wat{\ldots}  Introversion   
         3  INTJ  'Dear INTP,   I enjoyed our conversation the o{\ldots}  Introversion   
         4  ENTJ  'You're fired.|||That's another silly misconce{\ldots}  Extroversion   
         
                  N-S       T-F         J-P  \textbackslash{}
         0  Intuition   Feeling     Judging   
         1  Intuition  Thinking  Perceiving   
         2  Intuition  Thinking  Perceiving   
         3  Intuition  Thinking     Judging   
         4  Intuition  Thinking     Judging   
         
                                                      posts\_r  
         0  'URL URL enfp and intj moments  URL  sportscen{\ldots}  
         1  'I'm finding the lack of me in these posts ver{\ldots}  
         2  'Good one  \_\_\_\_\_   URL Of course, to which I s{\ldots}  
         3  'Dear INTP,   I enjoyed our conversation the o{\ldots}  
         4  'You're fired. That's another silly misconcept{\ldots}  
\end{Verbatim}
            
     \#\#\#\# Length of Post

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}84}]:} \PY{c+c1}{\PYZsh{} Add columns for the total number of words (across 50 posts), and average words per post}
         \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{total\PYZus{}words}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{posts\PYZus{}r}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n+nb}{len}\PY{p}{(}\PY{n}{re}\PY{o}{.}\PY{n}{findall}\PY{p}{(}\PY{l+s+sa}{r}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZbs{}}\PY{l+s+s1}{w+}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{x}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{avg\PYZus{}words\PYZus{}per\PYZus{}post}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{total\PYZus{}words}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{/} \PY{l+m+mi}{50}
         \PY{n}{df\PYZus{}working}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}84}]:}    type                                              posts           I-E  \textbackslash{}
         0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||{\ldots}  Introversion   
         1  ENTP  'I'm finding the lack of me in these posts ver{\ldots}  Extroversion   
         2  INTP  'Good one  \_\_\_\_\_   https://www.youtube.com/wat{\ldots}  Introversion   
         3  INTJ  'Dear INTP,   I enjoyed our conversation the o{\ldots}  Introversion   
         4  ENTJ  'You're fired.|||That's another silly misconce{\ldots}  Extroversion   
         
                  N-S       T-F         J-P  \textbackslash{}
         0  Intuition   Feeling     Judging   
         1  Intuition  Thinking  Perceiving   
         2  Intuition  Thinking  Perceiving   
         3  Intuition  Thinking     Judging   
         4  Intuition  Thinking     Judging   
         
                                                      posts\_r  total\_words  \textbackslash{}
         0  'URL URL enfp and intj moments  URL  sportscen{\ldots}          624   
         1  'I'm finding the lack of me in these posts ver{\ldots}         1268   
         2  'Good one  \_\_\_\_\_   URL Of course, to which I s{\ldots}          913   
         3  'Dear INTP,   I enjoyed our conversation the o{\ldots}         1164   
         4  'You're fired. That's another silly misconcept{\ldots}         1049   
         
            avg\_words\_per\_post  
         0               12.48  
         1               25.36  
         2               18.26  
         3               23.28  
         4               20.98  
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}85}]:} \PY{c+c1}{\PYZsh{} Average length of post overall}
         \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{avg\PYZus{}words\PYZus{}per\PYZus{}post}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}85}]:} 26.424853025936567
\end{Verbatim}
            
    Overall, the average post length is 26.4 words.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}86}]:} \PY{c+c1}{\PYZsh{} Average length of post, by 16 types}
         \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{avg\PYZus{}words\PYZus{}per\PYZus{}post}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}86}]:} type
         ENFJ    27.650632
         ENFP    27.116948
         ENTJ    26.211515
         ENTP    26.042336
         ESFJ    27.770952
         ESFP    22.192083
         ESTJ    26.428205
         ESTP    25.071910
         INFJ    27.495510
         INFP    26.801070
         INTJ    25.722970
         INTP    25.860966
         ISFJ    26.789036
         ISFP    24.605166
         ISTJ    26.185463
         ISTP    25.231632
         Name: avg\_words\_per\_post, dtype: float64
\end{Verbatim}
            
    Tukey's range test, also known as Tukey's HSD (honest significant
difference) test is a single-step multiple comparison procedure and
statistical test to find means that are significantly different from
each other.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}87}]:} \PY{c+c1}{\PYZsh{} Perform a Tukey range test to identify significant differences between the 16 classes on post length}
         \PY{n}{tukey\PYZus{}awpp} \PY{o}{=} \PY{n}{pairwise\PYZus{}tukeyhsd}\PY{p}{(}\PY{n}{endog}\PY{o}{=}\PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{avg\PYZus{}words\PYZus{}per\PYZus{}post}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}     \PY{c+c1}{\PYZsh{} Data}
                                   \PY{n}{groups}\PY{o}{=}\PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}   \PY{c+c1}{\PYZsh{} Groups}
                                   \PY{n}{alpha}\PY{o}{=}\PY{l+m+mf}{0.05}\PY{p}{)}          \PY{c+c1}{\PYZsh{} Significance level}
         \PY{n}{tukey\PYZus{}awpp}\PY{o}{.}\PY{n}{plot\PYZus{}simultaneous}\PY{p}{(}\PY{p}{)}    \PY{c+c1}{\PYZsh{} Plot group confidence intervals}
         \PY{n}{plt}\PY{o}{.}\PY{n}{vlines}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{l+m+mf}{26.42}\PY{p}{,}\PY{n}{ymin}\PY{o}{=}\PY{o}{\PYZhy{}}\PY{l+m+mf}{0.5}\PY{p}{,}\PY{n}{ymax}\PY{o}{=}\PY{l+m+mi}{16}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{red}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{95}\PY{l+s+s2}{\PYZpc{}}\PY{l+s+s2}{ Confidence Interval Plot \PYZhy{} Average \PYZsh{} of Words per Post}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{16}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Post Length}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Type}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{xticks}\PY{p}{(}\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{yticks}\PY{p}{(}\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}\PY{p}{;}
         
         \PY{c+c1}{\PYZsh{} Note: the Extroversion\PYZhy{}Sensing classes have n \PYZlt{} 100, so evaluate with caution.}
         \PY{c+c1}{\PYZsh{} ESTP (89), ESFP (48), ESFJ (42), ESTJ (39)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_155_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}88}]:} \PY{c+c1}{\PYZsh{} Display the test summary for the Tukey range test}
         \PY{n}{tukey\PYZus{}awpp}\PY{o}{.}\PY{n}{summary}\PY{p}{(}\PY{p}{)} \PY{c+c1}{\PYZsh{} Reject = \PYZdq{}True\PYZdq{} indicates a significant difference (reject null hypothesis of no difference)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}88}]:} <class 'statsmodels.iolib.table.SimpleTable'>
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}89}]:} \PY{c+c1}{\PYZsh{} Bar graph of length of post, by 16 types}
         \PY{n}{dims1} \PY{o}{=} \PY{p}{(}\PY{l+m+mf}{15.0}\PY{p}{,} \PY{l+m+mf}{4.0}\PY{p}{)}
         \PY{n}{fig}\PY{p}{,} \PY{n}{ax} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{n}{dims1}\PY{p}{)}
         \PY{n}{coolwarm} \PY{o}{=} \PY{n}{sns}\PY{o}{.}\PY{n}{color\PYZus{}palette}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{coolwarm}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+m+mi}{16}\PY{p}{)}
         \PY{n}{sns}\PY{o}{.}\PY{n}{set\PYZus{}palette}\PY{p}{(}\PY{n}{coolwarm}\PY{p}{)}
         \PY{n}{sns}\PY{o}{.}\PY{n}{barplot}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{type}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{avg\PYZus{}words\PYZus{}per\PYZus{}post}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{data}\PY{o}{=}\PY{n}{df\PYZus{}working}\PY{p}{,} \PYZbs{}
                       \PY{n}{order}\PY{o}{=}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ENFJ}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ENFP}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ENTJ}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ENTP}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ESFJ}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ESFP}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ESTJ}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ESTP}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PYZbs{}
                              \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{INFJ}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{INFP}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{INTJ}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{INTP}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ISFJ}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ISFP}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ISTJ}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ISTP}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}\PY{p}{;}
         \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Avg. \PYZsh{} of Words per Post, by Myers\PYZhy{}Briggs Type}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{16}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{xticks}\PY{p}{(}\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{yticks}\PY{p}{(}\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_157_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    The bar chart above shows the average number of words per post by the 16
types. This, in conjunction with the Tukey test, reveal that the
following types have a significantly higher number of words per post
than their noted counterparts listed in the parentheses: - INFJ (ESFP,
ESTP, INTJ, INTP, ISFP, ISTP) - INFP (ESFP, INTJ, INTP, ISFP, ISTP) -
ENFJ (ESFP, INTJ, INTP, ISFP, ISTP) - ENFP (ESFP, INTJ, INTP, ISFP,
ISTP) - ENTJ (ESFP) - ENTP (ESFP) - ESFJ (ESFP) - INTJ (ESFP) - INTP
(ESFP) - ISFJ (ESFP) - ISTJ (ESFP)

It is notable that, regardless of their \emph{Extrovert/Introvert} or
\emph{Judging/Perceptive} status, those with a \emph{Intuitive-Feeling}
type combination tend to use a significantly higher number of words per
post than their counterparts with a
\emph{Introversion-Intuitive-Thinking} combination,
\emph{Introversion-Sensing-Perception} combination, or type ESFP.
Conversely, those who are the ESFP type tend to use significantly fewer
words per post than nearly all of the other types.

\emph{(Note, the Extrovert-Sensing types: ESFJ, ESFP, ESTJ, and ESTP
have low base sizes and are subject to outlier values).}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}90}]:} \PY{c+c1}{\PYZsh{} Average length of post, by Introversion (I) – Extroversion (E) axis}
         \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{avg\PYZus{}words\PYZus{}per\PYZus{}post}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{I\PYZhy{}E}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}90}]:} I-E
         Extroversion    26.485803
         Introversion    26.406603
         Name: avg\_words\_per\_post, dtype: float64
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}91}]:} \PY{c+c1}{\PYZsh{} Calculation of standard deviation}
         \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{avg\PYZus{}words\PYZus{}per\PYZus{}post}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{I\PYZhy{}E}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}91}]:} I-E
         Extroversion    6.306564
         Introversion    6.578982
         Name: avg\_words\_per\_post, dtype: float64
\end{Verbatim}
            
    A \textbf{p-value} of \textbf{0.05} will be used to determine the
significance of t-test results.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}92}]:} \PY{c+c1}{\PYZsh{} T\PYZhy{}test on Introversion \PYZhy{} Extroversion axis for average \PYZsh{} words per post}
         \PY{n}{stats}\PY{o}{.}\PY{n}{ttest\PYZus{}ind\PYZus{}from\PYZus{}stats}\PY{p}{(}\PY{n}{mean1}\PY{o}{=}\PY{l+m+mf}{26.485803}\PY{p}{,} \PY{n}{std1}\PY{o}{=}\PY{l+m+mf}{6.306564}\PY{p}{,} \PY{n}{nobs1}\PY{o}{=}\PY{l+m+mi}{1999}\PY{p}{,} 
                                    \PY{n}{mean2}\PY{o}{=}\PY{l+m+mf}{26.406603}\PY{p}{,} \PY{n}{std2}\PY{o}{=}\PY{l+m+mf}{6.578982}\PY{p}{,} \PY{n}{nobs2}\PY{o}{=}\PY{l+m+mi}{6676}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}92}]:} Ttest\_indResult(statistic=0.4766412761846974, pvalue=0.6336295939332515)
\end{Verbatim}
            
    The p-value of 0.63 is greater than 0.05, thus the difference is not
significant.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}93}]:} \PY{c+c1}{\PYZsh{} Bar graph of length of post, by Introversion \PYZhy{} Extroversion axis}
         \PY{n}{IEcolors} \PY{o}{=} \PY{n}{sns}\PY{o}{.}\PY{n}{xkcd\PYZus{}palette}\PY{p}{(}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{red}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{soft pink}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
         \PY{n}{sns}\PY{o}{.}\PY{n}{set\PYZus{}palette}\PY{p}{(}\PY{n}{IEcolors}\PY{p}{)}
         \PY{n}{sns}\PY{o}{.}\PY{n}{barplot}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{I\PYZhy{}E}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{avg\PYZus{}words\PYZus{}per\PYZus{}post}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{data}\PY{o}{=}\PY{n}{df\PYZus{}working}\PY{p}{,} \PY{n}{order}\PY{o}{=}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Introversion}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Extroversion}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Avg. \PYZsh{} of Words per Post, by Introversion \PYZhy{} Extroversion Axis}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{16}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{xticks}\PY{p}{(}\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{yticks}\PY{p}{(}\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_164_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    The bar chart above shows virtually no difference between Introverts and
Extroverts in terms of the average number of words per post.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}94}]:} \PY{c+c1}{\PYZsh{} Average length of post, by Intuition (N) – Sensing (S) axis}
         \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{avg\PYZus{}words\PYZus{}per\PYZus{}post}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{N\PYZhy{}S}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}94}]:} N-S
         Intuition    26.578743
         Sensing      25.463459
         Name: avg\_words\_per\_post, dtype: float64
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}95}]:} \PY{c+c1}{\PYZsh{} Calculation of standard deviations}
         \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{avg\PYZus{}words\PYZus{}per\PYZus{}post}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{N\PYZhy{}S}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}95}]:} N-S
         Intuition    6.402543
         Sensing      7.118493
         Name: avg\_words\_per\_post, dtype: float64
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}96}]:} \PY{c+c1}{\PYZsh{} T\PYZhy{}test on Intuition \PYZhy{} Sensing axis for average \PYZsh{} words per post}
         \PY{n}{stats}\PY{o}{.}\PY{n}{ttest\PYZus{}ind\PYZus{}from\PYZus{}stats}\PY{p}{(}\PY{n}{mean1}\PY{o}{=}\PY{l+m+mf}{26.578743}\PY{p}{,} \PY{n}{std1}\PY{o}{=}\PY{l+m+mf}{6.402543}\PY{p}{,} \PY{n}{nobs1}\PY{o}{=}\PY{l+m+mi}{7478}\PY{p}{,} 
                                    \PY{n}{mean2}\PY{o}{=}\PY{l+m+mf}{25.463459}\PY{p}{,} \PY{n}{std2}\PY{o}{=}\PY{l+m+mf}{7.118493}\PY{p}{,} \PY{n}{nobs2}\PY{o}{=}\PY{l+m+mi}{1197}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}96}]:} Ttest\_indResult(statistic=5.506547082341566, pvalue=3.763926839653265e-08)
\end{Verbatim}
            
    The p-value of 3.76e-08 is lower than 0.05, thus the difference is
significant.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}97}]:} \PY{c+c1}{\PYZsh{} Bar graph of length of post, by Intuition \PYZhy{} Sensing axis}
         \PY{n}{NScolors} \PY{o}{=} \PY{n}{sns}\PY{o}{.}\PY{n}{xkcd\PYZus{}palette}\PY{p}{(}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{blue}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{light blue}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
         \PY{n}{sns}\PY{o}{.}\PY{n}{set\PYZus{}palette}\PY{p}{(}\PY{n}{NScolors}\PY{p}{)}
         \PY{n}{sns}\PY{o}{.}\PY{n}{barplot}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{N\PYZhy{}S}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{avg\PYZus{}words\PYZus{}per\PYZus{}post}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{data}\PY{o}{=}\PY{n}{df\PYZus{}working}\PY{p}{,} \PY{n}{order}\PY{o}{=}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Intuition}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Sensing}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Avg. \PYZsh{} of Words per Post, by Intuition vs. Sensing Axis}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{16}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{xticks}\PY{p}{(}\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{yticks}\PY{p}{(}\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_170_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    The bar chart above and the t-test prior to that shows that subjects
exhibiting higher Intuition traits tend to include more words per post
than their Sensing counterparts.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}98}]:} \PY{c+c1}{\PYZsh{} Average length of post, by Thinking (T) – Feeling (F) axis}
         \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{avg\PYZus{}words\PYZus{}per\PYZus{}post}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{T\PYZhy{}F}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}98}]:} T-F
         Feeling     26.932701
         Thinking    25.826049
         Name: avg\_words\_per\_post, dtype: float64
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}99}]:} \PY{c+c1}{\PYZsh{} Calculate standard deviation}
         \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{avg\PYZus{}words\PYZus{}per\PYZus{}post}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{T\PYZhy{}F}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}99}]:} T-F
         Feeling     6.545449
         Thinking    6.432678
         Name: avg\_words\_per\_post, dtype: float64
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}100}]:} \PY{c+c1}{\PYZsh{} T\PYZhy{}test on Thinking\PYZhy{}Feeling axis for average \PYZsh{} words per post}
          \PY{n}{stats}\PY{o}{.}\PY{n}{ttest\PYZus{}ind\PYZus{}from\PYZus{}stats}\PY{p}{(}\PY{n}{mean1}\PY{o}{=}\PY{l+m+mf}{26.932701}\PY{p}{,} \PY{n}{std1}\PY{o}{=}\PY{l+m+mf}{6.545449}\PY{p}{,} \PY{n}{nobs1}\PY{o}{=}\PY{l+m+mi}{4694}\PY{p}{,} 
                                     \PY{n}{mean2}\PY{o}{=}\PY{l+m+mf}{25.826049}\PY{p}{,} \PY{n}{std2}\PY{o}{=}\PY{l+m+mf}{6.432678}\PY{p}{,} \PY{n}{nobs2}\PY{o}{=}\PY{l+m+mi}{3981}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}100}]:} Ttest\_indResult(statistic=7.909254575127032, pvalue=2.9073291109032982e-15)
\end{Verbatim}
            
    The p-value of 2.91e-15 is lower than 0.05, thus the difference is
significant.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}101}]:} \PY{c+c1}{\PYZsh{} Bar graph of length of post, by Thinking vs. Feeling axis}
          \PY{n}{TFcolors} \PY{o}{=} \PY{n}{sns}\PY{o}{.}\PY{n}{xkcd\PYZus{}palette}\PY{p}{(}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{green}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{pale green}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
          \PY{n}{sns}\PY{o}{.}\PY{n}{set\PYZus{}palette}\PY{p}{(}\PY{n}{TFcolors}\PY{p}{)}
          \PY{n}{sns}\PY{o}{.}\PY{n}{barplot}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{T\PYZhy{}F}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{avg\PYZus{}words\PYZus{}per\PYZus{}post}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{data}\PY{o}{=}\PY{n}{df\PYZus{}working}\PY{p}{,} \PY{n}{order}\PY{o}{=}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Thinking}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Feeling}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Avg. \PYZsh{} of Words per Post, by Thinking vs. Feeling Axis}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{16}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{xticks}\PY{p}{(}\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{yticks}\PY{p}{(}\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_176_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    The bar graph above and corresponding t-test show that subjects with the
Feeling trait tend to use significantly more words per post than their
Thinking counterparts.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}102}]:} \PY{c+c1}{\PYZsh{} Average length of post, by Judging (J) – Perceiving (P) axis}
          \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{avg\PYZus{}words\PYZus{}per\PYZus{}post}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{J\PYZhy{}P}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}102}]:} J-P
          Judging       26.733465
          Perceiving    26.222645
          Name: avg\_words\_per\_post, dtype: float64
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}103}]:} \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{avg\PYZus{}words\PYZus{}per\PYZus{}post}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{J\PYZhy{}P}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}103}]:} J-P
          Judging       6.568131
          Perceiving    6.475843
          Name: avg\_words\_per\_post, dtype: float64
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}104}]:} \PY{c+c1}{\PYZsh{} T\PYZhy{}test on Judging\PYZhy{}Perceiving axis for average \PYZsh{} words per post}
          \PY{n}{stats}\PY{o}{.}\PY{n}{ttest\PYZus{}ind\PYZus{}from\PYZus{}stats}\PY{p}{(}\PY{n}{mean1}\PY{o}{=}\PY{l+m+mf}{26.733465}\PY{p}{,} \PY{n}{std1}\PY{o}{=}\PY{l+m+mf}{6.568131}\PY{p}{,} \PY{n}{nobs1}\PY{o}{=}\PY{l+m+mi}{5241}\PY{p}{,} 
                                     \PY{n}{mean2}\PY{o}{=}\PY{l+m+mf}{26.222645}\PY{p}{,} \PY{n}{std2}\PY{o}{=}\PY{l+m+mf}{6.475843}\PY{p}{,} \PY{n}{nobs2}\PY{o}{=}\PY{l+m+mi}{3434}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}104}]:} Ttest\_indResult(statistic=3.562134899302214, pvalue=0.00036982460305784914)
\end{Verbatim}
            
    The p-value of 0.0003698 is lower than 0.05, thus the difference is
significant.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}105}]:} \PY{c+c1}{\PYZsh{} Bar graph of length of post, by Judging \PYZhy{} Perceiving axis}
          \PY{n}{JPcolors} \PY{o}{=} \PY{n}{sns}\PY{o}{.}\PY{n}{xkcd\PYZus{}palette}\PY{p}{(}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{purple}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{lavender}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
          \PY{n}{sns}\PY{o}{.}\PY{n}{set\PYZus{}palette}\PY{p}{(}\PY{n}{JPcolors}\PY{p}{)}
          \PY{n}{sns}\PY{o}{.}\PY{n}{barplot}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{J\PYZhy{}P}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{avg\PYZus{}words\PYZus{}per\PYZus{}post}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{data}\PY{o}{=}\PY{n}{df\PYZus{}working}\PY{p}{,} \PY{n}{order}\PY{o}{=}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Judging}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Perceiving}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Avg. \PYZsh{} of Words per Post, by Judging vs. Perceiving Axis}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{16}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{xticks}\PY{p}{(}\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{yticks}\PY{p}{(}\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_182_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    The bar graph above and corresponding t-test show that subjects with the
Judging trait tend to use significantly more words per post than their
Perceiving counterparts.

     \#\#\#\# Polarity

polarity (-1 to 1): scores closer to -1 are more negative in tone,
closer to 0 are more neutral, and closer to 1 are more positive in tone.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}106}]:} \PY{k}{def} \PY{n+nf}{polarity}\PY{p}{(}\PY{n}{text}\PY{p}{)}\PY{p}{:}
              \PY{n}{text} \PY{o}{=} \PY{n}{TextBlob}\PY{p}{(}\PY{n}{text}\PY{p}{)}
              \PY{k}{return} \PY{n}{text}\PY{o}{.}\PY{n}{sentiment}\PY{o}{.}\PY{n}{polarity}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}107}]:} \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{polarity}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{posts\PYZus{}r}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{n}{polarity}\PY{p}{)}
          \PY{n}{df\PYZus{}working}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}107}]:}    type                                              posts           I-E  \textbackslash{}
          0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||{\ldots}  Introversion   
          1  ENTP  'I'm finding the lack of me in these posts ver{\ldots}  Extroversion   
          2  INTP  'Good one  \_\_\_\_\_   https://www.youtube.com/wat{\ldots}  Introversion   
          3  INTJ  'Dear INTP,   I enjoyed our conversation the o{\ldots}  Introversion   
          4  ENTJ  'You're fired.|||That's another silly misconce{\ldots}  Extroversion   
          
                   N-S       T-F         J-P  \textbackslash{}
          0  Intuition   Feeling     Judging   
          1  Intuition  Thinking  Perceiving   
          2  Intuition  Thinking  Perceiving   
          3  Intuition  Thinking     Judging   
          4  Intuition  Thinking     Judging   
          
                                                       posts\_r  total\_words  \textbackslash{}
          0  'URL URL enfp and intj moments  URL  sportscen{\ldots}          624   
          1  'I'm finding the lack of me in these posts ver{\ldots}         1268   
          2  'Good one  \_\_\_\_\_   URL Of course, to which I s{\ldots}          913   
          3  'Dear INTP,   I enjoyed our conversation the o{\ldots}         1164   
          4  'You're fired. That's another silly misconcept{\ldots}         1049   
          
             avg\_words\_per\_post  polarity  
          0               12.48  0.174200  
          1               25.36  0.174525  
          2               18.26  0.188119  
          3               23.28  0.123478  
          4               20.98  0.068665  
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}108}]:} \PY{c+c1}{\PYZsh{} Average polarity of posts, overall}
          \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{polarity}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}108}]:} 0.13313292270980398
\end{Verbatim}
            
    Overall, the average polarity of posts is 0.133 on a scale where -1
indicates a negative tone, 0 indicates neutral tone, and +1 indicates a
positive tone. Thus, the posts tend to have a neutral but
positive-leaning tone.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}109}]:} \PY{c+c1}{\PYZsh{} Average polarity of posts, by 16 types}
          \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{polarity}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}109}]:} type
          ENFJ    0.171106
          ENFP    0.161090
          ENTJ    0.131794
          ENTP    0.128875
          ESFJ    0.156516
          ESFP    0.133279
          ESTJ    0.132034
          ESTP    0.131005
          INFJ    0.140826
          INFP    0.136957
          INTJ    0.119186
          INTP    0.112073
          ISFJ    0.149495
          ISFP    0.152779
          ISTJ    0.125746
          ISTP    0.115987
          Name: polarity, dtype: float64
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}110}]:} \PY{c+c1}{\PYZsh{} Perform a Tukey range test to identify significant differences between the 16 classes on polarity}
          \PY{n}{tukey\PYZus{}p} \PY{o}{=} \PY{n}{pairwise\PYZus{}tukeyhsd}\PY{p}{(}\PY{n}{endog}\PY{o}{=}\PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{polarity}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}     \PY{c+c1}{\PYZsh{} Data}
                                    \PY{n}{groups}\PY{o}{=}\PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}   \PY{c+c1}{\PYZsh{} Groups}
                                    \PY{n}{alpha}\PY{o}{=}\PY{l+m+mf}{0.05}\PY{p}{)}          \PY{c+c1}{\PYZsh{} Significance level}
          \PY{n}{tukey\PYZus{}p}\PY{o}{.}\PY{n}{plot\PYZus{}simultaneous}\PY{p}{(}\PY{p}{)}    \PY{c+c1}{\PYZsh{} Plot group confidence intervals}
          \PY{n}{plt}\PY{o}{.}\PY{n}{vlines}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{l+m+mf}{0.13}\PY{p}{,}\PY{n}{ymin}\PY{o}{=}\PY{o}{\PYZhy{}}\PY{l+m+mf}{0.5}\PY{p}{,}\PY{n}{ymax}\PY{o}{=}\PY{l+m+mi}{16}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{red}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{95}\PY{l+s+s2}{\PYZpc{}}\PY{l+s+s2}{ Confidence Interval Plot \PYZhy{} Average Polarity}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{16}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Polarity}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Type}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{xticks}\PY{p}{(}\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{yticks}\PY{p}{(}\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}\PY{p}{;}
          
          \PY{c+c1}{\PYZsh{} Note: the Extroversion\PYZhy{}Sensing classes have n \PYZlt{} 100, so evaluate with caution.}
          \PY{c+c1}{\PYZsh{} ESTP (89), ESFP (48), ESFJ (42), ESTJ (39)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_190_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}111}]:} \PY{c+c1}{\PYZsh{} Display the test summary for the Tukey range test}
          \PY{n}{tukey\PYZus{}p}\PY{o}{.}\PY{n}{summary}\PY{p}{(}\PY{p}{)}     \PY{c+c1}{\PYZsh{} Reject = \PYZdq{}True\PYZdq{} indicates a significant difference (reject null hypothesis of no difference)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}111}]:} <class 'statsmodels.iolib.table.SimpleTable'>
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}112}]:} \PY{c+c1}{\PYZsh{} Bar graph of polarity, by 16 types}
          \PY{n}{dims1} \PY{o}{=} \PY{p}{(}\PY{l+m+mf}{15.0}\PY{p}{,} \PY{l+m+mf}{4.0}\PY{p}{)}
          \PY{n}{fig}\PY{p}{,} \PY{n}{ax} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{n}{dims1}\PY{p}{)}
          \PY{n}{coolwarm} \PY{o}{=} \PY{n}{sns}\PY{o}{.}\PY{n}{color\PYZus{}palette}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{coolwarm}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+m+mi}{16}\PY{p}{)}
          \PY{n}{sns}\PY{o}{.}\PY{n}{set\PYZus{}palette}\PY{p}{(}\PY{n}{coolwarm}\PY{p}{)}
          \PY{n}{sns}\PY{o}{.}\PY{n}{barplot}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{type}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{polarity}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{data}\PY{o}{=}\PY{n}{df\PYZus{}working}\PY{p}{,} \PYZbs{}
                        \PY{n}{order}\PY{o}{=}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ENFJ}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ENFP}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ENTJ}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ENTP}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ESFJ}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ESFP}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ESTJ}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ESTP}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PYZbs{}
                               \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{INFJ}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{INFP}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{INTJ}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{INTP}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ISFJ}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ISFP}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ISTJ}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ISTP}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Polarity of Posts, by Myers\PYZhy{}Briggs Type}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{16}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{ylim}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{xticks}\PY{p}{(}\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{yticks}\PY{p}{(}\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_192_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    The bar chart above shows the average polarity of posts by the 16 types.
This, in conjunction with the Tukey test, reveal that the following
types have a significantly higher average polarity than their noted
counterparts listed in the parentheses: - ENFJ (ENTJ, ENTP, ESFP, ESTJ,
ESTP, INFJ, INFP, INTJ, INTP, ISTJ, ISTP) - ENFP (ENTJ, ENTP, ESTP,
INFJ, INFP, INTJ, INTP, ISTJ, ISTP) - ISFP (ENTJ, ENTP, INFP, INTJ,
INTP, ISTJ, ISTP) - ISFJ (ENTP, INTJ, INTP, ISTJ, ISTP) - INFJ (ENTP,
INTJ, INTP, ISTP) - ESFJ (INTJ, INTP, ISTP) - INFP (INTJ, INTP, ISTP) -
ENTJ (INTP) - ENTP (INTP)

It is notable that those with a \emph{Extroversion-Intuitive-Feeling}
type, regardless of their \emph{Judging/Perceiving} status, have a
significantly higher polarity to their posts compared to most of the
other personality types - although their polarity is still relatively
neutral. Conversely, the \emph{Introversion-Intuitive-Thinking} types,
regardless of their \emph{Judging/Perceiving} status, tend to have a
significantly lower polarity (more neutral) than many of the other
personality types.

\emph{(Note, the Extrovert-Sensing types: ESFJ, ESFP, ESTJ, and ESTP
have low base sizes and are subject to outlier values).}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}113}]:} \PY{c+c1}{\PYZsh{} Average polarity of posts, by Introversion (I) – Extroversion (E) axis}
          \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{polarity}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{I\PYZhy{}E}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}113}]:} I-E
          Extroversion    0.144947
          Introversion    0.129595
          Name: polarity, dtype: float64
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}114}]:} \PY{c+c1}{\PYZsh{} Calculate standard deviation}
          \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{polarity}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{I\PYZhy{}E}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}114}]:} I-E
          Extroversion    0.063461
          Introversion    0.062351
          Name: polarity, dtype: float64
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}115}]:} \PY{c+c1}{\PYZsh{} T\PYZhy{}test on Introversion \PYZhy{} Extroversion axis for polarity}
          \PY{n}{stats}\PY{o}{.}\PY{n}{ttest\PYZus{}ind\PYZus{}from\PYZus{}stats}\PY{p}{(}\PY{n}{mean1}\PY{o}{=}\PY{l+m+mf}{0.144947}\PY{p}{,} \PY{n}{std1}\PY{o}{=}\PY{l+m+mf}{0.063461}\PY{p}{,} \PY{n}{nobs1}\PY{o}{=}\PY{l+m+mi}{1999}\PY{p}{,} 
                                     \PY{n}{mean2}\PY{o}{=}\PY{l+m+mf}{0.129595}\PY{p}{,} \PY{n}{std2}\PY{o}{=}\PY{l+m+mf}{0.062351}\PY{p}{,} \PY{n}{nobs2}\PY{o}{=}\PY{l+m+mi}{6676}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}115}]:} Ttest\_indResult(statistic=9.617491060707676, pvalue=8.662893551894502e-22)
\end{Verbatim}
            
    The p-value of 8.66e-22 is lower than 0.05, thus the difference is
significant.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}116}]:} \PY{c+c1}{\PYZsh{} Bar graph of polarity of posts, by Introversion \PYZhy{} Extroversion axis}
          \PY{n}{IEcolors} \PY{o}{=} \PY{n}{sns}\PY{o}{.}\PY{n}{xkcd\PYZus{}palette}\PY{p}{(}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{red}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{soft pink}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
          \PY{n}{sns}\PY{o}{.}\PY{n}{set\PYZus{}palette}\PY{p}{(}\PY{n}{IEcolors}\PY{p}{)}
          \PY{n}{sns}\PY{o}{.}\PY{n}{barplot}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{I\PYZhy{}E}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{polarity}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{data}\PY{o}{=}\PY{n}{df\PYZus{}working}\PY{p}{,} \PY{n}{order}\PY{o}{=}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Introversion}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Extroversion}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Polarity of Posts, by Introversion \PYZhy{} Extroversion Axis}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{16}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{ylim}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{xticks}\PY{p}{(}\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{yticks}\PY{p}{(}\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_198_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    The bar graph above and corresponding t-test show that Extroverts have a
significantly higher positive polarity in tone compared to Introverts,
but for both groups the tone is relatively neutral.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}117}]:} \PY{c+c1}{\PYZsh{} Average polarity of posts, by Intuition (N) – Sensing (S) axis}
          \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{polarity}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{N\PYZhy{}S}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}117}]:} N-S
          Intuition    0.132932
          Sensing      0.134390
          Name: polarity, dtype: float64
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}118}]:} \PY{c+c1}{\PYZsh{} Calculate standard deviation}
          \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{polarity}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{N\PYZhy{}S}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}118}]:} N-S
          Intuition    0.061490
          Sensing      0.071336
          Name: polarity, dtype: float64
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}119}]:} \PY{c+c1}{\PYZsh{} T\PYZhy{}test on Intuition \PYZhy{} Sensing axis for polarity}
          \PY{n}{stats}\PY{o}{.}\PY{n}{ttest\PYZus{}ind\PYZus{}from\PYZus{}stats}\PY{p}{(}\PY{n}{mean1}\PY{o}{=}\PY{l+m+mf}{0.132932}\PY{p}{,} \PY{n}{std1}\PY{o}{=}\PY{l+m+mf}{0.061490}\PY{p}{,} \PY{n}{nobs1}\PY{o}{=}\PY{l+m+mi}{7478}\PY{p}{,} 
                                     \PY{n}{mean2}\PY{o}{=}\PY{l+m+mf}{0.134390}\PY{p}{,} \PY{n}{std2}\PY{o}{=}\PY{l+m+mf}{0.071336}\PY{p}{,} \PY{n}{nobs2}\PY{o}{=}\PY{l+m+mi}{1197}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}119}]:} Ttest\_indResult(statistic=-0.7441151340741253, pvalue=0.45682698347744644)
\end{Verbatim}
            
    The p-value of 0.457 is greater than 0.05, thus the difference is not
significant.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}120}]:} \PY{c+c1}{\PYZsh{} Bar graph of polarity of posts, by Intuition \PYZhy{} Sensing axis}
          \PY{n}{NScolors} \PY{o}{=} \PY{n}{sns}\PY{o}{.}\PY{n}{xkcd\PYZus{}palette}\PY{p}{(}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{blue}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{light blue}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
          \PY{n}{sns}\PY{o}{.}\PY{n}{set\PYZus{}palette}\PY{p}{(}\PY{n}{NScolors}\PY{p}{)}
          \PY{n}{sns}\PY{o}{.}\PY{n}{barplot}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{N\PYZhy{}S}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{polarity}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{data}\PY{o}{=}\PY{n}{df\PYZus{}working}\PY{p}{,} \PY{n}{order}\PY{o}{=}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Intuition}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Sensing}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Polarity of Posts, by Intuition vs. Sensing Axis}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{16}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{ylim}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{xticks}\PY{p}{(}\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{yticks}\PY{p}{(}\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_204_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    The bar graph above and corresponding t-test show no significant
difference in polarity between subjects higher in Intuition vs. Sensing,
and for both groups the tone is relatively neutral.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}121}]:} \PY{c+c1}{\PYZsh{} Average polarity of posts, by Thinking (T) – Feeling (F) axis}
          \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{polarity}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{T\PYZhy{}F}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}121}]:} T-F
          Feeling     0.144516
          Thinking    0.119712
          Name: polarity, dtype: float64
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}122}]:} \PY{c+c1}{\PYZsh{} Calculate standard deviation}
          \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{polarity}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{T\PYZhy{}F}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}122}]:} T-F
          Feeling     0.063516
          Thinking    0.059523
          Name: polarity, dtype: float64
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}123}]:} \PY{c+c1}{\PYZsh{} T\PYZhy{}test on Thinking\PYZhy{}Feeling axis for polarity}
          \PY{n}{stats}\PY{o}{.}\PY{n}{ttest\PYZus{}ind\PYZus{}from\PYZus{}stats}\PY{p}{(}\PY{n}{mean1}\PY{o}{=}\PY{l+m+mf}{0.144516}\PY{p}{,} \PY{n}{std1}\PY{o}{=}\PY{l+m+mf}{0.063516}\PY{p}{,} \PY{n}{nobs1}\PY{o}{=}\PY{l+m+mi}{4694}\PY{p}{,} 
                                     \PY{n}{mean2}\PY{o}{=}\PY{l+m+mf}{0.119712}\PY{p}{,} \PY{n}{std2}\PY{o}{=}\PY{l+m+mf}{0.059523}\PY{p}{,} \PY{n}{nobs2}\PY{o}{=}\PY{l+m+mi}{3981}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}123}]:} Ttest\_indResult(statistic=18.653436564934832, pvalue=3.615788576742857e-76)
\end{Verbatim}
            
    The p-value is less than 0.05, thus the difference is significant.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}124}]:} \PY{c+c1}{\PYZsh{} Bar graph of polarity of posts, by Thinking vs. Feeling axis}
          \PY{n}{TFcolors} \PY{o}{=} \PY{n}{sns}\PY{o}{.}\PY{n}{xkcd\PYZus{}palette}\PY{p}{(}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{green}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{pale green}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
          \PY{n}{sns}\PY{o}{.}\PY{n}{set\PYZus{}palette}\PY{p}{(}\PY{n}{TFcolors}\PY{p}{)}
          \PY{n}{sns}\PY{o}{.}\PY{n}{barplot}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{T\PYZhy{}F}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{polarity}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{data}\PY{o}{=}\PY{n}{df\PYZus{}working}\PY{p}{,} \PY{n}{order}\PY{o}{=}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Thinking}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Feeling}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Polarity of Posts, by Thinking vs. Feeling Axis}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{16}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{ylim}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{xticks}\PY{p}{(}\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{yticks}\PY{p}{(}\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_210_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    The bar graph above and corresponding t-test show that subjects on the
Feeling side of the axis have a significantly higher positive polarity
in tone compared to those on the Thinking side, but for both groups the
tone is relatively neutral.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}125}]:} \PY{c+c1}{\PYZsh{} Average polarity of posts, by Judging (J) – Perceiving (P) axis}
          \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{polarity}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{J\PYZhy{}P}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}125}]:} J-P
          Judging       0.134629
          Perceiving    0.132153
          Name: polarity, dtype: float64
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}126}]:} \PY{c+c1}{\PYZsh{} Calculate standard deviation}
          \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{polarity}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{J\PYZhy{}P}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}126}]:} J-P
          Judging       0.062215
          Perceiving    0.063394
          Name: polarity, dtype: float64
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}127}]:} \PY{c+c1}{\PYZsh{} T\PYZhy{}test on Judging\PYZhy{}Perceiving axis for polarity}
          \PY{n}{stats}\PY{o}{.}\PY{n}{ttest\PYZus{}ind\PYZus{}from\PYZus{}stats}\PY{p}{(}\PY{n}{mean1}\PY{o}{=}\PY{l+m+mf}{0.134629}\PY{p}{,} \PY{n}{std1}\PY{o}{=}\PY{l+m+mf}{0.062215}\PY{p}{,} \PY{n}{nobs1}\PY{o}{=}\PY{l+m+mi}{5241}\PY{p}{,} 
                                     \PY{n}{mean2}\PY{o}{=}\PY{l+m+mf}{0.132153}\PY{p}{,} \PY{n}{std2}\PY{o}{=}\PY{l+m+mf}{0.063394}\PY{p}{,} \PY{n}{nobs2}\PY{o}{=}\PY{l+m+mi}{3434}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}127}]:} Ttest\_indResult(statistic=1.7991365694178103, pvalue=0.07203182935182134)
\end{Verbatim}
            
    The p-value of .072 is larger than 0.05, thus the difference is not
significant.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}128}]:} \PY{c+c1}{\PYZsh{} Bar graph of polarity of posts, by Judging \PYZhy{} Perceiving axis}
          \PY{n}{JPcolors} \PY{o}{=} \PY{n}{sns}\PY{o}{.}\PY{n}{xkcd\PYZus{}palette}\PY{p}{(}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{purple}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{lavender}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
          \PY{n}{sns}\PY{o}{.}\PY{n}{set\PYZus{}palette}\PY{p}{(}\PY{n}{JPcolors}\PY{p}{)}
          \PY{n}{sns}\PY{o}{.}\PY{n}{barplot}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{J\PYZhy{}P}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{polarity}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{data}\PY{o}{=}\PY{n}{df\PYZus{}working}\PY{p}{,} \PY{n}{order}\PY{o}{=}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Judging}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Perceiving}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Polarity of Posts, by Judging vs. Perceiving Axis}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{16}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{ylim}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{xticks}\PY{p}{(}\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{yticks}\PY{p}{(}\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_216_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    The bar graph above and corresponding t-test show no significant
differences in terms of polarity for Judgers or Perceivers.

     \#\#\#\# Subjectivity

subjectivity (0 to 1): scores closer to 0 are more objective in tone,
scores closer to 1 are more subjective in tone

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}129}]:} \PY{k}{def} \PY{n+nf}{subjectivity}\PY{p}{(}\PY{n}{text}\PY{p}{)}\PY{p}{:}
              \PY{n}{text} \PY{o}{=} \PY{n}{TextBlob}\PY{p}{(}\PY{n}{text}\PY{p}{)}
              \PY{k}{return} \PY{n}{text}\PY{o}{.}\PY{n}{sentiment}\PY{o}{.}\PY{n}{subjectivity}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}130}]:} \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{subjectivity}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{posts\PYZus{}r}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{n}{subjectivity}\PY{p}{)}
          \PY{n}{df\PYZus{}working}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}130}]:}    type                                              posts           I-E  \textbackslash{}
          0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||{\ldots}  Introversion   
          1  ENTP  'I'm finding the lack of me in these posts ver{\ldots}  Extroversion   
          2  INTP  'Good one  \_\_\_\_\_   https://www.youtube.com/wat{\ldots}  Introversion   
          3  INTJ  'Dear INTP,   I enjoyed our conversation the o{\ldots}  Introversion   
          4  ENTJ  'You're fired.|||That's another silly misconce{\ldots}  Extroversion   
          
                   N-S       T-F         J-P  \textbackslash{}
          0  Intuition   Feeling     Judging   
          1  Intuition  Thinking  Perceiving   
          2  Intuition  Thinking  Perceiving   
          3  Intuition  Thinking     Judging   
          4  Intuition  Thinking     Judging   
          
                                                       posts\_r  total\_words  \textbackslash{}
          0  'URL URL enfp and intj moments  URL  sportscen{\ldots}          624   
          1  'I'm finding the lack of me in these posts ver{\ldots}         1268   
          2  'Good one  \_\_\_\_\_   URL Of course, to which I s{\ldots}          913   
          3  'Dear INTP,   I enjoyed our conversation the o{\ldots}         1164   
          4  'You're fired. That's another silly misconcept{\ldots}         1049   
          
             avg\_words\_per\_post  polarity  subjectivity  
          0               12.48  0.174200      0.502012  
          1               25.36  0.174525      0.551938  
          2               18.26  0.188119      0.615378  
          3               23.28  0.123478      0.546078  
          4               20.98  0.068665      0.513298  
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}131}]:} \PY{c+c1}{\PYZsh{} Average subjectivity of posts, overall}
          \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{subjectivity}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}131}]:} 0.5401621653498018
\end{Verbatim}
            
    Overall, the average subjectivity of posts is 0.540 on a scale where 0
indicates an objective tone, and 1 indicates a subjective tone. Thus,
the posts tend to have a moderate tone, being neither overly objective
nor subjective.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}132}]:} \PY{c+c1}{\PYZsh{} Average subjectivity of posts, by 16 types}
          \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{subjectivity}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}132}]:} type
          ENFJ    0.556873
          ENFP    0.559246
          ENTJ    0.534690
          ENTP    0.540593
          ESFJ    0.547430
          ESFP    0.551374
          ESTJ    0.536098
          ESTP    0.540242
          INFJ    0.541934
          INFP    0.546770
          INTJ    0.529273
          INTP    0.528651
          ISFJ    0.550440
          ISFP    0.548526
          ISTJ    0.524557
          ISTP    0.527188
          Name: subjectivity, dtype: float64
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}133}]:} \PY{c+c1}{\PYZsh{} Perform a Tukey range test to identify significant differences between the 16 classes on subjectivity}
          \PY{n}{tukey\PYZus{}s} \PY{o}{=} \PY{n}{pairwise\PYZus{}tukeyhsd}\PY{p}{(}\PY{n}{endog}\PY{o}{=}\PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{subjectivity}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}     \PY{c+c1}{\PYZsh{} Data}
                                    \PY{n}{groups}\PY{o}{=}\PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}   \PY{c+c1}{\PYZsh{} Groups}
                                    \PY{n}{alpha}\PY{o}{=}\PY{l+m+mf}{0.05}\PY{p}{)}          \PY{c+c1}{\PYZsh{} Significance level}
          \PY{n}{tukey\PYZus{}s}\PY{o}{.}\PY{n}{plot\PYZus{}simultaneous}\PY{p}{(}\PY{p}{)}    \PY{c+c1}{\PYZsh{} Plot group confidence intervals}
          \PY{n}{plt}\PY{o}{.}\PY{n}{vlines}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{l+m+mf}{0.54}\PY{p}{,}\PY{n}{ymin}\PY{o}{=}\PY{o}{\PYZhy{}}\PY{l+m+mf}{0.5}\PY{p}{,}\PY{n}{ymax}\PY{o}{=}\PY{l+m+mi}{16}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{red}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{95}\PY{l+s+s2}{\PYZpc{}}\PY{l+s+s2}{ Confidence Interval Plot \PYZhy{} Average Subjectivity}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{16}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Subjectivity}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Type}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{xticks}\PY{p}{(}\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{yticks}\PY{p}{(}\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}\PY{p}{;}
          
          \PY{c+c1}{\PYZsh{} Note: the Extroversion\PYZhy{}Sensing classes have n \PYZlt{} 100, so evaluate with caution.}
          \PY{c+c1}{\PYZsh{} ESTP (89), ESFP (48), ESFJ (42), ESTJ (39)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_224_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}134}]:} \PY{c+c1}{\PYZsh{} Display the test summary for the Tukey range test}
          \PY{n}{tukey\PYZus{}s}\PY{o}{.}\PY{n}{summary}\PY{p}{(}\PY{p}{)}     \PY{c+c1}{\PYZsh{} Reject = \PYZdq{}True\PYZdq{} indicates a significant difference (reject null hypothesis of no difference)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}134}]:} <class 'statsmodels.iolib.table.SimpleTable'>
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}135}]:} \PY{c+c1}{\PYZsh{} Bar graph of subjectivity, by 16 types}
          \PY{n}{dims1} \PY{o}{=} \PY{p}{(}\PY{l+m+mf}{15.0}\PY{p}{,} \PY{l+m+mf}{4.0}\PY{p}{)}
          \PY{n}{fig}\PY{p}{,} \PY{n}{ax} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{n}{dims1}\PY{p}{)}
          \PY{n}{coolwarm} \PY{o}{=} \PY{n}{sns}\PY{o}{.}\PY{n}{color\PYZus{}palette}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{coolwarm}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+m+mi}{16}\PY{p}{)}
          \PY{n}{sns}\PY{o}{.}\PY{n}{set\PYZus{}palette}\PY{p}{(}\PY{n}{coolwarm}\PY{p}{)}
          \PY{n}{sns}\PY{o}{.}\PY{n}{barplot}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{type}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{subjectivity}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{data}\PY{o}{=}\PY{n}{df\PYZus{}working}\PY{p}{,} \PYZbs{}
                        \PY{n}{order}\PY{o}{=}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ENFJ}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ENFP}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ENTJ}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ENTP}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ESFJ}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ESFP}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ESTJ}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ESTP}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PYZbs{}
                               \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{INFJ}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{INFP}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{INTJ}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{INTP}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ISFJ}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ISFP}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ISTJ}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ISTP}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Subjectivity of Posts, by Myers\PYZhy{}Briggs Type}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{16}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{ylim}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{xticks}\PY{p}{(}\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{yticks}\PY{p}{(}\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_226_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    The bar chart above shows the average subjectivity of posts by the 16
types. This, in conjunction with the Tukey test, reveal that the
following types have a significantly higher average subjectivity than
their noted counterparts listed in the parentheses: - ENFP (ENTJ, ENTP,
ESTP, INFJ, INFP, INTJ, INTP, ISTJ, ISTP) - ENFJ (ENTJ, ENTP, INFJ,
INTJ, INTP, ISTJ, ISTP) - INFP (ENTJ, INTJ, INTP, ISTJ, ISTP) - ENTP
(INTJ, INTP, ISTJ, ISTP) - INFJ (INTJ, INTP, ISTJ, ISTP) - ISFJ (INTJ,
INTP, ISTJ, ISTP) - ISFP (INTJ, INTP, ISTJ, ISTP) - ESFP (ESTJ, ISTP)

The posts of those with an \emph{Extroversion-Intuitive-Feeling} type
(regardless of their \emph{Judging/Perceiving} status) have a
significantly higher average subjectivity than many of the other types,
notably those with \emph{Extroversion-Intuitive-Thinking},
\emph{Introversion-Intuitive-Thinking}, or
\emph{Introversion-Sensing-Thinking} traits. Conversely, the
\emph{Introversion-Intuitive-Thinking} and
\emph{Introversion-Sensing-Thinking} types tend to display significantly
lower subjectivity than many of the other types. Overall, however, each
of the classes have an average subjectivity level in the moderate range,
being neither overly subjective nor objective in their posts.

\emph{(Note, the Extrovert-Sensing types: ESFJ, ESFP, ESTJ, and ESTP
have low base sizes and are subject to outlier values).}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}136}]:} \PY{c+c1}{\PYZsh{} Average subjectivity of posts, by Introversion (I) – Extroversion (E) axis}
          \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{subjectivity}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{I\PYZhy{}E}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}136}]:} I-E
          Extroversion    0.548056
          Introversion    0.537798
          Name: subjectivity, dtype: float64
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}137}]:} \PY{c+c1}{\PYZsh{} Calculate standard deviation}
          \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{subjectivity}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{I\PYZhy{}E}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}137}]:} I-E
          Extroversion    0.045576
          Introversion    0.046268
          Name: subjectivity, dtype: float64
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}138}]:} \PY{c+c1}{\PYZsh{} T\PYZhy{}test on Introversion \PYZhy{} Extroversion axis for subjectivity}
          \PY{n}{stats}\PY{o}{.}\PY{n}{ttest\PYZus{}ind\PYZus{}from\PYZus{}stats}\PY{p}{(}\PY{n}{mean1}\PY{o}{=}\PY{l+m+mf}{0.548056}\PY{p}{,} \PY{n}{std1}\PY{o}{=}\PY{l+m+mf}{0.045576}\PY{p}{,} \PY{n}{nobs1}\PY{o}{=}\PY{l+m+mi}{1999}\PY{p}{,} 
                                     \PY{n}{mean2}\PY{o}{=}\PY{l+m+mf}{0.537798}\PY{p}{,} \PY{n}{std2}\PY{o}{=}\PY{l+m+mf}{0.046268}\PY{p}{,} \PY{n}{nobs2}\PY{o}{=}\PY{l+m+mi}{6676}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}138}]:} Ttest\_indResult(statistic=8.72573578305491, pvalue=3.1360883473603333e-18)
\end{Verbatim}
            
    The p-value is lower than 0.05, thus the difference is significant.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}139}]:} \PY{c+c1}{\PYZsh{} Bar graph of subjectivity of posts, by Introversion \PYZhy{} Extroversion axis}
          \PY{n}{IEcolors} \PY{o}{=} \PY{n}{sns}\PY{o}{.}\PY{n}{xkcd\PYZus{}palette}\PY{p}{(}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{red}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{soft pink}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
          \PY{n}{sns}\PY{o}{.}\PY{n}{set\PYZus{}palette}\PY{p}{(}\PY{n}{IEcolors}\PY{p}{)}
          \PY{n}{sns}\PY{o}{.}\PY{n}{barplot}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{I\PYZhy{}E}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{subjectivity}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{data}\PY{o}{=}\PY{n}{df\PYZus{}working}\PY{p}{,} \PY{n}{order}\PY{o}{=}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Introversion}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Extroversion}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Subjectivity of Posts, by Introversion \PYZhy{} Extroversion Axis}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{16}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{ylim}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{xticks}\PY{p}{(}\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{yticks}\PY{p}{(}\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_232_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    The bar graph and associated t-test show that the posts of Introverts
have a significantly higher subjectivity than those of Extroverts, but
both groups are relatively moderate.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}140}]:} \PY{c+c1}{\PYZsh{} Average subjectivity of posts, by Intuition (N) – Sensing (S) axis}
          \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{subjectivity}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{N\PYZhy{}S}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}140}]:} N-S
          Intuition    0.540551
          Sensing      0.537734
          Name: subjectivity, dtype: float64
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}141}]:} \PY{c+c1}{\PYZsh{} Calculate standard deviation}
          \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{subjectivity}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{N\PYZhy{}S}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}141}]:} N-S
          Intuition    0.045310
          Sensing      0.052072
          Name: subjectivity, dtype: float64
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}142}]:} \PY{c+c1}{\PYZsh{} T\PYZhy{}test on Intuition \PYZhy{} Sensing axis for subjectivity}
          \PY{n}{stats}\PY{o}{.}\PY{n}{ttest\PYZus{}ind\PYZus{}from\PYZus{}stats}\PY{p}{(}\PY{n}{mean1}\PY{o}{=}\PY{l+m+mf}{0.540551}\PY{p}{,} \PY{n}{std1}\PY{o}{=}\PY{l+m+mf}{0.045310}\PY{p}{,} \PY{n}{nobs1}\PY{o}{=}\PY{l+m+mi}{7478}\PY{p}{,} 
                                     \PY{n}{mean2}\PY{o}{=}\PY{l+m+mf}{0.537734}\PY{p}{,} \PY{n}{std2}\PY{o}{=}\PY{l+m+mf}{0.052072}\PY{p}{,} \PY{n}{nobs2}\PY{o}{=}\PY{l+m+mi}{1197}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}142}]:} Ttest\_indResult(statistic=1.954337388621632, pvalue=0.05069341814096863)
\end{Verbatim}
            
    The p-value is greater than 0.05, thus the difference is not
significant.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}143}]:} \PY{c+c1}{\PYZsh{} Bar graph of subjectivity of posts, by Intuition \PYZhy{} Sensing axis}
          \PY{n}{NScolors} \PY{o}{=} \PY{n}{sns}\PY{o}{.}\PY{n}{xkcd\PYZus{}palette}\PY{p}{(}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{blue}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{light blue}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
          \PY{n}{sns}\PY{o}{.}\PY{n}{set\PYZus{}palette}\PY{p}{(}\PY{n}{NScolors}\PY{p}{)}
          \PY{n}{sns}\PY{o}{.}\PY{n}{barplot}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{N\PYZhy{}S}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{subjectivity}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{data}\PY{o}{=}\PY{n}{df\PYZus{}working}\PY{p}{,} \PY{n}{order}\PY{o}{=}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Intuition}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Sensing}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Subjectivity of Posts, by Intuition vs. Sensing Axis}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{16}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{ylim}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{xticks}\PY{p}{(}\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{yticks}\PY{p}{(}\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_238_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    The bar graph and corresponding t-test show that subjects classified at
the Intuition end of the axis are not significantly different from their
Sensing counterparts in terms of subjectivity of their posts. Overall,
both groups are fairly moderate in their subjectivity.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}144}]:} \PY{c+c1}{\PYZsh{} Average subjectivity of posts, by Thinking (T) – Feeling (F) axis}
          \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{subjectivity}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{T\PYZhy{}F}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}144}]:} T-F
          Feeling     0.547743
          Thinking    0.531224
          Name: subjectivity, dtype: float64
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}145}]:} \PY{c+c1}{\PYZsh{} Calculate standard deviation}
          \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{subjectivity}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{T\PYZhy{}F}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}145}]:} T-F
          Feeling     0.046642
          Thinking    0.044282
          Name: subjectivity, dtype: float64
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}146}]:} \PY{c+c1}{\PYZsh{} T\PYZhy{}test on Thinking\PYZhy{}Feeling axis for subjectivity}
          \PY{n}{stats}\PY{o}{.}\PY{n}{ttest\PYZus{}ind\PYZus{}from\PYZus{}stats}\PY{p}{(}\PY{n}{mean1}\PY{o}{=}\PY{l+m+mf}{0.547743}\PY{p}{,} \PY{n}{std1}\PY{o}{=}\PY{l+m+mf}{0.046642}\PY{p}{,} \PY{n}{nobs1}\PY{o}{=}\PY{l+m+mi}{4694}\PY{p}{,} 
                                     \PY{n}{mean2}\PY{o}{=}\PY{l+m+mf}{0.531224}\PY{p}{,} \PY{n}{std2}\PY{o}{=}\PY{l+m+mf}{0.044282}\PY{p}{,} \PY{n}{nobs2}\PY{o}{=}\PY{l+m+mi}{3981}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}146}]:} Ttest\_indResult(statistic=16.822779704486784, pvalue=1.6176276285064264e-62)
\end{Verbatim}
            
    The p-value is lower than 0.05, thus the difference is significant.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}147}]:} \PY{c+c1}{\PYZsh{} Bar graph of subjectivity of posts, by Thinking vs. Feeling axis}
          \PY{n}{TFcolors} \PY{o}{=} \PY{n}{sns}\PY{o}{.}\PY{n}{xkcd\PYZus{}palette}\PY{p}{(}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{green}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{pale green}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
          \PY{n}{sns}\PY{o}{.}\PY{n}{set\PYZus{}palette}\PY{p}{(}\PY{n}{TFcolors}\PY{p}{)}
          \PY{n}{sns}\PY{o}{.}\PY{n}{barplot}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{T\PYZhy{}F}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{subjectivity}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{data}\PY{o}{=}\PY{n}{df\PYZus{}working}\PY{p}{,} \PY{n}{order}\PY{o}{=}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Thinking}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Feeling}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Subjectivity of Posts, by Thinking vs. Feeling Axis}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{16}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{ylim}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{xticks}\PY{p}{(}\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{yticks}\PY{p}{(}\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_244_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    The bar graph and corresponding t-test show that subjects at the Feeling
end of the axis have a significantly higher subjectivity to their posts
than their Thinking counterparts, but both groups are fairly moderate.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}148}]:} \PY{c+c1}{\PYZsh{} Average subjectivity of posts, by Judging (J) – Perceiving (P) axis}
          \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{subjectivity}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{J\PYZhy{}P}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}148}]:} J-P
          Judging       0.537625
          Perceiving    0.541824
          Name: subjectivity, dtype: float64
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}149}]:} \PY{c+c1}{\PYZsh{} Calculate standard deviation}
          \PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{subjectivity}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{n}{df\PYZus{}working}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{J\PYZhy{}P}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}149}]:} J-P
          Judging       0.045853
          Perceiving    0.046535
          Name: subjectivity, dtype: float64
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}150}]:} \PY{c+c1}{\PYZsh{} T\PYZhy{}test on Judging\PYZhy{}Perceiving axis for subjectivity}
          \PY{n}{stats}\PY{o}{.}\PY{n}{ttest\PYZus{}ind\PYZus{}from\PYZus{}stats}\PY{p}{(}\PY{n}{mean1}\PY{o}{=}\PY{l+m+mf}{0.537625}\PY{p}{,} \PY{n}{std1}\PY{o}{=}\PY{l+m+mf}{0.045853}\PY{p}{,} \PY{n}{nobs1}\PY{o}{=}\PY{l+m+mi}{5241}\PY{p}{,} 
                                     \PY{n}{mean2}\PY{o}{=}\PY{l+m+mf}{0.541824}\PY{p}{,} \PY{n}{std2}\PY{o}{=}\PY{l+m+mf}{0.046535}\PY{p}{,} \PY{n}{nobs2}\PY{o}{=}\PY{l+m+mi}{3434}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}150}]:} Ttest\_indResult(statistic=-4.146578536349087, pvalue=3.4069543197347476e-05)
\end{Verbatim}
            
    The p-value is lower than 0.05, thus the difference is significant.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}151}]:} \PY{c+c1}{\PYZsh{} Bar graph of subjectivity of posts, by Judging \PYZhy{} Perceiving axis}
          \PY{n}{JPcolors} \PY{o}{=} \PY{n}{sns}\PY{o}{.}\PY{n}{xkcd\PYZus{}palette}\PY{p}{(}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{purple}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{lavender}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
          \PY{n}{sns}\PY{o}{.}\PY{n}{set\PYZus{}palette}\PY{p}{(}\PY{n}{JPcolors}\PY{p}{)}
          \PY{n}{sns}\PY{o}{.}\PY{n}{barplot}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{J\PYZhy{}P}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{subjectivity}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{data}\PY{o}{=}\PY{n}{df\PYZus{}working}\PY{p}{,} \PY{n}{order}\PY{o}{=}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Judging}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Perceiving}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Subjectivity of Posts, by Judging vs. Perceiving Axis}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{16}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{ylim}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{xticks}\PY{p}{(}\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{yticks}\PY{p}{(}\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_250_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    The bar graph and corresponding t-test show that those at the Perceiving
end of the spectrum show significantly higher subjectivity to their
posts than their Judging counterparts, yet both groups are relatively
moderate.

    \begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

     \#\#\# Conclusion

While all three models surpassed the baseline of 0.211 in predicting the
sixteen classes, they did not all perform similarly. While the
\emph{Random Forest Classifier} had the highest accuracy at 0.270, its
predictions were limited entirely to the four Introvert-Intuition (IN-)
classes, the most abundant classes in the dataset. The \emph{K-Neighbors
Classifier} had a much lower accuracy at 0.217, just barely clearing the
baseline, but unlike the prior model it posted predictions across the
full set of classes. The third model attempted, \emph{One-Vs-The-Rest
Classifier}, at 0.265 did not have as high an accuracy score as Random
Forest, but it did make predictions across the full range of classes.

At first glance, the \emph{One-Vs-The-Rest Classifier} appears to have a
large amount of mismatches in the confusion matrix. However, it is
notable that many of the predictions differ from the actual class by
only one letter of the type code. Recall that the Myers-Briggs
personality types are comprised of four axes which make up the
four-letter code. In many cases, if not predicting exactly, the model is
able to attribute codes that match on three of the four axes. For
example, there are several ENTPs in which \emph{Introversion/Intuitive}
classes were misattributed as ENTP.

The binary classification exercise to predict each of the classes in the
four axes was somewhat more successful. A \emph{Random Forest Classifer}
was used. The final model accuracy topped the baseline for only the
\emph{Thinking-Feeling} analysis (baseline 0.541, accuracy 0.697), but
was not excessively far from the baseline for the other axes:
\emph{Introversion-Extroversion} (baseline 0.769, accuracy 0.727),
\emph{Intuition-Sensing} (baseline 0.862, accuracy 0.819), and
\emph{Judging-Perceiving} (baseline 0.604, accuracy 0.585). While it
should be noted that \emph{Thinking-Feeling} was the most balanced of
the four axes and this may have helped the model accuracy, it is
possible that members of the \emph{Thinking} vs. \emph{Feeling} classes
actually do have greater differentiation in the language they use in
social media posts compared to the other dimensions. This axis describes
people's method for making decisions (i.e. putting more weight on
objective principles and impersonal facts vs. personal concerns and the
people involved), so perhaps the words each of these groups use do
differ. Further exploration can be done using TF-IDF Vectorizer to
confirm this.

In terms of the sentiment analysis and word count, subjects across the
types and axes tended to be fairly moderate in the subjectivity and
neutral in polarity of their posts. However, there was a significantly
higher subjectivity seen among the \emph{Extroversion-Intuitive-Feeling}
types compared to their counterparts, yet when analyzed by individual
axis the \emph{Introversion}, \emph{Sensing}, \emph{Feeling}, and
\emph{Perceiving} ends of the respective axes showed higher subjectivity
scores. Likewise, a significantly higher polarity occurred among
subjects in the \emph{Extroversion-Intuitive-Feeling} types, and also at
the \emph{Extroversion} and \emph{Feeling} ends of those axes. Overall
the subjects averaged about 26.4 words per post, with the
\emph{Intuitive-Feeling} types -\/- as well as those at the
\emph{Intuition}, \emph{Feeling}, and \emph{Judging} poles of their axes
-\/- having a significantly higher average length.

Viewing the four axes independently, there are statistically significant
differences on post length favoring the \emph{Intuitive},
\emph{Feeling}, and \emph{Judging} classes of their respective pairs.
Likewise, in terms of their polarity, the \emph{Extroversion} and
\emph{Feeling} classes have a statistically significant higher score
than their axis counterparts - though it is important to note that both
of these still scored at the neutral/skewing positive part of the scale
as all the other classes did. In addition, the \emph{Extroversion},
\emph{Feeling}, and \emph{Perceiving} classes garnered statistically
significant higher scores than their counterparts in terms of the
subjectivity of their posts - again, however, it should be noted that
each of the classes scored relatively moderate on this measure, being
neither overly subjective nor objective in their posts.

    \begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

     \#\#\# Next Steps

An interesting project for further research can be done using different
social media sites, to analyze subjects' writing style in different
contexts. The PersonalityCafe forum, while providing excellent
information for the dataset including MBTI personality type, can be a
bit limited in scope of the conversation that occurs there. It is also
possibly a self-selecting sample, perhaps because Introverts may be more
drawn to the topic of personality types than their Extroverted
counterparts. A site like Facebook would be a rich source for
information, both because the topic of discussion is broadened, and
because it may draw a wider diversity of personality types due to its
ubiquity. While Facebook does not inherently contain the information
regarding personality type, this can be obtained by administering
surveys incorporating the MBTI assessment to site users who have
consented to participate in research.


    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
